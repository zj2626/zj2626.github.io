{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\zj2626\\GraphLabData\\Data2.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\zj2626\\GraphLabData\\Data2.csv"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.023017 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.023017 secs."
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file C:\\Users\\zj2626\\GraphLabData\\Data2.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file C:\\Users\\zj2626\\GraphLabData\\Data2.csv"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 169 lines in 0.023018 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 169 lines in 0.023018 secs."
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------------------------------------+\n",
      "| ﻿name | score |                         comment                         |\n",
      "+-------+-------+---------------------------------------------------------+\n",
      "|  芳华 |   40  |    “没有被善待的人 最容易识别善良 也最珍惜善良。” ...   |\n",
      "|  芳华 |   40  |  三星半 手松点也是可以四星的。全片最触动我的 就是那...  |\n",
      "|  芳华 |   40  |  严歌苓笔下有幻灭 但冯小刚镜头里只是一闪而过。严写的... |\n",
      "|  芳华 |   40  |  这场战争活着不如死去 那个年代清醒不如疯魔。倘若这样... |\n",
      "|  芳华 |   20  |            又臭又长 可能是我们这届观众不行...           |\n",
      "|  芳华 |   20  |  冯小刚现在的意义是“我这么牛逼我这些题材都敢拍。”但...  |\n",
      "|  芳华 |   10  | 或许是想与声之形竞争年度喂屎片的位置吧。从霸凌者的角... |\n",
      "|  芳华 |   50  |   【红颜弹指老 刹那芳华】“一个始终不被善待的人 最能...  |\n",
      "|  芳华 |   20  |  文工团解散的时候 我觉得自己好像参加完军训看同学们抱... |\n",
      "|  芳华 |   40  |   7 冯小刚这次应该是走心了 第一次能在他的电影里找到...  |\n",
      "+-------+-------+---------------------------------------------------------+\n",
      "+-------------------------------+-----------+\n",
      "|           word_count          | sentiment |\n",
      "+-------------------------------+-----------+\n",
      "| {'\\xe6\\x88\\x91\\xe4\\xbb\\xac... |     1     |\n",
      "| {'\\xe4\\xb8\\x80\\xe5\\x9c\\xba... |     1     |\n",
      "| {'\\xe4\\xbd\\x86\\xe5\\x86\\xaf... |     1     |\n",
      "| {'\\xe5\\x88\\x98\\xe5\\xb3\\xb0... |     1     |\n",
      "| {'\\xe5\\x8f\\x88\\xe8\\x87\\xad... |     0     |\n",
      "| {'\\xe5\\x86\\xaf\\xe5\\xb0\\x8f... |     0     |\n",
      "| {'\\xe5\\x8d\\x81\\xe5\\xb9\\xb4... |     0     |\n",
      "| {'\\xe6\\x9c\\x89\\xe4\\xba\\x9b... |     1     |\n",
      "| {'\\xe6\\x96\\x87\\xe5\\xb7\\xa5... |     0     |\n",
      "| {'\\xe5\\x86\\xaf\\xe5\\xb0\\x8f... |     1     |\n",
      "+-------------------------------+-----------+\n",
      "[148 rows x 5 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.</pre>"
      ],
      "text/plain": [
       "WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set."
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 127</pre>"
      ],
      "text/plain": [
       "Number of examples          : 127"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 1</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 1"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 668</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 668"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 669</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 669"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 3        | 0.007874  | 0.000000     | 1.000000          | 0.571429            |</pre>"
      ],
      "text/plain": [
       "| 1         | 3        | 0.007874  | 0.000000     | 1.000000          | 0.571429            |"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.002002     | 1.000000          | 0.571429            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.002002     | 1.000000          | 0.571429            |"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.002002     | 1.000000          | 0.571429            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.002002     | 1.000000          | 0.571429            |"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.003003     | 1.000000          | 0.571429            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.003003     | 1.000000          | 0.571429            |"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 8        | 1.000000  | 0.004004     | 1.000000          | 0.571429            |</pre>"
      ],
      "text/plain": [
       "| 5         | 8        | 1.000000  | 0.004004     | 1.000000          | 0.571429            |"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 9        | 1.000000  | 0.004004     | 1.000000          | 0.571429            |</pre>"
      ],
      "text/plain": [
       "| 6         | 9        | 1.000000  | 0.004004     | 1.000000          | 0.571429            |"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is updated and available in a tab in the default browser.\n",
      "本来没有高期待 但还是比预想的差。大段样板戏 情感莫名 想讲大时代 涉及敏感又浅尝辄止 不深刻不入心 这点比潘金莲好不了多少。我是钢炮 但我还是不能钢 可你们要以为我钢着。尤其一段文工团解散戏 涂脂抹粉的脸和僵硬的表情 夸张矫情的歌唱 最难看的群戏。是不是唱《血染的风采》更合适？\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# version python2.7\n",
    "#  构建分类模型-电影评价情感分类器\n",
    "\n",
    "# 下面注释的代码不能使用,使用便报错: No such file or directory\n",
    "# import sys\n",
    "# reload(sys)  \n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "import graphlab\n",
    "import numpy as np\n",
    "\n",
    "#读取电影的评价信息\n",
    "comments = graphlab.SFrame('GraphLabData/Data2.csv')\n",
    "\n",
    "# 对每个评价建立单词计数向量\n",
    "comments['word_count'] = graphlab.text_analytics.count_words(comments['comment'])\n",
    "# comments.head()\n",
    "\n",
    "# 查看文件中电影的分布情况\n",
    "# comments['﻿name'].show()\n",
    "\n",
    "# 观察某一个电影的评价进行分析: 获取数据集中满足name为'芳华'的数据,赋值给movie_reviews\n",
    "movie_reviews = comments[comments['﻿name'] == '芳华']\n",
    "# print (movie_reviews)\n",
    "\n",
    "# 构建情感分类器\n",
    "# comments['score'].show(view = 'Categorical')\n",
    "\n",
    "# 定义正面评价和负面评论: 按照评分判断是正面还是负面,首先要去除中性的评分--30 (满分50)\n",
    "comments = comments[comments['score'] != 30]\n",
    "# print (len(comments))\n",
    "\n",
    "# 正面评价\n",
    "comments['sentiment'] = comments['score']  > 30\n",
    "print (comments)\n",
    "\n",
    "# 训练情感分类器\n",
    "train_data, test_data = comments.random_split(.8, seed = 0)\n",
    "comment_model = graphlab.logistic_classifier.create(train_data, target = 'sentiment', features = ['word_count'], validation_set = test_data)\n",
    "\n",
    "# 进行了6次迭代\n",
    "\n",
    "# 评估情感模型  ROC曲线\n",
    "comment_model.evaluate(test_data, metric = 'roc_curve')\n",
    "comment_model.show(view = 'Evaluation')\n",
    "\n",
    "# 应用模型理解情感\n",
    "movie_reviews['predicted_sentiment'] = comment_model.predict(movie_reviews, output_type = 'probability')\n",
    "# 对预测的情感进行排序(False:降序)\n",
    "movie_reviews = movie_reviews.sort('predicted_sentiment', ascending = False)\n",
    "# 展示情感预测\n",
    "movie_reviews.head()\n",
    "\n",
    "# 查看评论\n",
    "print (movie_reviews[0]['comment']) # 最好\n",
    "print (movie_reviews[-1]['comment']) # 最不好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

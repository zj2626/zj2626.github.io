{"meta":{"title":"ZJ_BLOG","subtitle":"Silence的博客","description":"欢迎来到晋的博客,本博客用来收录平时学习笔记,欢迎访问","author":"一起沉默","url":"http://zj2626.github.io"},"pages":[{"title":"categories","date":"2020-02-19T01:26:08.541Z","updated":"2018-01-13T02:29:22.268Z","comments":true,"path":"categories/index.html","permalink":"http://zj2626.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-02-19T01:26:08.543Z","updated":"2018-01-13T02:29:22.272Z","comments":true,"path":"tags/index.html","permalink":"http://zj2626.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"4.OutOfMemoryError","slug":"20210601001_OutOfMemoryError","date":"2021-05-31T15:01:30.134Z","updated":"2021-05-31T15:36:42.317Z","comments":true,"path":"2021/05/31/20210601001_OutOfMemoryError/","link":"","permalink":"http://zj2626.github.io/2021/05/31/20210601001_OutOfMemoryError/","excerpt":"1. 溢出虚拟机规范中, 除了程序计数器, 其他部分都可能发生OOM异常 2.溢出种类1.Java堆溢出2.虚拟机栈和本地方法栈溢出3.方法去和运行时常量池溢出4.本机直接内存溢出","text":"1. 溢出虚拟机规范中, 除了程序计数器, 其他部分都可能发生OOM异常 2.溢出种类1.Java堆溢出2.虚拟机栈和本地方法栈溢出3.方法去和运行时常量池溢出4.本机直接内存溢出","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"使用多种算法对泰坦尼克号乘客获救原因进行分析","slug":"2018031301","date":"2020-01-15T05:50:39.657Z","updated":"2021-03-10T13:50:15.274Z","comments":true,"path":"2020/01/15/2018031301/","link":"","permalink":"http://zj2626.github.io/2020/01/15/2018031301/","excerpt":"","text":"123import pandastitanic = pandas.read_csv('titanic_train.csv')titanic.head(20) 12# 数据简单统计titanic.describe() 1234# 由表Age列有部分缺失，影响最终模型效果# 解决方法： 填充中位数 (使用fillna()方法填充缺失值NaN， 使用median()获得中位数/中值)titanic['Age'] = titanic['Age'].fillna(titanic['Age'].median())titanic.describe() 123456789101112# 处理原始数据，其中有的是字符量需要映射为数值print (titanic['Sex'].unique())titanic.loc[titanic['Sex'] == 'male', 'Sex'] = 0titanic.loc[titanic['Sex'] == 'female', 'Sex'] = 1print (titanic['Embarked'].unique())titanic['Embarked'] = titanic['Embarked'].fillna('S')# 缺失值填充，填充数量最多的类别titanic.loc[titanic['Embarked'] == 'S', 'Embarked'] = 0titanic.loc[titanic['Embarked'] == 'C', 'Embarked'] = 1titanic.loc[titanic['Embarked'] == 'Q', 'Embarked'] = 2titanic.head() 线性回归 步骤 观察数据，填充缺失值，改变数据形式（数据映射） 使用交叉验证减少过拟合风险 使用线性回归算法计算预测值 确定阈值，计算精度 1234567891011121314151617181920212223242526272829303132333435363738394041# 线性回归from sklearn.linear_model import LinearRegressionfrom sklearn.cross_validation import KFold# 要使用的特征 船仓等级、性别、年龄、兄弟姐妹人数、老人孩子人数、船票价格、上船位置predictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']# 构建线性回归alg = LinearRegression()kf = KFold(titanic.shape[0], n_folds=3, random_state=0)predictions0 = []for train, test in kf: # print (train.shape, test.shape) train_predictors = titanic.loc[train, predictors] train_targets = titanic.loc[train, ['Survived']] print (train_predictors.shape, train_targets.shape) test_features = titanic.loc[test, predictors] # 训练 拟合数据 使用交叉验证拆分出来的训练集 alg.fit(train_predictors, train_targets) # 验证 使用交叉验证拆分出来的验证集 test_predictions = alg.predict(test_features) predictions0.append(test_predictions)# 三组预测值print (len(predictions0), '\\n\\n')import numpy as np# 设定一个阈值 大于阈值表示获救 小于阈值表示未获救predictions = np.concatenate(predictions0, axis=0)predictions[predictions &gt; 0.5] = 1predictions[predictions &lt;= 0.5] = 0print (type(predictions), type(titanic['Survived'].values))print (predictions.shape,titanic['Survived'].values.reshape(-1, 1).shape)accuracy = len(predictions[predictions == titanic['Survived'].values.reshape(-1, 1)]) / len(predictions)print (accuracy) 12345# 随机森林from sklearn import cross_validationfrom sklearn.ensemble import RandomForestClassifierpredictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] 123456789# 构造随机森林# n_estimators：构造的树个数 min_samples_split：最小切分点 min_samples_leaf：叶子节点最小个数alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)# 交叉验证kf = cross_validation.KFold(titanic.shape[0], n_folds=3, random_state=1)# 准确率scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic['Survived'], cv=kf)# 平均准确率print (scores.mean()) 1234567891011121314151617181920212223# 随机森林调优： 修改参数 '''&gt; RandomForestClassifier参数：1. max_features:随机森林允许单个决策树使用特征的最大数量, 增加max_features一般能提高模型的性能,同时降低算法的速度2. n_estimators:在利用最大投票数或平均值来预测之前，想要建立子树的数量。较多的子树可以让模型有更好的性能，但同时让你的代码变慢3. min_sample_leaf:最小样本叶片大小'''#1 构建随机森林模型(分类器)alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=4, min_samples_leaf=10)#2 构建交叉验证kf = cross_validation.KFold(titanic.shape[0], n_folds=3, random_state=1)'''&gt; cross_validation.cross_val_score参数：1. alg:分类器，可以是任何的分类器，比如支持向量机分类器。alg = svm.SVC(kernel='linear', C=1)2. cv：交叉验证（cross validation）方法，如果cv是一个int数字的话，并且如果提供了raw target参数，那么就代表使用StratifiedKFold分类方式，如果没有提供raw target参数，那么就代表使用KFold分类方式。3. raw data,raw target：验证使用的数据（feature以及label）4. 返回值：对于每次不同的的划分raw data时，在test data（验证集）上得到的分类的准确率'''#3 进行交叉验证scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic['Survived'], cv=kf)print (len(scores), '-----', scores.mean(), '-----', scores) 123# 随机森林调优： 添加特征titanic['FamilySize'] = titanic['SibSp'] + titanic['Parch']titanic['NameLength'] = titanic['Name'].apply(lambda x: len(x)) 12345# 特征重要程度import numpy as npfrom sklearn.feature_selection import SelectKBest,f_classifimport matplotlib.pyplot as pltpredictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'NameLength'] Univariate feature selection：单变量的特征选择单变量特征选择的原理是分别单独的计算每个变量的某个统计指标，根据该指标来判断哪些指标重要。剔除那些不重要的指标。 sklearn.feature_selection模块中主要有以下几个方法： SelectKBest和SelectPercentile比较相似，前者选择排名排在前n个的变量，后者选择排名排在前n%的变量。而他们通过什么指标来给变量排名呢？这需要二外的指定。 对于regression问题，可以使用f_regression指标。对于classification问题，可以使用chi2或者f_classif变量。 使用的例子：12from sklearn.feature_selectionimport SelectPercentile, f_classifselector =SelectPercentile(f_classif, percentile=10) Recursive feature elimination：循环特征选择不单独的检验某个变量的价值，而是将其聚集在一起检验。它的基本思想是，对于一个数量为d的feature的集合，他的所有的子集的个数是2的d次方减1（包含空集）。指定一个外部的学习算法，比如SVM之类的。通过该算法计算所有子集的validationerror。选择error最小的那个子集作为所挑选的特征。 由以下两个方法实现：sklearn.feature_selection.RFE，sklearn.feature_selection.RFECV L1-based featureselection：该思路的原理是：在linearregression模型中，有的时候会得到sparsesolution。意思是说很多变量前面的系数都等于0或者接近于0。这说明这些变量不重要，那么可以将这些变量去除。 Tree-based featureselection：决策树特征选择基于决策树算法做出特征选择 123456789selector = SelectKBest(f_classif, k=5)selector.fit(titanic[predictors], titanic['Survived'])scores = -np.log10(selector.pvalues_)print (scores)plt.bar(range(len(predictors)), scores)plt.xticks(range(len(predictors)), predictors, rotation='vertical')plt.show() 12345678910111213141516171819202122232425262728293031323334353637383940414243# 多种算法集成预测from sklearn.ensemble import GradientBoostingClassifierfrom sklearn.linear_model import LogisticRegressionimport numpy as np# 两个算法集成到一起使用algorithms = [ [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'FamilySize']], [LogisticRegression(random_state=1), ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]]kf = KFold(titanic.shape[0], n_folds=3, random_state=1)predictions = []# 两个算法分别预测for train, test in kf: train_target = titanic.loc[train, ['Survived']] full_test_predictions = [] # 循环分类算法，获得不同算法求得的概率 for alg, predictors in algorithms: # alg：分类算法 predictors：特征 # 使用训练集 拟合数据 alg.fit(titanic.loc[train, predictors], train_target) # 使用验证集 计算 (这里 直接取预测的概率的第二个值--&gt;[:, 1]) test_predictions = alg.predict_proba(titanic.loc[test, predictors].astype(float))[:, 1] full_test_predictions.append(test_predictions) # 使用不同的分类算法之后计算平均概率 test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2 test_predictions[test_predictions &lt;= 0.5] = 0 test_predictions[test_predictions &gt; 0.5] = 1 predictions.append(test_predictions)# 获得的分类结果predictions = np.concatenate(predictions, axis=0)# 计算精确度accuracy = len(predictions[predictions == titanic['Survived']]) / len(predictions)print (accuracy) 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://zj2626.github.io/categories/机器学习/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"http://zj2626.github.io/tags/机器学习/"}]},{"title":"关于使用sklearn进行数据预处理-归一化/标准化/正则化(转)","slug":"2018031202","date":"2020-01-15T05:50:39.656Z","updated":"2021-03-10T15:20:21.767Z","comments":true,"path":"2020/01/15/2018031202/","link":"","permalink":"http://zj2626.github.io/2020/01/15/2018031202/","excerpt":"","text":"一、标准化（Z-Score），或者去除均值和方差缩放公式为：(X-mean)/std 计算时对每个属性/每列分别进行。 将数据按期属性（按列进行）减去其均值，并处以其方差。得到的结果是，对于每个属性/每列来说所有数据都聚集在0附近，方差为1。 实现时，有两种不同的方式： 使用sklearn.preprocessing.scale()函数，可以直接将给定数据进行标准化。 123456789101112131415161718&gt;&gt;&gt; from sklearn import preprocessing&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; X = np.array([[ 1., -1., 2.],... [ 2., 0., 0.],... [ 0., 1., -1.]])&gt;&gt;&gt; X_scaled = preprocessing.scale(X) &gt;&gt;&gt; X_scaled array([[ 0. ..., -1.22..., 1.33...], [ 1.22..., 0. ..., -0.26...], [-1.22..., 1.22..., -1.06...]]) &gt;&gt;&gt;#处理后数据的均值和方差&gt;&gt;&gt; X_scaled.mean(axis=0)array([ 0., 0., 0.]) &gt;&gt;&gt; X_scaled.std(axis=0)array([ 1., 1., 1.]) 使用sklearn.preprocessing.StandardScaler类，使用该类的好处在于可以保存训练集中的参数（均值、方差）直接使用其对象转换测试集数据。12345678910111213141516171819&gt;&gt;&gt; scaler = preprocessing.StandardScaler().fit(X)&gt;&gt;&gt; scalerStandardScaler(copy=True, with_mean=True, with_std=True) &gt;&gt;&gt; scaler.mean_ array([ 1. ..., 0. ..., 0.33...]) &gt;&gt;&gt; scaler.std_ array([ 0.81..., 0.81..., 1.24...]) &gt;&gt;&gt; scaler.transform(X) array([[ 0. ..., -1.22..., 1.33...], [ 1.22..., 0. ..., -0.26...], [-1.22..., 1.22..., -1.06...]]) &gt;&gt;&gt;#可以直接使用训练集对测试集数据进行转换&gt;&gt;&gt; scaler.transform([[-1., 1., 0.]]) array([[-2.44..., 1.22..., -0.26...]]) 二、将属性缩放到一个指定范围除了上述介绍的方法之外，另一种常用的方法是将属性缩放到一个指定的最大和最小值（通常是1-0）之间，这可以通过preprocessing.MinMaxScaler类实现。 使用这种方法的目的包括： 对于方差非常小的属性可以增强其稳定性。 维持稀疏矩阵中为0的条目 123456789101112131415161718192021222324&gt;&gt;&gt; X_train = np.array([[ 1., -1., 2.],... [ 2., 0., 0.],... [ 0., 1., -1.]])...&gt;&gt;&gt; min_max_scaler = preprocessing.MinMaxScaler()&gt;&gt;&gt; X_train_minmax = min_max_scaler.fit_transform(X_train)&gt;&gt;&gt; X_train_minmaxarray([[ 0.5 , 0. , 1. ], [ 1. , 0.5 , 0.33333333], [ 0. , 1. , 0. ]]) &gt;&gt;&gt; #将相同的缩放应用到测试集数据中&gt;&gt;&gt; X_test = np.array([[ -3., -1., 4.]])&gt;&gt;&gt; X_test_minmax = min_max_scaler.transform(X_test)&gt;&gt;&gt; X_test_minmaxarray([[-1.5 , 0. , 1.66666667]]) &gt;&gt;&gt; #缩放因子等属性&gt;&gt;&gt; min_max_scaler.scale_ array([ 0.5 , 0.5 , 0.33...]) &gt;&gt;&gt; min_max_scaler.min_ array([ 0. , 0.5 , 0.33...]) 当然，在构造类对象的时候也可以直接指定最大最小值的范围：feature_range=(min, max)，此时应用的公式变为： X_std=(X-X.min(axis=0))/(X.max(axis=0)-X.min(axis=0)) X_scaled=X_std/(max-min)+min 三、正则化（Normalization）正则化的过程是将每个样本缩放到单位范数（每个样本的范数为1），如果后面要使用如二次型（点积）或者其它核方法计算两个样本之间的相似性这个方法会很有用。 Normalization主要思想是对每个样本计算其p-范数，然后对该样本中每个元素除以该范数，这样处理的结果是使得每个处理后样本的p-范数（l1-norm,l2-norm）等于1。 p-范数的计算公式：||X||p=(|x1|^p+|x2|^p+...+|xn|^p)^1/p 该方法主要应用于文本分类和聚类中。例如，对于两个TF-IDF向量的l2-norm进行点积，就可以得到这两个向量的余弦相似性。 可以使用preprocessing.normalize()函数对指定数据进行转换： 123456789&gt;&gt;&gt; X = [[ 1., -1., 2.],... [ 2., 0., 0.],... [ 0., 1., -1.]]&gt;&gt;&gt; X_normalized = preprocessing.normalize(X, norm='l2') &gt;&gt;&gt; X_normalized array([[ 0.40..., -0.40..., 0.81...], [ 1. ..., 0. ..., 0. ...], [ 0. ..., 0.70..., -0.70...]]) 可以使用processing.Normalizer()类实现对训练集和测试集的拟合和转换： 123456789101112&gt;&gt;&gt; normalizer = preprocessing.Normalizer().fit(X) # fit does nothing&gt;&gt;&gt; normalizerNormalizer(copy=True, norm='l2') &gt;&gt;&gt;&gt;&gt;&gt; normalizer.transform(X) array([[ 0.40..., -0.40..., 0.81...], [ 1. ..., 0. ..., 0. ...], [ 0. ..., 0.70..., -0.70...]]) &gt;&gt;&gt; normalizer.transform([[-1., 1., 0.]]) array([[-0.70..., 0.70..., 0. ...]]) 补充： 转载来自这里 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"http://zj2626.github.io/tags/机器学习/"}]},{"title":"scikit-learn数据预处理fit_transform()与transform()的区别(转)","slug":"2018031201","date":"2020-01-15T05:50:39.654Z","updated":"2021-03-10T13:50:15.349Z","comments":true,"path":"2020/01/15/2018031201/","link":"","permalink":"http://zj2626.github.io/2020/01/15/2018031201/","excerpt":"问题：scikit-learn中fit_transform()与transform()到底有什么区别，能不能混用？","text":"问题：scikit-learn中fit_transform()与transform()到底有什么区别，能不能混用？ 二者的功能都是对数据进行某种统一处理（比如标准化~N(0,1)，将数据缩放(映射)到某个固定区间，归一化，正则化等） fit_transform(partData)对部分数据先拟合fit，找到该part的整体指标，如均值、方差、最大值最小值等等（根据具体转换的目的），然后对该partData进行转换transform，从而实现数据的标准化、归一化等等。。 根据对之前部分fit的整体指标，对剩余的数据（restData）使用同样的均值、方差、最大最小值等指标进行转换transform(restData)，从而保证part、rest处理方式相同。 必须先用fit_transform(partData)，之后再transform(restData) 如果直接transform(partData)，程序会报错 如果fit_transfrom(partData)后，使用fit_transform(restData)而不用transform(restData)，虽然也能归一化，但是两个结果不是在同一个“标准”下的，具有明显差异。 实验：使用preprocessing.MinMaxScaler()对象对数据进行归一化。原理是：(x-xMin)/(xMax - xMin)，从而将所有数据映射到【0,1】区间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import numpy as np from sklearn.preprocessing import MinMaxScalerdata = np.array(np.random.randint(-100,100,24).reshape(6,4))dataOut[55]: array([[ 68, -63, -31, -10], [ 49, -49, 73, 18], [ 46, 65, 75, -78], [-72, 30, 90, -80], [ 95, -88, 79, -49], [ 34, -81, 57, 83]])train = data[:4]test = data[4:]trainOut[58]: array([[ 68, -63, -31, -10], [ 49, -49, 73, 18], [ 46, 65, 75, -78], [-72, 30, 90, -80]])testOut[59]: array([[ 95, -88, 79, -49], [ 34, -81, 57, 83]])minmaxTransformer = MinMaxScaler(feature_range=(0,1))#先对train用fit_transformer(),包括拟合fit找到xMin,xMax,再transform归一化train_transformer = minmaxTransformer.fit_transform(train)#根据train集合的xMin，xMax,对test集合进行归一化transform.#(如果test中的某个值比之前的xMin还要小，依然用原来的xMin；同理如果test中的某个值比之前的xMax还要大，依然用原来的xMax.#所以，对test集合用同样的xMin和xMax，**有可能不再映射到【0,1】**)test_transformer = minmaxTransformer.transform(test)train_transformerOut[64]: array([[ 1. , 0. , 0. , 0.71428571], [ 0.86428571, 0.109375 , 0.85950413, 1. ], [ 0.84285714, 1. , 0.87603306, 0.02040816], [ 0. , 0.7265625 , 1. , 0. ]])test_transformerOut[65]: array([[ 1.19285714, -0.1953125 , 0.90909091, 0.31632653], [ 0.75714286, -0.140625 , 0.72727273, 1.66326531]])#如果少了fit环节，直接transform(partData),则会报错minmaxTransformer = MinMaxScaler(feature_range=(0,1))train_transformer2 = minmaxTransformer.transform(train)Traceback (most recent call last): File \"&lt;ipython-input-68-a2aeaf2132be&gt;\", line 1, in &lt;module&gt; train_transformer2 = minmaxTransformer.transform(train) File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\", line 352, in transform check_is_fitted(self, 'scale_') File \"D:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 690, in check_is_fitted raise _NotFittedError(msg % &#123;'name': type(estimator).__name__&#125;)NotFittedError: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.#如果对test也用fit_transform(),则结果跟之前不一样。对于许多机器学习算法来说，对于train和test的处理应该统一。test_transformer2 = minmaxTransformer.fit_transform(test)test_transformer2Out[71]: array([[ 1., 0., 1., 0.], [ 0., 1., 0., 1.]])test_transformerOut[72]: array([[ 1.19285714, -0.1953125 , 0.90909091, 0.31632653], [ 0.75714286, -0.140625 , 0.72727273, 1.66326531]]) 转载来自这里 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"http://zj2626.github.io/tags/机器学习/"}]},{"title":"构建逻辑回归模型实例","slug":"2018030701","date":"2020-01-15T05:50:39.653Z","updated":"2021-03-10T15:20:21.722Z","comments":true,"path":"2020/01/15/2018030701/","link":"","permalink":"http://zj2626.github.io/2020/01/15/2018030701/","excerpt":"","text":"逻辑回归 逻辑回归是应用非常广泛的一个分类机器学习算法，它将数据拟合到一个logit函数(或者叫做logistic函数)中，从而能够完成对事件发生的概率进行预测。 构建逻辑回归模型步骤： 导入数据 预处理数据 对不平衡的数据进行下采样（或者过采样）处理 把处理之后的数据进行切分，切分为训训练集和测试集 对训练集进行交叉验证，同时寻找最佳的正则化参数以减少过拟合 使用最佳的正则化参数对处理之后的数据进行训练并预测，观察召回率和精确率 使用最佳的正则化参数对处理之后的数据进行训练并预测，观察召回率和精确率 修改阈值以获得更好的召回率和精确率 1. 数据与任务信用卡欺诈数据12345678import pandas as pdimport matplotlib.pyplot as pltimport numpy as np%matplotlib inlinedata = pd.read_csv(\"creditcard.csv\")data.head() 要使用逻辑回归对数据进行建模 任务：二分类， 把数据分为有欺诈和无欺诈的两种数据2. 使用sklearn进行数据预处理 公式为：(X-mean)/std 计算时对每个属性/每列分别进行。 Standardization标准化:将特征数据的分布调整成标准正太分布，也叫高斯分布，也就是使得数据的均值维0，方差为1 标准化的原因在于如果有些特征的方差过大，则会主导目标函数从而使参数估计器无法正确地去学习其他特征。 标准化的过程为两步：去均值的中心化（均值变为0）；方差的规模化（方差变为1）。 在sklearn.preprocessing中提供了一个scale的方法，可以实现以上功能。如下面所示: 123456x = np.array([[1., -1., 2.], [2., 0., 0.], [0., 1., -1.]])# 将每一列特征标准化为标准正太分布，注意，标准化是针对每一列而言的x_scale = preprocessing.scale(x)x_scale preprocessing这个模块还提供了一个实用类StandarScaler，它可以在训练数据集上做了标准转换操作之后，把相同的转换应用到测试训练集中。可以对训练数据，测试数据应用相同的转换，以后有新的数据进来也可以直接调用，不用再重新把数据放在一起再计算一次了。 123456789# 调用fit方法，根据已有的训练数据创建一个标准化的转换器scaler = preprocessing.StandardScaler().fit(x)scalerStandardScaler(copy=True, with_mean=True, with_std=True)# 使用上面这个转换器去转换训练数据x,调用transform方法scaler.transform(x) StandardScaler()中可以传入两个参数：with_mean,with_std.这两个都是布尔型的参数，默认情况下都是true,但也可以自定义成false.即不要均值中心化或者不要方差规模化为1. 1. 处理数据 数据下采样1.1 预处理数据,修改列”Amount”数据分布1234567# 导入预处理sklearn中预处理模块的标准化模块from sklearn.preprocessing import StandardScalerif 'Amount' in data.columns: # 转化特征为新的特征 data['normAount'] = StandardScaler().fit_transform(data['Amount'].reshape(-1, 1)) # reshape:改变数组的形状,参数为改变后的行列数 # fit_transform：对数据进行变换 矩阵旋转：-1表示自动识别 根据另一个矩阵列（行）数确定本行（列）数 1.2 数据处理,去除不需要的特征12345678910111213141516171819# 去掉两个没用的特征（列） axis=1表示对每一行去做这个操作，axis=0表示对每一列做相同的这个操作if ('Time') in data.columns: data = data.drop(['Time'], axis=1) if ('Amount') in data.columns: data = data.drop(['Amount'], axis=1) print(data.columns, len(data.columns))# 1.2.1 数据图形化展示(1的数据太少索引看上去没有)count_classes = pd.value_counts(data['Class'], sort=True).sort_index() # 画图显示按某列分类之后的数据数量比例count_classes.plot(kind = 'bar') # bar：条形图plt.xlabel(\"Class\")plt.ylabel(\"Frequency\")# 1.2.2 原数据特征和分类X = data.loc[:, data.columns != \"Class\"]y = data.loc[:, data.columns == 'Class']print (\"SHAPE\", X.shape, y.shape)# Class为0的数量远远大于1的数据，需要使数据个数相近 解决方案： 1.下采样（多的数据抽取部分） 2.过采样（少的数据生成更多） 3.下采样 把数据相对多的减少,可减少为和数据少的数量相同的数量 1.3 区分正常数据和异常数据: 通过特征’Class’区分1234567891011121314# 1.3.1 异常数据-信息number_records = data[data.Class == 1]# 1.3.2 异常数据个数number_records_fraud = len(number_records)# 1.3.3 异常数据索引frand_indices = np.array(number_records.index)print (\"异常样本索引 有&#123;&#125;个\".format(number_records_fraud), frand_indices[:10])# 1.3.4 正常数据-索引normal_indices = data[data.Class == 0].indexprint (\"正常样本索引 有&#123;&#125;个\".format(len(normal_indices)), normal_indices[-10:])print (\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;所有数据 正常异常比 \", len(normal_indices), '\\t', number_records_fraud)print(\"**************\") 1.4 下采样处理数据 把多的一方数据进行随机减少到与少的一方相同12345# 在所有的正常样本索引normal_indices中随机获取，随机选取number_records_fraud个# np.random.choice: 可以从一个int数字或1维array里随机选取内容，并将选取结果放入n维array中返回。random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace=False)random_normal_indices = np.array(random_normal_indices)print (\"'下采样'后有正常样本个数：\", len(random_normal_indices)) 1.5 数据索引合并 (意思就是把新的正常数据和原来的异常数据进行拼接)123456under_sample_indices = np.concatenate([frand_indices, random_normal_indices])print (\"合并后有样本个数：\", len(under_sample_indices))under_sample_data = data.iloc[under_sample_indices, :]print (\"合并后样本：\", under_sample_data[:1])print (\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;下采样数据 正常异常比 \", len(under_sample_data[under_sample_data == 0]), '\\t', len(under_sample_data[under_sample_data == 1])) 1.6 获取合并数据中的feature(特征)和label(分类)12345X_undersample = under_sample_data.loc[:, under_sample_data.columns != 'Class']y_undersample = under_sample_data.loc[:, under_sample_data.columns == 'Class']print (X_undersample.shape, y_undersample.shape)print (len(under_sample_data[under_sample_data[\"Class\"] == 1]), len(under_sample_data[under_sample_data[\"Class\"] == 0])) 2. 切分数据为训练和测试1234567891011121314151617# 切分原始数据 取数据集中80%的数据作为训练集（建立model） 其他20%的为测试集(测试model)from sklearn.cross_validation import train_test_splitprint (X.shape, y.shape)## 2.1.对原始数据进行切分 （最终需要使用原数据集中的测试数据进行测试）X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) # test_size测试集所占比例 random_state切分之前进行乱序print (\"1.训练集数据大小\", X_train.shape)print (\"2.测试集数据大小\", X_test.shape)print (len(X_train) + len(X_test), len(y_train), len(y_test), \"\\n\")## 2.2.对下采样数据进行切分X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample, y_undersample, test_size=0.2, random_state=0) # test_size测试集大小 random_state切分之前进行乱序print (\"3.训练集数据大小\", X_train_undersample.shape)print (\"4.测试集数据大小\", X_test_undersample.shape)print (len(X_train_undersample) + len(X_test_undersample), len(y_train_undersample), len(y_test_undersample), \"\\n\")# 切分训练集 把训练集平均切分为三分然后进行交叉验证 （三组数据分别进行建模和验证） 评估标准：召回率（recall）不适用准确率，因为准确率不能正确的得到所求的，是没用的 模型评估表： 相关（Relevant），正类 不相关（NonRelevant），负类 被检测到（Retrieved） true positives （TP） false positives （FP） 未被检测到（Retrieved） false negatives （FN） true negatives （TN） 一些术语： TP：True Positive，即正确预测出的正样本个数 FP：False Positive，即错误预测出的正样本个数（本来是负样本，被我们预测成了正样本） TN：True Negative，即正确预测出的负样本个数 FN：False Negative，即错误预测出的负样本个数（本来是正样本，被我们预测成了负样本） 分类器性能评价指标由以上四个指标，可以进一步衍生出其他三个常用的评价分类器性能的指标 Precision(精确率)：TP÷(TP+FP)TP÷(TP+FP)，分类器预测出的正样本中，真实正样本的比例 Recall(召回率)：TP÷(TP+FN)TP÷(TP+FN)，在所有真实正样本中，分类器中能找到多少 Accuracy(准确率)：(TP+TN)÷(TP+NP+TN+FN)(TP+TN)÷(TP+NP+TN+FN)，分类器对整体的判断能力，即正确预测的比例 过拟合： 数据在训练集表现很好 在测试集表现很差 1234from sklearn.linear_model import LogisticRegression # 逻辑回归# 注意这里导入的 不是from sklearn.model_selection import KFoldfrom sklearn.cross_validation import KFold # 交叉验证 # cross_val_scorefrom sklearn.metrics import confusion_matrix, recall_score, classification_report # 混淆矩阵 3. 通过多次循环交叉验证 确定正则化参数 random_state：随机种子数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960def printing_Kfold_scores(x_train_data, y_train_data): # KFold：切分数据集 （这里切分为5部分） shuffle:是否每次都\"洗牌\"(Falses时，其效果等同于random_state等于整数，每次划分的结果相同) fold = KFold(len(y_train_data), 5, shuffle=False) print (type(fold), len(y_train_data), len(fold)) # 长度是5 # 正则化惩罚项(正则化参数) 预设了多个惩罚值，具体使用哪个需要尝试 列举了5个 c_param_range = [0.01, 0.1, 1, 10, 100] # 新建DataFrame类型的数据用来存放不同正则化之后的结果 results_table = pd.DataFrame(index = range(len(c_param_range)), columns = ['C_parameter', 'Mean recall score']) results_table['C_parameter'] = c_param_range # 先按照正则化参数进行循环以确定最好的参数 然后对每个逻辑回归进行交叉验证以获得最好的逻辑回归函数 # 循环正则化参数 获取最好的c参数 for index, c_param in enumerate(c_param_range): print (\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\") print (\"C_parameter \", c_param) recall_accs = [] # 循环进行交叉验证 # 每次循环次数为数据切分的大小,切分为n块就交叉验证n次,每次都是区其中n-1块为训练集1块为验证集 # start=1:开始索引为1 # iteration为索引 indices为划分好的数据:其中有n-1数据大小的训练集以及1数据代销的验证集 # 循环中集合每次都不一样,所有的数据都会当一次验证集:例如 三个数据[1,2,3],循环使得数据分别为训练和验证每次为:[[1],[2, 3]], [[2],[1, 3]], [[3],[1, 2]] for iteration, indices in enumerate(fold, start=1): # 这里并不是用fold直接划分训练集数据, 而是把索引进行1:5的划分, 然后按照索引获取数据中的对应的数据 print (iteration, len(indices[0]), len(indices[1])) # 建立逻辑回归模型 lr = LogisticRegression(C = c_param, penalty = 'l1') # C:正则化参数; penalty:惩罚项:使用L1正则化(惩罚) ‘l1’ or ‘l2’(默认: ‘l2’) # 在调参时如果我们主要的目的只是为了解决过拟合，一般penalty选择L2正则化就够了。 # 但是如果选择L2正则化发现还是过拟合，即预测效果差的时候，就可以考虑L1正则化。 # 另外，如果模型的特征非常多，我们希望一些不重要的特征系数归零，从而让模型系数稀疏化的话，也可以使用L1正则化。 # print (\"LR-逻辑回归表达式---\", lr) # 训练 参数一:训练数据特征(feature) 参数二:训练数据分类(label) lr.fit(x_train_data.iloc[indices[0],:], y_train_data.iloc[indices[0],:].values.ravel()) # 预测 y_pred_undersample = lr.predict(x_train_data.iloc[indices[1], :].values) # 计算召回率 召回率 =提取出的正确信息条数 /样本中的信息条数。通俗地说，就是所有准确的条目有多少被检索出来了。 # 参数: 1.真实数据集 2.预测数据集 recall_acc = recall_score(y_train_data.iloc[indices[1],:].values, y_pred_undersample) recall_accs.append(recall_acc) print (len(indices), \"Iteration \", iteration, \": recall score = \", recall_acc) # 求每个惩罚值经过交叉验证之后平均召回率 results_table.loc[index, 'Mean recall score'] = np.mean(recall_accs) print ('\\nMean recall score ', np.mean(recall_accs), '\\n') print (results_table) best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter'] print (\"finally-------best is--------&gt; \", best_c) return best_cbest_c = printing_Kfold_scores(X_train_undersample, y_train_undersample) ndarray数据格式化: set_printoptions set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, suppress=None, nanstr=None, infstr=None, formatter=None) precision:输出结果保留精度的位数 (num) threshold:array数量的个数在小于threshold的时候不会被折叠 (num) edgeitems:在array已经被折叠后，开头和结尾都会显示edgeitems个数 (num) formatter:这个很有意思，像python3里面str.format(),就是可以对你的输出进行自定义的格式化 其他的暂时没用到 4. 使用最好的正则化参数 构建逻辑回归模型并进行测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 构建逻辑回归模型lr = LogisticRegression(C = best_c, penalty='l1')# 训练回归模型lr.fit(X_train_undersample, y_train_undersample.values.ravel())# 使用模型进行测试y_pred_undersample = lr.predict(X_test_undersample.values)# y_pred_undersample为预测(分类)值, y_test_undersample为真实测试集的(分类)值print (type(y_pred_undersample), len(y_pred_undersample), \"\\n\")# 打印和绘制混淆矩阵import itertoolsdef plot_confusion_matrix(cm, classes, title='Confussion matrix', cmap=plt.cm.Blues): #设置显示混淆矩阵 plt.imshow(cm, interpolation='nearest', cmap=cmap) plt.title(title) plt.colorbar() # 设置坐标数 tick_marks = np.arange(len(classes)) plt.xticks(tick_marks, classes, rotation=0) plt.yticks(tick_marks, classes) thresh = cm.max() / 2 # itertools.product可进行多层次循环 传入参数个数(n)和索引个数相同 可循环n^2次 # 设置每个方块中的文字 for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): # print (j, i, cm[i, j]) # 因为i表示横坐标的位置, j表示纵坐标的位置 所以需要把i和j交换位置 plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] &gt; thresh else \"black\") plt.tight_layout() # 设置坐标文字 plt.ylabel(\"True label\") # 真实数据 plt.xlabel(\"Predicted label\") # 预测数据 1表示正例 0表示负例# 画混淆矩阵图 参数: 1.y_true, 2.y_predcnf_matrix = confusion_matrix(y_test_undersample, y_pred_undersample)np.set_printoptions(precision=2)print (\"Recall metric in the testing dataset: \", cnf_matrix[1, 1]/(cnf_matrix[1, 0] + cnf_matrix[1, 1]))class_names = [0, 1]plt.figure()plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')plt.show()# 由图可见, 召回率为 85 / (85 + 6) = 93.41%# 精确率为 (85) / (85 + 9) = 90.43%# 准确率为 (85 + 97) / (85 + 9 + 6 + 97) = 92.39%# 以上计算都是基于下采样数据集的,还需要在原数据的测试集上进行测试操作 (与上面同理) 4. 使用最好的正则化参数 构建逻辑回归模型并进行测试 (使用原始数据的测试集和训练集)12345678910111213141516# 在原数据的测试集上进行测试操作lr = LogisticRegression(C = best_c, penalty='l1')lr.fit(X_train, y_train.values.ravel())y_pred = lr.predict(X_test.values)# y_pred为预测(分类)值, y_test为真实测试集的(分类)值cnf_matrix = confusion_matrix(y_test, y_pred)np.set_printoptions(precision=2)print (\"Recall metric in the testing dataset: \", cnf_matrix[1, 1]/(cnf_matrix[1, 0] + cnf_matrix[1, 1]))class_names = [0, 1]plt.figure()plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')plt.show() 5. 修改阈值以获取最好的逻辑回归模型12345678910111213141516171819202122232425262728# 阈值: 默认使用sigma函数默认值:0.5, 意思是当预测概率大于0.5表示True,概率小鱼0.5表示Falselr = LogisticRegression(C = best_c, penalty='l1')# 训练lr.fit(X_train, y_train.values.ravel())# 预测 这里是预测概率值 每个数据的预测包含两个值，对于二分类问题，也就是被判断为0的概率和被判断为1的概率y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values) # 预测概率值而不是类别值# 可能的阈值thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]plt.figure(figsize=(10, 10)) # 画图域for index, i in enumerate(thresholds): # 预测概率 y_test_predictions_high_recall = y_pred_undersample_proba[:, 1] &gt; i plt.subplot(3, 3, index + 1) cnf_matrix = confusion_matrix(y_test_undersample, y_test_predictions_high_recall) np.set_printoptions(precision=2) print (i, \"Recall metric in the testing dataset: \", cnf_matrix[1, 1] / (cnf_matrix[1, 0] + cnf_matrix[1, 1])) class_names = [0, 1] plot_confusion_matrix(cnf_matrix, classes=class_names, title=\"Threshold &gt;= %s\" %i) ## 随着阈值上升 召回率不断变化 其中本来是1的被误检测为0的越来越多 可见 要选取最合适的阈值以达到召回率最高 过采样 把数据相对少的增加,可增加为和数据多的数量相同的数量 (生成) 12345678910111213141516import pandas as pdfrom imblearn.over_sampling import SMOTEfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.metrics import confusion_matrixfrom sklearn.model_selection import train_test_splitcredit_cards = pd.read_csv(\"creditcard.csv\")columns = credit_cards.columnsfeatures_columns = columns.delete(len(columns) - 1) #删除最后一列数据print (features_columns)features = credit_cards[features_columns]labels = credit_cards['Class']print (\"原始的数据个数\", (credit_cards[credit_cards['Class'] == 0]).shape, (credit_cards[credit_cards['Class'] == 1]).shape) 12features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=0)print (features_train.shape, features_test.shape, labels_train.shape, labels_test.shape) 12345678oversampler = SMOTE(random_state = 0) # SMOTE随机生成数据 生成只能是训练集生成数据, 而测试集不生成# 只生成训练集数据 使得Class为1和为0的数量相同 返回训练集的特征和分类os_features, os_labels = oversampler.fit_sample(features_train, labels_train)print (\"可见 的确生成了新的数据,补充了异常的数据 \", len(os_labels[os_labels[:] == 1]), len(os_labels[os_labels[:] == 0]))print ((os_features).shape, len(os_features[os_features == 1]), len(os_features[os_features == 0]), (os_labels).shape, len(os_labels[os_labels == 1]), len(os_labels[os_labels == 0])) 123456os_features = pd.DataFrame(os_features)os_labels = pd.DataFrame(os_labels)# 获取最佳参数best_c = printing_Kfold_scores(os_features, os_labels)# plot_confusion_matrix 1234567891011121314151617lr = LogisticRegression(C = best_c, penalty='l1')# 训练 使用生成的数据lr.fit(os_features, os_labels.values.ravel())# 使用真实数据测试y_pred = lr.predict(features_test.values)# 打印和绘制混淆矩阵cnf_matrix = confusion_matrix(labels_test, y_pred)np.set_printoptions(precision=2)print (\"Recall metric in the testing dataset: \", cnf_matrix[1, 1] / (cnf_matrix[1, 0] + cnf_matrix[1, 1]))class_names = [0, 1]plt.figure()plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')plt.show() 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://zj2626.github.io/categories/机器学习/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"http://zj2626.github.io/tags/机器学习/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"http://zj2626.github.io/tags/逻辑回归/"}]},{"title":"正则表达式","slug":"20171225_regular","date":"2020-01-15T05:50:39.652Z","updated":"2021-03-10T13:50:15.287Z","comments":true,"path":"2020/01/15/20171225_regular/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20171225_regular/","excerpt":"","text":"正则表达式： waiting。。。 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"正则","slug":"正则","permalink":"http://zj2626.github.io/categories/正则/"}],"tags":[{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"},{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"正则表达式","slug":"正则表达式","permalink":"http://zj2626.github.io/tags/正则表达式/"}]},{"title":"Python 爬虫实战（4）","slug":"20171222_crawler4","date":"2020-01-15T05:50:39.650Z","updated":"2021-03-10T13:50:15.382Z","comments":true,"path":"2020/01/15/20171222_crawler4/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20171222_crawler4/","excerpt":"多线程 待添加 条件变量 condition","text":"多线程 待添加 条件变量 condition 个人代码：1234567891011121314151617181920212223242526272829303132333435363738394041#生产者消费者import threading # , _thread ()python2x是threadimport timeimport queue #python2x是Queueimport randommutex = threading.Lock() #等价于_thread.allocate_lock()，也等价于_thread.allocate()myq = queue.Queue(10)num = range(10)class Producer(threading.Thread): def run(self): global myq, num for i in range(30): time.sleep(0.3) if not myq.full() and mutex.acquire(): info = random.choice(num) myq.put(info) print(\"put in data: \", info, \"; queue size\", myq.qsize()) mutex.release()class Consumer(threading.Thread): def run(self): global myq, num for i in range(30): time.sleep(1) if not myq.empty() and mutex.acquire(): info = myq.get() print(\"get out data: \", info, \"; queue size\", myq.qsize()) mutex.release()def main(): print ('main') p = Producer() c = Consumer() p.start() c.start()if __name__ == '__main__': main() 别人家的代码【滑稽】：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/usr/bin/env python# -*- coding:utf-8 -*-import thread, threadingimport urllib2import time, randomimport Queueshare_queue = Queue.Queue() #共享队列my_lock = thread.allocate_lock()class Producer(threading.Thread) : def run(self) : products = range(5) global share_queue while True : num = random.choice(products) my_lock.acquire() share_queue.put(num) print \"Produce : \", num my_lock.release() time.sleep(random.random())class Consumer(threading.Thread) : def run(self) : global share_queue while True: my_lock.acquire() if share_queue.empty() : #这里没有使用信号量机制进行阻塞等待, print \"Queue is Empty...\" my_lock.release() time.sleep(random.random()) continue num = share_queue.get() print \"Consumer : \", num my_lock.release() time.sleep(random.random())def main() : producer = Producer() consumer = Consumer() producer.start() consumer.start()if __name__ == '__main__': main() 转载自 链接地址: http://www.jianshu.com/p/86b8e78c418a 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://zj2626.github.io/categories/爬虫/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://zj2626.github.io/tags/爬虫/"}]},{"title":"TypeError, a bytes-like object is required, not 'str'","slug":"20171219_python_error","date":"2020-01-15T05:50:39.649Z","updated":"2021-03-10T15:20:21.688Z","comments":true,"path":"2020/01/15/20171219_python_error/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20171219_python_error/","excerpt":"问题分析: 该问题主要是由于当前操作的字符串是bytes类型的字符串对象，并对该bytes类型的字符串对象进行按照str类型的操作。 解决办法，将s转码成为str类型","text":"问题分析: 该问题主要是由于当前操作的字符串是bytes类型的字符串对象，并对该bytes类型的字符串对象进行按照str类型的操作。 解决办法，将s转码成为str类型 str和bytes类型之间的常用转码方式 str to bytes 1234567891011s = 'ab bbb'print (type(s))b = bytes(s, encoding = 'utf-8')print (type(b))b2 = s.encode('utf-8')print (type(b2))b3 = str.encode(s)print (type(b3)) bytes to str 12345678910111213141516b = b'abbbb'print (type(b))s = str(b, encoding = 'utf-8')print (type(s))s2 = b.decode()print (type(s2))s3 = b.decode('utf-8')print (type(s3))s4 = bytes.decode(b)print (type(s4)) 转载自 链接地址: http://blog.csdn.net/bible_reader/article/details/53047550 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"BUG解决","slug":"BUG解决","permalink":"http://zj2626.github.io/categories/BUG解决/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"转码","slug":"转码","permalink":"http://zj2626.github.io/tags/转码/"}]},{"title":"Python 爬虫实战（3）","slug":"20171219_crawler3","date":"2020-01-15T05:50:39.647Z","updated":"2021-03-10T13:50:15.304Z","comments":true,"path":"2020/01/15/20171219_crawler3/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20171219_crawler3/","excerpt":"Socket 网络编程 Socket(套接字),是操作系统内核中的一个数据结构，它是网络中的节点进行相互通信的门户。它是网络进程的ID。网络通信，归根到底还是进程间的通信（不同计算机上的进程间通信, 又称进程间通信, IP协议进行的主要是端到端通信）。在网络中，每一个节点（计算机或路由）都有一个网络地址，也就是IP地址。两个进程通信时，首先要确定各自所在的网络节点的网络地址。但是，网络地址只能确定进程所在的计算机，而一台计算机上很可能同时运行着多个进程，所以仅凭网络地址还不能确定到底是和网络中的哪一个进程进行通信，因此套接口中还需要包括其他的信息，也就是端口号（PORT）。在一台计算机中，一个端口号一次只能分配给一个进程，也就是说，在一台计算机中，端口号和进程之间是一一对应关系。 所以，使用端口号和网络地址的组合可以唯一的确定整个网络中的一个网络进程 端口号的范围从0~65535，一类是由互联网指派名字和号码公司ICANN负责分配给一些常用的应用程序固定使用的“周知的端口”，其值一般为0~1023, 用户自定义端口号一般大于等于1024 每一个socket都用一个半相关描述{协议、本地地址、本地端口}来表示；一个完整的套接字则用一个相关描述{协议、本地地址、本地端口、远程地址、远程端口}来表示。socket也有一个类似于打开文件的函数调用，该函数返回一个整型的socket描述符，随后的连接建立、数据传输等操作都是通过socket来实现的","text":"Socket 网络编程 Socket(套接字),是操作系统内核中的一个数据结构，它是网络中的节点进行相互通信的门户。它是网络进程的ID。网络通信，归根到底还是进程间的通信（不同计算机上的进程间通信, 又称进程间通信, IP协议进行的主要是端到端通信）。在网络中，每一个节点（计算机或路由）都有一个网络地址，也就是IP地址。两个进程通信时，首先要确定各自所在的网络节点的网络地址。但是，网络地址只能确定进程所在的计算机，而一台计算机上很可能同时运行着多个进程，所以仅凭网络地址还不能确定到底是和网络中的哪一个进程进行通信，因此套接口中还需要包括其他的信息，也就是端口号（PORT）。在一台计算机中，一个端口号一次只能分配给一个进程，也就是说，在一台计算机中，端口号和进程之间是一一对应关系。 所以，使用端口号和网络地址的组合可以唯一的确定整个网络中的一个网络进程 端口号的范围从0~65535，一类是由互联网指派名字和号码公司ICANN负责分配给一些常用的应用程序固定使用的“周知的端口”，其值一般为0~1023, 用户自定义端口号一般大于等于1024 每一个socket都用一个半相关描述{协议、本地地址、本地端口}来表示；一个完整的套接字则用一个相关描述{协议、本地地址、本地端口、远程地址、远程端口}来表示。socket也有一个类似于打开文件的函数调用，该函数返回一个整型的socket描述符，随后的连接建立、数据传输等操作都是通过socket来实现的 原文见： http://python.jobbole.com/88396/ 个人代码：TCP12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#服务器端#!/usr/bin/env python# -*- coding:utf-8 -*- import sysimport socket #socket模块 BUF_SIZE = 1024 #设置缓冲区大小server_addr = ('127.0.0.1', 51230) #IP和端口构成表示地址try : server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #生成一个新的socket对象except socket.error as msg : print (\"Creating Socket Failure. Error Code : \" + str(msg[0]) + \" Message : \" + msg[1]) sys.exit()print (\"Socket Created!\")server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #设置地址复用try : server.bind(server_addr) #绑定地址except socket.error as msg : print (\"Binding Failure. Error Code : \" + str(msg[0]) + \" Message : \" + msg[1]) sys.exit()print (\"Socket Bind!\")server.listen(5) #监听, 最大监听数为5print (\"Socket listening\")while True: client, client_addr = server.accept() #接收TCP连接, 并返回新的套接字和地址, 阻塞函数 print ('Connected by', client_addr) while True : data = client.recv(BUF_SIZE) #从客户端接收数据 print (str(data, encoding = \"utf-8\")) if data == b'exit': break client.sendall(data) #发送数据到客户端server.close()#客户端#!/usr/bin/env python# -*- coding:utf-8 -*- import sysimport socket BUF_SIZE = 1024 #设置缓冲区的大小server_addr = ('127.0.0.1', 51230) #IP和端口构成表示地址try : client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #返回新的socket对象except socket.error as msg : print (\"Creating Socket Failure. Error Code : \" + str(msg[0]) + \" Message : \" + msg[1]) sys.exit()client.connect(server_addr) #要连接的服务器地址while True: data = input(\"Please input some string &gt; \") if not data : print (\"input can't empty, Please input again..\") continue client.sendall(bytes(data, encoding = 'utf-8')) #发送数据到服务器 # client.sendall(str.encode(data)) data = client.recv(BUF_SIZE) #从服务器端接收数据 print (str(data, encoding = \"utf-8\"))client.close() UDP123456789101112131415161718192021222324252627282930313233#服务器端#!/usr/bin/env python# -*- coding:utf-8 -*-import socket #socket模块BUFF_SIZE = 1024server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)address = ('127.0.0.1', 12346)server.bind(address)while True: print (\"WAIT\") data, client_address = server.recvfrom(BUFF_SIZE) print (str(data, encoding='utf-8'), 'from' ,client_address) server.sendto(data, client_address) #客户端#!/usr/bin/env python# -*- coding:utf-8 -*-import socket #socket模块import sysBUFF_SIZE = 1024client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)address = ('127.0.0.1', 12346)while True: data = input(\"Please input some \") if data == 'exit': break client.sendto(bytes(data, encoding='utf-8'), address) data = client.recv(BUFF_SIZE) print (str(data, encoding='utf-8')) 别人家的代码【滑稽】：TCP12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#服务器端#!/usr/bin/env python# -*- coding:utf-8 -*- import sysimport socket #socket模块 BUF_SIZE = 1024 #设置缓冲区大小server_addr = ('127.0.0.1', 8888) #IP和端口构成表示地址try : server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #生成一个新的socket对象except socket.error, msg : print \"Creating Socket Failure. Error Code : \" + str(msg[0]) + \" Message : \" + msg[1] sys.exit()print \"Socket Created!\"server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #设置地址复用try : server.bind(server_addr) #绑定地址except socket.error, msg : print \"Binding Failure. Error Code : \" + str(msg[0]) + \" Message : \" + msg[1] sys.exit()print \"Socket Bind!\"server.listen(5) #监听, 最大监听数为5print \"Socket listening\"while True: client, client_addr = server.accept() #接收TCP连接, 并返回新的套接字和地址, 阻塞函数 print 'Connected by', client_addr while True : data = client.recv(BUF_SIZE) #从客户端接收数据 print data client.sendall(data) #发送数据到客户端server.close()#客户端#!/usr/bin/env python# -*- coding:utf-8 -*- import sysimport socket BUF_SIZE = 1024 #设置缓冲区的大小server_addr = ('127.0.0.1', 8888) #IP和端口构成表示地址try : client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #返回新的socket对象except socket.error, msg : print \"Creating Socket Failure. Error Code : \" + str(msg[0]) + \" Message : \" + msg[1] sys.exit()client.connect(server_addr) #要连接的服务器地址while True: data = raw_input(\"Please input some string &gt; \") if not data : print \"input can't empty, Please input again..\" continue client.sendall(data) #发送数据到服务器 data = client.recv(BUF_SIZE) #从服务器端接收数据 print dataclient.close() UDP12345678910111213141516171819202122232425262728293031323334#服务器端#!/usr/bin/env python# -*- coding:utf-8 -*- import socket BUF_SIZE = 1024 #设置缓冲区大小server_addr = ('127.0.0.1', 8888) #IP和端口构成表示地址server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) #生成新的套接字对象server.bind(server_addr) #套接字绑定IP和端口while True : print \"waitting for data\" data, client_addr = server.recvfrom(BUF_SIZE) #从客户端接收数据 print 'Connected by', client_addr, ' Receive Data : ', data server.sendto(data, client_addr) #发送数据给客户端server.close()#客户端#!/usr/bin/env python# -*- coding:utf-8 -*- import socketimport struct BUF_SIZE = 1024 #设置缓冲区server_addr = ('127.0.0.1', 8888) #IP和端口构成表示地址client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) #生成新的套接字对象 while True : data = raw_input('Please Input data &gt; ') client.sendto(data, server_addr) #向服务器发送数据 data, addr = client.recvfrom(BUF_SIZE) #从服务器接收数据 print \"Data : \", dataclient.close() 其他1234567891011121314151617181920212223242526s.getpeername()#返回连接套接字的远程地址。返回值通常是元组（ipaddr,port）。 s.getsockname()#返回套接字自己的地址。通常是一个元组(ipaddr,port) s.setsockopt(level,optname,value)#设置给定套接字选项的值。 s.getsockopt(level,optname[.buflen])#返回套接字选项的值。 s.settimeout(timeout)#设置套接字操作的超时期，timeout是一个浮点数，单位是秒。值为None表示没有超时期。一般，超时期应该在刚创建套接字时设置，因为它们可能用于连接的操作（如connect()） s.gettimeout()#返回当前超时期的值，单位是秒，如果没有设置超时期，则返回None。 s.fileno()#返回套接字的文件描述符。 s.setblocking(flag)#如果flag为0，则将套接字设为非阻塞模式，否则将套接字设为阻塞模式（默认值）。非阻塞模式下，如果调用recv()没有发现任何数据，或send()调用无法立即发送数据，那么将引起socket.error异常。 s.makefile()#创建一个与该套接字相关连的文件 转载自 链接地址: http://python.jobbole.com/88396/ 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://zj2626.github.io/categories/爬虫/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://zj2626.github.io/tags/爬虫/"}]},{"title":"Python 爬虫实战（2）","slug":"20171219_crawler2","date":"2020-01-15T05:50:39.646Z","updated":"2021-03-10T15:20:21.754Z","comments":true,"path":"2020/01/15/20171219_crawler2/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20171219_crawler2/","excerpt":"目标： 获取上交所和深交所所有股票的名称和交易信息,存储到一个本地文件中 网站选择原则： 股票信息静态存在于html页面中，非js代码生成，没有Robbts协议限制 选取方法： 打开网页，查看源代码，搜索网页的股票价格数据是否存在于源代码中","text":"目标： 获取上交所和深交所所有股票的名称和交易信息,存储到一个本地文件中 网站选择原则： 股票信息静态存在于html页面中，非js代码生成，没有Robbts协议限制 选取方法： 打开网页，查看源代码，搜索网页的股票价格数据是否存在于源代码中 下面的百度股市通中，股票的信息完全再html代码中，符合要求（并且发现网址中包含我们需要的关键字:sz代表深交所，而后面的数字就是股票代码了） 除了单个股票的信息，我们需要所有交所和深交所的股票，访问 http://quote.eastmoney.com/stocklist.html 查看页面 所有我们只需要先获取所有的股票代码，然后循环访问百度即可获得所有的股票信息 输出结果： 大部分讲解都在 Python 爬虫实战（1） 中介绍过了，需要请查看 http://zj2626.github.io/2017/12/14/20171214_crawler python文件读写 Python内置了读写文件的函数，用法和C是兼容的。 在磁盘上读写文件的功能都是由操作系统提供的，现代操作系统不允许普通的程序直接操作磁盘，所以，读写文件就是请求操作系统打开一个文件对象（通常称为文件描述符），然后，通过操作系统提供的接口从这个文件对象中读取数据（读文件），或者把数据写入这个文件对象（写文件）。 读文件 python内置的open()函数，返回一个文件对象;(参数中 r代表读 w代表写) 得到文件对象，则可以直接调用f.read()把文件内容读取到内存中来1f.read() 读取时发生的问题： 如果文件不存在，open()函数就会抛出一个IOError的错误，并且给出错误码和详细的信息告诉你文件不存在 ‘gbk’ codec can’t decode byte 0xaf in position … 12345#问题2解决方案两个：# 1. 打开文件的时候就指定编码的类型 f = open('E:/Data.txt', 'r',encoding = 'utf-8') f.read()# 2. 修改文件编码为utf-8 最后一步是调用close()方法关闭文件。文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间能打开的文件数量也是有限的 1f.close() 为了防止中途出现异常而无法关闭文件，使用try finally语句 123456try: f = open('E:/Data.txt', 'r', encoding = 'utf-8') print(f.read())finally: if f: f.close() 为了简化代码，python提供了一个更好的更简洁的方法读取文件(和try…finally一样的) 12with open('E:/Data.txt', 'r', encoding = 'utf-8') as f: print(f.read()) read()方法一次把所有的文件内容读取进来，如果文件太大就不太好用，所以要反复调用read(size)来一部分一部分的读取，也可以调用readline()一次读取一行，或者调用readlines()一次读取全部并返回list1234with open('E:/Data.txt', 'r', encoding = 'utf-8') as f: print(f.readline()) print(f.readline()) print(f.readline()) 如果文件很小，read()一次性读取最方便；如果不能确定文件大小，反复调用read(size)比较保险；如果是配置文件，调用readlines()最方便 写文件 第二个参数传入标识符’w’或者’wb’表示写文本文件或写二进制文件; write()函数会把数据替换掉原文件中内容123456try: f = open('E:/Data.txt', 'w', encoding = 'utf-8') f.write('ffffffffffffffffffffffff')finally: if f: f.close() 当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。 同读取一样 系统提供更好的12with open('E:/Data.txt', 'w', encoding = 'utf-8') as f: f.write('kkkkkkkkkkkkkkkk') 二进制文件 前面讲的默认都是读取文本文件，并且是UTF-8编码的文本文件。要读取二进制文件，比如图片、视频等等，用’rb’模式打开文件即可 12with open('D:/20171226101748.png', 'rb') as f: f.read() 个人代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from urllib import requestfrom bs4 import BeautifulSoup as bsimport redef getCodes(): url = 'http://quote.eastmoney.com/stocklist.html'; resp = request.urlopen(url) resp_text = resp.read().decode('gbk') soap = bs(resp_text, 'html.parser') list = soap.find_all('div', id = 'quotesearch')[0].find_all('ul')[0].find_all('li') codeList = [] for li in list: try: #eg: sh603183 codeList.append(re.findall(r\"[s][hz]\\d&#123;6&#125;\", li.find('a')['href'])) except: continue return codeListdef makeDict(code): infoDict = &#123;&#125; url = 'https://gupiao.baidu.com/stock/'+ code +'.html'; resp = request.urlopen(url) resp_text = resp.read().decode('utf-8') soap = bs(resp_text, 'html.parser') try: stockInfo = soap.find_all(attrs = &#123;'class','stock-bets'&#125;) name = soap.find(attrs = &#123;'class', 'bets-name'&#125;) if name is None: return None infoDict['name'] = name.text.strip() keys = soap.find_all('dt') values = soap.find_all('dd') for i in range(len(keys)): infoDict[keys[i].text] = values[i].text return infoDict except: return Nonedef writeFile(codeList): i=0 for code in codeList: i = i+1 # 下面两个判断是因为前45个股票百度并没有信息，所以跳过了，200个以后的数据就不再取了，太多了，科科 if i &lt; 45: continue if i &gt; 200: break infoDict = makeDict(code[0]) if infoDict is None: continue print (infoDict) with open('E://Data.txt', 'a', encoding = 'utf-8') as f: f.write(str(infoDict) + '\\n')codeList = getCodes();print(\"start\")writeFile(codeList) 别人家的代码【滑稽】：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# -*- coding: utf-8 -*- import requestsfrom bs4 import BeautifulSoupimport tracebackimport re def getHTMLText(url): try: r = requests.get(url) r.raise_for_status() r.encoding = r.apparent_encoding return r.text except: return \"\" def getStockList(lst, stockURL): html = getHTMLText(stockURL) soup = BeautifulSoup(html, 'html.parser') a = soup.find_all('a') for i in a: try: href = i.attrs['href'] lst.append(re.findall(r\"[s][hz]\\d&#123;6&#125;\", href)[0]) except: continue def getStockInfo(lst, stockURL, fpath): count = 0 for stock in lst: url = stockURL + stock + \".html\" html = getHTMLText(url) try: if html==\"\": continue infoDict = &#123;&#125; soup = BeautifulSoup(html, 'html.parser') stockInfo = soup.find('div',attrs=&#123;'class':'stock-bets'&#125;) name = stockInfo.find_all(attrs=&#123;'class':'bets-name'&#125;)[0] infoDict.update(&#123;'股票名称': name.text.split()[0]&#125;) keyList = stockInfo.find_all('dt') valueList = stockInfo.find_all('dd') for i in range(len(keyList)): key = keyList[i].text val = valueList[i].text infoDict[key] = val with open(fpath, 'a', encoding='utf-8') as f: f.write( str(infoDict) + '\\n' ) count = count + 1 print(\"\\r当前进度: &#123;:.2f&#125;%\".format(count*100/len(lst)),end=\"\") except: count = count + 1 print(\"\\r当前进度: &#123;:.2f&#125;%\".format(count*100/len(lst)),end=\"\") continue def main(): stock_list_url = 'http://quote.eastmoney.com/stocklist.html' stock_info_url = 'https://gupiao.baidu.com/stock/' output_file = 'D:/BaiduStockInfo.txt' slist=[] getStockList(slist, stock_list_url) getStockInfo(slist, stock_info_url, output_file) main() 转载自 链接地址: http://python.jobbole.com/88350/ 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://zj2626.github.io/categories/爬虫/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://zj2626.github.io/tags/爬虫/"}]},{"title":"Python 爬虫实战（1）","slug":"20171214_crawler","date":"2020-01-15T05:50:39.645Z","updated":"2021-03-10T15:20:21.787Z","comments":true,"path":"2020/01/15/20171214_crawler/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20171214_crawler/","excerpt":"前言：在我学习完python的基础知识之后，当然想要练练手，加深一下对python以及其语法的理解，所以听说爬虫特别有成就感，非常有利于学习and娱乐，以及培养学习的兴趣，so就到处百度爬虫的相关文章，网上的确有很多相关的，但我还是决定自己写写,只有自己写下了讲出来才能代表真的学会了这么技术","text":"前言：在我学习完python的基础知识之后，当然想要练练手，加深一下对python以及其语法的理解，所以听说爬虫特别有成就感，非常有利于学习and娱乐，以及培养学习的兴趣，so就到处百度爬虫的相关文章，网上的确有很多相关的，但我还是决定自己写写,只有自己写下了讲出来才能代表真的学会了这么技术 我也是第一次学python和抓包，是根据网上的各种讲解以及自己的摸索，慢慢学会的，有什么说的不对的，欢迎指正 刚开始的时候我的使用Anaconda管理包和环境（py3.6），然而后来我在学多线程的时候，就出现了问题：setdaemon(true)一直没效果（设置守护线程后，守护线程本来应该在所有非守护线程执行完就立马结束而不管守护线程是否结束的，but没用，网上各种查也查不到，后来我把代码写到.py文件里直接在cmd里执行该脚本就没问题了） 使用Anaconda是因为我打算入坑深度学习，所以提前熟悉熟悉这个管理工具，科科 本章目的： 抓取豆瓣电影网站正在上映列表的评价关键词，并使用词云表示出来 豆瓣正在上映列表如图 豆瓣电影《芳华》短评列表如图 最终获得的《芳华》短评词云如图 抓取步骤大致分为三步，具体的又分为下面几步：1.访问并获取网页数据并抽取出来有用信息 首先要获取网页数据 获取豆瓣正在上映列表的网页数据使用Python的urllib模块: 其提供了一个从指定的URL地址获取网页数据(创建一个表示远程url的类文件对象)，通过该对象可以对其进行分析处理，获取想要的数据 函数原型 url: 请求的地址（除了url，其他都可以不填） data: 访问url时请求的参数 timeout: 超时时间 python2.X写法： 12import urlliburltext = urllib.urlopen(url) python3.X写法： 12import urllib.request #from urllib import requesturltext = urllib.request.urlopen(url) urlopen()方法返回值类型： 如果请求的是http或者https地址，则返回http.client.HTTPResponse对象如果请求的是ftp或者Data URL地址(以及requests explicitly handled by legacyURLopener and FancyURLopener classes &lt;-原谅我没看懂)，则返回urllib.response.addinfourl对象 上面的对象包含多个方法可供我们使用 geturl() :返回请求的网页地址 info() :返回一个httplib.HTTPMessage对象，表示远程服务器返回的头信息 getcode():返回HTTP状态码 read() , readline() , readlines() , fileno() , close() 这些方法的使用方式与文件对象完全一样 实例 123456import urlliburltext = urllib.request.urlopen('https://movie.douban.com/nowplaying/beijing/')print (urltext)print (urltext.geturl())print (urltext.info())print (urltext.getcode()) 其次,分析网页数据，抓取想要的数据 找到网页上你要的电影列表的位置，看看有什么标签特点 我们发现所有的电影列表都在id为nowplaying的div下面的一个ul下，该ul的class为lists，并且每个电影的li标签的class为list-item该li标签中有许多熟悉，我们发现data-title为电影标题，data-score为电影评分，data-star为打星…,最最重要的是id，每个电影都不同，可推测应该是电影的唯一标识（编号）；我们要通过某一个标识来查询该电影的短评， 通过查看电影主页的网址（https://movie.douban.com/subject/26862829/ ）可知，这个id就是我们需要的 使用python的BeautifulSoup库进行网页信息的抓取（网页解析库）BeautifulSoup 是一个可以从 HTML 或 XML 文件中提取数据的 Python 库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式.Beautiful Soup 会帮你节省数小时甚至数天的工作时间. BeautifulSoup:Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时，Beautiful Soup就不能自动识别编码方式了。然后，你仅仅需要说明一下原始编码方式就可以了。Beautiful Soup已成为和lxml、html6lib一样出色的python解释器，为用户灵活地提供不同的解析策略或强劲的速度。(from http://beautifulsoup.readthedocs.io/zh_CN/latest/ ) 使用BeautifulSoup解析代码,能够得到一个 BeautifulSoup 的对象,并能按照标准的缩进格式的结构输出 Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种: Tag, NavigableString, BeautifulSoup, Comment1234Tag: &lt;class &apos;bs4.element.Tag&apos;&gt;标签对象，两个属性：name, attribute (直接调用：tag.name，tag[&apos;class&apos;]), 如果是多值属性，则返回list，也可以赋值为多值属性（假的多值属性返回字符串，如id=&quot;aaa bbb&quot;）NavigableString: &lt;class &apos;bs4.element.NavigableString&apos;&gt; tag中的字符串对象，即tag.string; tag中包含的字符串不能编辑,但是可以被替换成其它的字符串,用 replace_with() 方法BeautifulSoup : &lt;class &apos;bs4.BeautifulSoup&apos;&gt;BeautifulSoup对象表示的是一个文档的全部内容.大部分时候,可以把它当作 Tag 对象,它支持 遍历文档树 和 搜索文档树 中描述的大部分的方法; 一个方法：soup.name # [document]Comment : &lt;class &apos;bs4.element.Comment&apos;&gt;文档的注释部分，Comment 对象是一个特殊类型的 NavigableString 对象 BeautifulSoup对象使用示例： 解析时，可以传入一段字符串或一个文件句柄. 123456from bs4 import BeautifulSoup #导入模块soup = BeautifulSoup(open(\"index.html\"))soup = BeautifulSoup(\"&lt;html&gt;data&lt;/html&gt;\")#首先,文档被转换成Unicode,并且HTML的实例都被转换成Unicode编码#然后,BeautifulSoup选择最合适的解析器来解析这段文档,如果手动指定解析器那么Beautiful Soup会选择指定的解析器来解析文档 soup.title # 标签对象：北京 - 在线购票&amp;影讯 soup.title.name # 标签名称：title soup.title.string # 标签内容：北京 - 在线购票&amp;影讯 soup.p # 第一个p标签对象：豆瓣 soup.p[‘class’] # 第一个p标签对象的类属性7. 12345678原型：find_all( name , attrs , recursive , string , **kwargs ) 搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件 name: name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉. attrs: 通过属性选择器查询，有两种写法 1. soup.find_all(class_=&apos;value&apos;, id=&apos;value2&apos;) 2. soup.find_all(attrs=&#123;&quot;class&quot;: &quot;value&quot;, &quot;id&quot;:&quot;value2&quot;&#125;) limit: 限制查询结果个数 recursive: 调用tag的 find_all() 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 recursive=False string: 通过 string 参数可以搜搜文档中的字符串内容. soup.find_all(&quot;a&quot;, string=&quot;value&quot;) #查询标签中文字包含value的a标签 soup.find(‘a’).get(‘href’) # 找到第一个a标签 并返回其href属性内容 （ find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.） 更多用法见BeautifulSoup官网中文文档：http://beautifulsoup.readthedocs.io/zh_CN/latest/ 解析网页代码,并编码为utf-8 1234import urlliburltext = urllib.request.urlopen('https://movie.douban.com/nowplaying/beijing/')html_data = urltext.read().decode('utf-8')print (html_data) 获取正在上映列表数据 nowplaying_movie_list列表（List） 12345678910import urlliburltext = urllib.request.urlopen('https://movie.douban.com/nowplaying/beijing/')html_data = urltext.read().decode('utf-8')from bs4 import BeautifulSoup as bssoup = bs(html_data, 'html.parser')nowplaying_movie = soup.find_all('div', id = 'nowplaying') # 先获取id为nowplaying的div# print (nowplaying_movie) # 只有一条数据，因为id是唯一的nowplaying_movie_list = nowplaying_movie[0].find_all('li', class_ = 'list-item')# 再获取class为list-item的liprint (nowplaying_movie_list) 至此已经获得了最内部一层的电影数据， 可以直接获得每个电影的id了 1print (nowplaying_movie_list[0]['id'], '\\n') #获取第一个电影的id数据 现在 我们需要获取其中某一个id，通过这个id获取对应电影的短评，然后就可以进行处理了 你也可以自由发挥，制作一个查询的功能，通过输入电影名称指定某一个电影进行分析 2.分析网页中有用信息并进行处理 首先按照上面的步骤访问电影首页，抽取短评信息，存放到一个List中 首先解析网页代码 123456789requrl = \"https://movie.douban.com/subject/\" + nowplaying_movie_list[0]['id'] + \"/comments?start=0&amp;limit=20\"resp = urllib.request.urlopen(requrl)html_data = resp.read().decode('utf-8')soup = bs(html_data, 'html.parser')title = soup.find('title') # 直接获取title标签print(title.string) #获取标签中内容comment_div_list = soup.find_all('div', class_ = 'comment')print (comment_div_list) #所有的短片标签列表 通过下面的源码可知，所有的短评文字都放在class为comment-item的div下的一个p标签中，所有我们要得到所有的p标签并组成一个List 12345commentList = [] #存放所有的短评内容数据 Listfor cm in comment_div_list: if cm.find_all('p')[0] is not None: commentList.append(cm.find_all('p')[0].string) #把短评内容存放在列表中print (commentList) 已得短评List，但是该List中包含大量的单引号（List自带的），换行符等不需要的东西，并且由于我们要做成词云，所有的符号都不要，只要文字 12345678while True: if None in commentList: commentList.remove(None) #去除NoneType数据 else: breakcomments = ''.join(commentList) #拼接字符串comments = comments.replace(' ','').replace(\"\\n\", \"\").replace(\"\\t\", \"\")print (comments) 词云展示的只是关键词，所以去除用户短评中的所有的标点符号（正则表达式） 12345import re #正则表达式pattern = re.compile(r'[\\u4e00-\\u9fa5]+') #去除标点符号(正则表达式)filterdata = re.findall(pattern, comments)cleaned_comments = ''.join(filterdata) # 把filterdata按照空字符串为间隔连接起来print (cleaned_comments) 目前所有的评价都没有间隔的展示在这里，我们需要把其中的词语取出来得到所有的关键词 使用jieba分词, 把字符串中的所有的词语分出来，组成一个List 结巴（jieba）是国人出的一个精品插件，可以对一段中文进行分词，有三种分词模式，可以适应不同需求。 12345678jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用jieba.lcut 以及 jieba.lcut_for_search 直接返回 listjieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。也可以添加自定义词典 （from： http://blog.csdn.net/qq_27231343/article/details/51898940 ） 123456789101112131415161718192021#代码示例# encoding=utf-8import jiebaseg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)print(\"Full Mode: \" + \"/ \".join(seg_list)) # 全模式seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)print(\"Default Mode: \" + \"/ \".join(seg_list)) # 精确模式seg_list = jieba.cut(\"他来到了网易杭研大厦\") # 默认是精确模式print(\"* \".join(seg_list))seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\") # 搜索引擎模式print(\", \".join(seg_list))#输出结果# Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学# Default Mode: 我/ 来到/ 北京/ 清华大学# 他* 来到* 了* 网易* 杭研* 大厦 (此处，“杭研”并没有在词典中，但是也被Viterbi算法识别出来了)# 小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造 使用jieba分割短评，获取返回的分词List 123import jiebasegment = jieba.lcut(cleaned_comments)print (segment) 数据中有“的”、“是”、“我”、“你”等虚词（停用词），而这些词在任何场景中都是高频时，并且没有实际的含义，所以我们要他们进行清除。 使用pandas 1234567891011import pandas as pdwords_df = pd.DataFrame(&#123;'segment':segment&#125;) #格式转换 把List转化为Dict# words_df.head()# print(words_df)# print (words_df.segment)#从网上下载常用停用词文件 stopwords.txt 然后对比去除统计结果中所有的停用词stopwords=pd.read_csv(\"E:/stopwords.txt\",index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')#quoting=3全不引用# print (stopwords.stopword)# print (words_df.segment.isin(stopwords.stopword))words_df = words_df[~words_df.segment.isin(stopwords.stopword)] #stopwords.txt不能有空格words_df.head() 我的停用词文件： http://p18j2ow6f.bkt.clouddn.com/static/file/stopwords.txt 清洗了关键词以后，我们把剩下的词语进行分类统计，观察每个词语的频率 使用numpy 1234import numpy #numpy计算包words_stat = words_df.groupby(by=['segment'])['segment'].agg(&#123;\"计数\":numpy.size&#125;) # 按照segment分类words_stat = words_stat.reset_index().sort_values(by=[\"计数\"],ascending=False) #词频按照 计数 由大到小排列words_stat.head() 3.制作为词云12345678910111213import matplotlib# %matplotlib inlinematplotlib.rcParams['figure.figsize'] = (10.0, 5.0)from wordcloud import WordCloud #词云包wordcloud=WordCloud(font_path=\"E:/simhei.ttf\",background_color=\"white\",max_font_size=80) #指定字体类型、字体大小和字体颜色# print (wordcloud)word_frequence = &#123;x[0]:x[1] for x in words_stat.head(1000).values&#125;# print (word_frequence)wordcloud=wordcloud.fit_words(word_frequence)matplotlib.pyplot.imshow(wordcloud) 我的字体文件： http://p18j2ow6f.bkt.clouddn.com/static/file/simhei.ttf 最终效果 遇到403: forbidden以及503: Service Unavailable问题的解决方法：这是网站对自动化爬虫的禁止需要用python的模块urllib2模块(对于3.6版本使用 urllib.request) User-Agent是浏览器特有的属性，通过浏览器查看源代码就可以查看到(其他的属性也可以通过浏览器点击F12中的network窗口发现) 123456789101112131415161718192021222324252627282930313233import urllib.requestimport randomfrom bs4 import BeautifulSoup as bsimport reimport csvdef getCodes(): headers=[\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36\"] randdom_header=random.choice(headers) url = 'http://bj.meituan.com/meishi/c17/'; req=request.Request(url) req.add_header(\"User-Agent\",randdom_header) req.add_header(\"Host\",\"bj.meituan.com\") req.add_header(\"Referer\",\"http://bj.meituan.com/\") req.add_header(\"GET\",url) resp_text=request.urlopen(req).read() soap = bs(resp_text, 'html.parser') list = soap.find_all('ul', class_ = 'list-ul')[0].find_all('li') print (list) codeList = [] for div in list: try: url = div.find('div', class_ = 'img ').find('a')['href']# len = url.index('?') codeList.append(url) # url[: len] except: continue return codeList 个人完整代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110from urllib import request #python3.X写法#import urllib #python2.X写法from bs4 import BeautifulSoup as bsimport re #正则表达式import jieba #分词包 中文分词操作 结巴分词import pandas as pdimport numpy #numpy计算包\"\"\"python2.X 关于 urllib的用法 import urllib text = urllib.urlopen(url).read()python3.X 关于 urllib的用法 import urllib.request #from urllib import request response = urllib.request.urlopen(url) text = response.read()\"\"\"def getList(): resp = request.urlopen('https://movie.douban.com/nowplaying/beijing/') #获取url下的影片列表;python2.x下使用urllib.urlopen() html_data = resp.read().decode('utf-8') # 读取返回的数据(返回页面的html代码) # print(html_data) soup = bs(html_data, 'html.parser') # 解析html代码 开始获取其中的数据 nowplaying_movie = soup.find_all('div', id = 'nowplaying') #获取id为nowplaying的div标签以及内部的代码 (得到的是一个list) # print (nowplaying_movie); nowplaying_movie_list = nowplaying_movie[0].find_all('li', class_ = 'list-item') #获取class是list-item的所有li标签 # print (nowplaying_movie_list); # print (nowplaying_movie_list[0]['id'], '\\n'); # 打印第一个影片的id \"\"\"测试代码 开始\"\"\" # test = nowplaying_movie_list[0].find_all('ul') # print (test) # test = nowplaying_movie_list[0].find_all('ul')[0].find_all('li')[1] # print (test) \"\"\"测试代码 结束\"\"\" return nowplaying_movie_listdef getComments(nowplaying_movie_list, num): requrl = \"https://movie.douban.com/subject/\" + nowplaying_movie_list[num]['id'] + \"/comments?start=0&amp;limit=20\" #获取url下的影片短评列表 resp = urllib.request.urlopen(requrl) html_data = resp.read().decode('utf-8') soup = bs(html_data, 'html.parser') title = soup.find('title') print(title.string) comment_div_list = soup.find_all('div', class_ = 'comment') #print (comment_div_list) commentList = [] #存放所有的短评内容数据 for cm in comment_div_list: if cm.find_all('p')[0] is not None: commentList.append(cm.find_all('p')[0].string) #把短评内容存放在列表中 # print (comments) comments = '' for k in range(len(commentList)): comments = comments + (str(commentList[k])).strip() #print (comments) pattern = re.compile(r'[\\u4e00-\\u9fa5]+') #去除标点符号(正则表达式) filterdata = re.findall(pattern, comments) cleaned_comments = ''.join(filterdata) # 把filterdata按照空字符串为间隔连接起来 # print (cleaned_comments) segment = jieba.lcut(cleaned_comments) #list # print (segment) words_df = pd.DataFrame(&#123;'segment':segment&#125;) #格式转换 # words_df.head() # print(words_df) # print (words_df.segment) # 数据中有“的”、“是”、“我”、“你”等虚词（停用词），而这些词在任何场景中都是高频时，并且没有实际的含义，所以我们要他们进行清除。 #从网上下载常用停用词文件 stopwords.txt 然后对比去除统计结果中所有的停用词 stopwords=pd.read_csv(\"E:/stopwords.txt\",index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')#quoting=3全不引用 # print (stopwords.stopword) # print (words_df.segment.isin(stopwords.stopword)) words_df = words_df[~words_df.segment.isin(stopwords.stopword)] #stopwords.txt不能有空格 words_df.head() #进行词频统计 words_stat = words_df.groupby(by=['segment'])['segment'].agg(&#123;\"计数\":numpy.size&#125;) # 按照segment分类 words_stat = words_stat.reset_index().sort_values(by=[\"计数\"],ascending=False) #词频按照 计数 由大到小排列 words_stat.head() return words_stat#词云展示def show(words_stat): import matplotlib %matplotlib inline matplotlib.rcParams['figure.figsize'] = (10.0, 5.0) from wordcloud import WordCloud #词云包 wordcloud=WordCloud(font_path=\"E:/simhei.ttf\",background_color=\"white\",max_font_size=80) #指定字体类型、字体大小和字体颜色 # print (wordcloud) word_frequence = &#123;x[0]:x[1] for x in words_stat.head(1000).values&#125; # print (word_frequence) wordcloud=wordcloud.fit_words(word_frequence) matplotlib.pyplot.imshow(wordcloud)num = 0 #从0开始, 获取豆瓣最新上映电影短评关键信息movie_list = getList()words_stat = getComments(movie_list, num)show(words_stat) 别人家的代码【滑稽】：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#coding:utf-8__author__ = 'hang'import warningswarnings.filterwarnings(\"ignore\")import jieba #分词包import numpy #numpy计算包import codecs #codecs提供的open方法来指定打开的文件的语言编码，它会在读取的时候自动转换为内部unicodeimport reimport pandas as pdimport matplotlib.pyplot as pltfrom urllib import requestfrom bs4 import BeautifulSoup as bs%matplotlib inlineimport matplotlibmatplotlib.rcParams['figure.figsize'] = (10.0, 5.0)from wordcloud import WordCloud#词云包#分析网页函数def getNowPlayingMovie_list(): resp = request.urlopen('https://movie.douban.com/nowplaying/hangzhou/') html_data = resp.read().decode('utf-8') soup = bs(html_data, 'html.parser') nowplaying_movie = soup.find_all('div', id='nowplaying') nowplaying_movie_list = nowplaying_movie[0].find_all('li', class_='list-item') nowplaying_list = [] for item in nowplaying_movie_list: nowplaying_dict = &#123;&#125; nowplaying_dict['id'] = item['data-subject'] for tag_img_item in item.find_all('img'): nowplaying_dict['name'] = tag_img_item['alt'] nowplaying_list.append(nowplaying_dict) return nowplaying_list#爬取评论函数def getCommentsById(movieId, pageNum): eachCommentList = []; if pageNum&gt;0: start = (pageNum-1) * 20 else: return False requrl = 'https://movie.douban.com/subject/' + movieId + '/comments' +'?' +'start=' + str(start) + '&amp;limit=20' print(requrl) resp = request.urlopen(requrl) html_data = resp.read().decode('utf-8') soup = bs(html_data, 'html.parser') comment_div_lits = soup.find_all('div', class_='comment') for item in comment_div_lits: if item.find_all('p')[0].string is not None: eachCommentList.append(item.find_all('p')[0].string) return eachCommentListdef main(): #循环获取第一个电影的前10页评论 commentList = [] NowPlayingMovie_list = getNowPlayingMovie_list() for i in range(10): num = i + 1 commentList_temp = getCommentsById(NowPlayingMovie_list[0]['id'], num) commentList.append(commentList_temp) #将列表中的数据转换为字符串 comments = '' for k in range(len(commentList)): comments = comments + (str(commentList[k])).strip() #使用正则表达式去除标点符号 pattern = re.compile(r'[\\u4e00-\\u9fa5]+') filterdata = re.findall(pattern, comments) cleaned_comments = ''.join(filterdata) #使用结巴分词进行中文分词 segment = jieba.lcut(cleaned_comments) words_df=pd.DataFrame(&#123;'segment':segment&#125;) #去掉停用词 stopwords=pd.read_csv(\"stopwords.txt\",index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')#quoting=3全不引用 words_df=words_df[~words_df.segment.isin(stopwords.stopword)] #统计词频 words_stat=words_df.groupby(by=['segment'])['segment'].agg(&#123;\"计数\":numpy.size&#125;) words_stat=words_stat.reset_index().sort_values(by=[\"计数\"],ascending=False) #用词云进行显示 wordcloud=WordCloud(font_path=\"simhei.ttf\",background_color=\"white\",max_font_size=80) word_frequence = &#123;x[0]:x[1] for x in words_stat.head(1000).values&#125; word_frequence_list = [] for key in word_frequence: temp = (key,word_frequence[key]) word_frequence_list.append(temp) wordcloud=wordcloud.fit_words(word_frequence_list) plt.imshow(wordcloud)#主函数main() 转载自 链接地址: http://python.jobbole.com/88325/ 个人博客 欢迎来访： http://zj2626.com","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://zj2626.github.io/categories/爬虫/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zj2626.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://zj2626.github.io/tags/爬虫/"}]},{"title":"VM options配置","slug":"20170924_VM-options配置","date":"2020-01-15T05:50:39.643Z","updated":"2021-03-10T13:50:15.316Z","comments":true,"path":"2020/01/15/20170924_VM-options配置/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170924_VM-options配置/","excerpt":"转载自 链接地址: http://www.cnblogs.com/mingforyou/archive/2012/03/03/2378143.html转载自 链接地址: http://unixboy.iteye.com/blog/174173/","text":"转载自 链接地址: http://www.cnblogs.com/mingforyou/archive/2012/03/03/2378143.html转载自 链接地址: http://unixboy.iteye.com/blog/174173/ 文章一Eclipse崩溃，错误提示：MyEclipse has detected that less than 5% of the 64MB of PermGen (Non-heap memory) space remains. It is strongly recommendedthat you exit and restart MyEclipse with new virtual machine memoryparamters to increase this memory. Failure to do so can result indata loss. The recommended Eclipse memory parameters are:eclipse.exe -vmargs -Xms128M -Xmx512M -XX:PermSize=64M -XX:MaxPermSize=128M 1.参数的含义-vmargs -Xms128M -Xmx512M -XX:PermSize=64M -XX:MaxPermSize=128M-vmargs 说明后面是VM的参数，所以后面的其实都是JVM的参数了-Xms128m JVM初始分配的堆内存-Xmx512m JVM最大允许分配的堆内存，按需分配-XX:PermSize=64M JVM初始分配的非堆内存-XX:MaxPermSize=128M JVM最大允许分配的非堆内存，按需分配 我们首先了解一下JVM内存管理的机制，然后再解释每个参数代表的含义。 堆(Heap)和非堆(Non-heap)内存 按照官方的说法：“Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。”“在JVM中堆之外的内存称为非堆内存(Non-heap memory)”。 可以看出JVM主要管理两种类型的内存：堆和非堆。简单来说堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给自己用的， 所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法的代码都在非堆内存中。 堆内存分配 JVM初始分配的堆内存由-Xms指定，默认是物理内存的1/64；JVM最大分配的堆内存由-Xmx指定，默认是物理内存的1/4。默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制； 空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx 相等以避免在每次GC 后调整堆的大小。 说明：如果-Xmx 不指定或者指定偏小，应用可能会导致java.lang.OutOfMemory错误，此错误来自JVM，不是Throwable的，无法用try…catch捕捉。 非堆内存分配 JVM使用-XX:PermSize设置非堆内存初始值，默认是物理内存的1/64；由XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4。（还有一说：MaxPermSize缺省值和-server -client选项相关， -server选项下默认MaxPermSize为64m，-client选项下默认MaxPermSize为32m。这个我没有实验。） 上面错误信息中的PermGen space的全称是Permanent Generation space，是指内存的永久保存区域。还没有弄明白PermGen space是属于非堆内存，还是就是非堆内存，但至少是属于了。XX:MaxPermSize设置过小会导致java.lang.OutOfMemoryError: PermGen space 就是内存益出。说说为什么会内存益出：（1）这一部分内存用于存放Class和Meta的信息，Class在被 Load的时候被放入PermGen space区域，它和存放Instance的Heap区域不同。（2）GC(Garbage Collection)不会在主程序运行期对PermGen space进行清理，所以如果你的APP会LOAD很多CLASS 的话,就很可能出现PermGen space错误。 这种错误常见在web服务器对JSP进行pre compile的时候。 JVM内存限制(最大值) 首先JVM内存限制于实际的最大物理内存，假设物理内存无限大的话，JVM内存的最大值跟操作系统有很大的关系。简单的说就32位处理器虽然可控内存空间有4GB,但是具体的操作系统会给一个限制， 这个限制一般是2GB-3GB（一般来说Windows系统下为1.5G-2G，Linux系统下为2G-3G），而64bit以上的处理器就不会有限制了。 为什么有的机器我将-Xmx和-XX:MaxPermSize都设置为512M之后Eclipse可以启动，而有些机器无法启动？通过上面对JVM内存管理的介绍我们已经了解到JVM内存包含两种：堆内存和非堆内存，另外JVM最大内存首先取决于实际的物理内存和操作系统。所以说设置VM参数导致程序无法启动主要有以下几种原因：1) 参数中-Xms的值大于-Xmx，或者-XX:PermSize的值大于-XX:MaxPermSize；2) -Xmx的值和-XX:MaxPermSize的总和超过了JVM内存的最大限制，比如当前操作系统最大内存限制，或者实际的物理内存等等。说到实际物理内存这里需要说明一点的是，如果你的内存是1024MB，但实际系统中用到的并不可能是1024MB，因为有一部分被硬件占用了。 为何将上面的参数写入到eclipse.ini文件Eclipse没有执行对应的设置？那为什么同样的参数在快捷方式或者命令行中有效而在eclipse.ini文件中是无效的呢？这是因为我们没有遵守eclipse.ini文件的设置规则：参数形如“项 值”这种形式，中间有空格的需要换行书写，如果值中有空格的需要用双引号包括起来。比如我们使用-vm C:/Java/jre1.6.0/bin/javaw.exe参数设置虚拟机，在eclipse.ini文件中要写成这样： -vmC:/Java/jre1.6.0/bin/javaw.exe-vmargs-Xms128M-Xmx512M-XX:PermSize=64M-XX:MaxPermSize=128M 实际运行的结果可以通过Eclipse中“Help”-“About Eclipse SDK”窗口里面的“Configuration Details”按钮进行查看。另外需要说明的是，Eclipse压缩包中自带的eclipse.ini文件内容是这样的：-showsplashorg.eclipse.platform–launcher.XXMaxPermSize256m-vmargs-Xms40m-Xmx256m其中–launcher.XXMaxPermSize（注意最前面是两个连接线）跟-XX:MaxPermSize参数的含义基本是一样的，我觉得唯一的区别就是前者是eclipse.exe启动的时候设置的参数，而后者是eclipse所使用的JVM中的参数。其实二者设置一个就可以了，所以这里可以把–launcher.XXMaxPermSize和下一行使用#注释掉。 其他的启动参数。 如果你有一个双核的CPU，也许可以尝试这个参数:-XX:+UseParallelGC让GC可以更快的执行。（只是JDK 5里对GC新增加的参数） 补充： 如果你的WEB APP下都用了大量的第三方jar，其大小超过了服务器jvm默认的大小，那么就会产生内存益出问题了。解决方法： 设置MaxPermSize大小可以在myelipse里选中相应的服务器比如tomcat5，展开里面的JDK子项页面，来增加服务器启动的JVM参数设置： -Xms128m-Xmx256m-XX:PermSize=128M-XX:MaxNewSize=256m-XX:MaxPermSize=256m 或者手动设置MaxPermSize大小,比如tomcat，修改TOMCAT_HOME/bin/catalina.bat，在echo “Using CATALINA_BASE: $CATALINA_BASE”上面加入以下行：JAVA_OPTS=”-server -XX:PermSize=64M -XX:MaxPermSize=128m 建议：将相同的第三方jar文件移置到tomcat/shared/lib目录下，这样可以减少jar 文档重复占用内存 文章二1.堆大小设置JVM 中最大堆大小有三方面限制：相关操作系统的数据模型（32-bt还是64-bit）限制；系统的可用虚拟内存限制；系统的可用物理内存限制。32位系统下，一般限制在1.5G~2G；64为操作系统对内存无限制。我在Windows Server 2003 系统，3.5G物理内存，JDK5.0下测试，最大可设置为1478m。 典型设置： java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -Xmx3550m：设置JVM最大可用内存为3550M。-Xms3550m：设置JVM初始内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。-Xmn2g：设置年轻代大小为2G。整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。-Xss128k：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0 -XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5-XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6-XX:MaxPermSize=16m:设置持久代大小为16m。-XX:MaxTenuringThreshold=0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。 2.回收器选择JVM给了三种选择：串行收集器、并行收集器、并发收集器，但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行判断。 吞吐量优先的并行收集器如上文所述，并行收集器主要以到达一定的吞吐量为目标，适用于科学技术和后台处理等。 典型配置： java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20-XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。-XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20 -XX:+UseParallelOldGC-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100-XX:MaxGCPauseMillis=100:设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:MaxGCPauseMillis=100 -XX:+UseAdaptiveSizePolicy-XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。 响应时间优先的并发收集器如上文所述，并发收集器主要是保证系统的响应时间，减少垃圾收集时的停顿时间。适用于应用服务器、电信领域等。 典型配置： java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC-XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了，原因不明。所以，此时年轻代大小最好用-Xmn设置。-XX:+UseParNewGC:设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。 java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=5 -XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。-XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除碎片 辅助信息 JVM提供了大量命令行参数，打印信息，供调试使用。主要有以下一些： -XX:+PrintGC输出形式：[GC 118250K-&gt;113543K(130112K), 0.0094143 secs][Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs] -XX:+PrintGCDetails输出形式：[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs][GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs] -XX:+PrintGCTimeStamps -XX:+PrintGC：PrintGCTimeStamps可与上面两个混合使用输出形式：11.851: [GC 98328K-&gt;93620K(130112K), 0.0082960 secs] -XX:+PrintGCApplicationConcurrentTime:打印每次垃圾回收前，程序未中断的执行时间。可与上面混合使用输出形式：Application time: 0.5291524 seconds -XX:+PrintGCApplicationStoppedTime：打印垃圾回收期间程序暂停的时间。可与上面混合使用输出形式：Total time for which application threads were stopped: 0.0468229 seconds -XX:PrintHeapAtGC:打印GC前后的详细堆栈信息 输出形式： 34.702: [GC {Heap before gc invocations=7: def new generation total 55296K, used 52568K [0x1ebd0000, 0x227d0000, 0x227d0000) eden space 49152K, 99% used [0x1ebd0000, 0x21bce430, 0x21bd0000) from space 6144K, 55% used [0x221d0000, 0x22527e10, 0x227d0000) to space 6144K, 0% used [0x21bd0000, 0x21bd0000, 0x221d0000) tenured generation total 69632K, used 2696K [0x227d0000, 0x26bd0000, 0x26bd0000) the space 69632K, 3% used [0x227d0000, 0x22a720f8, 0x22a72200, 0x26bd0000) compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000) the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000) ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000) rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000) 34.735: [DefNew: 52568K-&gt;3433K(55296K), 0.0072126 secs] 55264K-&gt;6615K(124928K)Heap after gc invocations=8: def new generation total 55296K, used 3433K [0x1ebd0000, 0x227d0000, 0x227d0000) eden space 49152K, 0% used [0x1ebd0000, 0x1ebd0000, 0x21bd0000) from space 6144K, 55% used [0x21bd0000, 0x21f2a5e8, 0x221d0000) to space 6144K, 0% used [0x221d0000, 0x221d0000, 0x227d0000) tenured generation total 69632K, used 3182K [0x227d0000, 0x26bd0000, 0x26bd0000) the space 69632K, 4% used [0x227d0000, 0x22aeb958, 0x22aeba00, 0x26bd0000) compacting perm gen total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000) the space 8192K, 35% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000) ro space 8192K, 66% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000) rw space 12288K, 46% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000) } , 0.0757599 secs] -Xloggc:filename:与上面几个配合使用，把相关日志信息记录到文件以便分析。 常见配置汇总 1.堆设置 -Xms:初始堆大小 -Xmx:最大堆大小 -XX:NewSize=n:设置年轻代大小 -XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4 -XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5 -XX:MaxPermSize=n:设置持久代大小 2.收集器设置 -XX:+UseSerialGC:设置串行收集器 -XX:+UseParallelGC:设置并行收集器 -XX:+UseParalledlOldGC:设置并行年老代收集器 -XX:+UseConcMarkSweepGC:设置并发收集器 3.垃圾回收统计信息 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:filename 4.并行收集器设置 -XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数。 -XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间 -XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n) 5.并发收集器设置 -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。 -XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。 调优总结1.年轻代大小选择 响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。 吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。 2.年老代大小选择 响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得： 并发垃圾收集信息 持久代并发收集次数 传统GC信息 花在年轻代和年老代回收上的时间比例 减少年轻代和年老代花费的时间，一般会提高应用的效率 吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。 3.较小堆引起的碎片问题因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置： -XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。 -XX:CMSFullGCsBeforeCompaction=0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"Minor GC、Major GC和Full GC之间的区别","slug":"20170924_GC之间的区别","date":"2020-01-15T05:50:39.642Z","updated":"2021-03-10T15:33:38.677Z","comments":true,"path":"2020/01/15/20170924_GC之间的区别/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170924_GC之间的区别/","excerpt":"转载链接地址: http://www.importnew.com/15820.html","text":"转载链接地址: http://www.importnew.com/15820.html 在 Plumbr 从事 GC 暂停检测相关功能的工作时，我被迫用自己的方式，通过大量文章、书籍和演讲来介绍我所做的工作。在整个过程中，经常对 Minor、Major、和 Full GC 事件的使用感到困惑。这也是我写这篇博客的原因，我希望能清楚地解释这其中的一些疑惑。 文章要求读者熟悉 JVM 内置的通用垃圾回收原则。堆内存划分为 Eden、Survivor 和 Tenured/Old 空间，代假设和其他不同的 GC 算法超出了本文讨论的范围。 Minor GC从年轻代空间（包括 Eden 和 Survivor 区域）回收内存被称为 Minor GC。这一定义既清晰又易于理解。但是，当发生Minor GC事件的时候，有一些有趣的地方需要注意到： 当 JVM 无法为一个新的对象分配空间时会触发 Minor GC，比如当 Eden 区满了。所以分配率越高，越频繁执行 Minor GC。内存池被填满的时候，其中的内容全部会被复制，指针会从0开始跟踪空闲内存。Eden 和 Survivor 区进行了标记和复制操作，取代了经典的标记、扫描、压缩、清理操作。所以 Eden 和 Survivor 区不存在内存碎片。写指针总是停留在所使用内存池的顶部。执行 Minor GC 操作时，不会影响到永久代。从永久代到年轻代的引用被当成 GC roots，从年轻代到永久代的引用在标记阶段被直接忽略掉。质疑常规的认知，所有的 Minor GC 都会触发“全世界的暂停（stop-the-world）”，停止应用程序的线程。对于大部分应用程序，停顿导致的延迟都是可以忽略不计的。其中的真相就 是，大部分 Eden 区中的对象都能被认为是垃圾，永远也不会被复制到 Survivor 区或者老年代空间。如果正好相反，Eden 区大部分新生对象不符合 GC 条件，Minor GC 执行时暂停的时间将会长很多。所以 Minor GC 的情况就相当清楚了——每次 Minor GC 会清理年轻代的内存。 Major GC vs Full GC大家应该注意到，目前，这些术语无论是在 JVM 规范还是在垃圾收集研究论文中都没有正式的定义。但是我们一看就知道这些在我们已经知道的基础之上做出的定义是正确的，Minor GC 清理年轻带内存应该被设计得简单： Major GC 是清理老年代。Full GC 是清理整个堆空间—包括年轻代和老年代。很不幸，实际上它还有点复杂且令人困惑。首先，许多 Major GC 是由 Minor GC 触发的，所以很多情况下将这两种 GC 分离是不太可能的。另一方面，许多现代垃圾收集机制会清理部分永久代空间，所以使用“cleaning”一词只是部分正确。 这使得我们不用去关心到底是叫 Major GC 还是 Full GC，大家应该关注当前的 GC 是否停止了所有应用程序的线程，还是能够并发的处理而不用停掉应用程序的线程。 这种混乱甚至内置到 JVM 标准工具。下面一个例子很好的解释了我的意思。让我们比较两个不同的工具 Concurrent Mark 和 Sweep collector (-XX:+UseConcMarkSweepGC)在 JVM 中运行时输出的跟踪记录。 第一次尝试通过 jstat 输出： my-precious: me$ jstat -gc -t 4235 1s Time S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 5.7 34048.0 34048.0 0.0 34048.0 272640.0 194699.7 1756416.0 181419.9 18304.0 17865.1 2688.0 2497.6 3 0.275 0 0.000 0.275 6.7 34048.0 34048.0 34048.0 0.0 272640.0 247555.4 1756416.0 263447.9 18816.0 18123.3 2688.0 2523.1 4 0.359 0 0.000 0.359 7.7 34048.0 34048.0 0.0 34048.0 272640.0 257729.3 1756416.0 345109.8 19072.0 18396.6 2688.0 2550.3 5 0.451 0 0.000 0.451 8.7 34048.0 34048.0 34048.0 34048.0 272640.0 272640.0 1756416.0 444982.5 19456.0 18681.3 2816.0 2575.8 7 0.550 0 0.000 0.550 9.7 34048.0 34048.0 34046.7 0.0 272640.0 16777.0 1756416.0 587906.3 20096.0 19235.1 2944.0 2631.8 8 0.720 0 0.000 0.72010.7 34048.0 34048.0 0.0 34046.2 272640.0 80171.6 1756416.0 664913.4 20352.0 19495.9 2944.0 2657.4 9 0.810 0 0.000 0.81011.7 34048.0 34048.0 34048.0 0.0 272640.0 129480.8 1756416.0 745100.2 20608.0 19704.5 2944.0 2678.4 10 0.896 0 0.000 0.89612.7 34048.0 34048.0 0.0 34046.6 272640.0 164070.7 1756416.0 822073.7 20992.0 19937.1 3072.0 2702.8 11 0.978 0 0.000 0.97813.7 34048.0 34048.0 34048.0 0.0 272640.0 211949.9 1756416.0 897364.4 21248.0 20179.6 3072.0 2728.1 12 1.087 1 0.004 1.09114.7 34048.0 34048.0 0.0 34047.1 272640.0 245801.5 1756416.0 597362.6 21504.0 20390.6 3072.0 2750.3 13 1.183 2 0.050 1.23315.7 34048.0 34048.0 0.0 34048.0 272640.0 21474.1 1756416.0 757347.0 22012.0 20792.0 3200.0 2791.0 15 1.336 2 0.050 1.38616.7 34048.0 34048.0 34047.0 0.0 272640.0 48378.0 1756416.0 838594.4 22268.0 21003.5 3200.0 2813.2 16 1.433 2 0.050 1.484 这个片段是 JVM 启动后第17秒提取的。基于该信息，我们可以得出这样的结果，运行了12次 Minor GC、2次 Full GC，时间总跨度为50毫秒。通过 jconsole 或者 jvisualvm 这样的基于GUI的工具你能得到同样的结果。 java -XX:+PrintGCDetails -XX:+UseConcMarkSweepGC eu.plumbr.demo.GarbageProducer 3.157: [GC (Allocation Failure) 3.157: [ParNew: 272640K-&gt;34048K(306688K), 0.0844702 secs] 272640K-&gt;69574K(2063104K), 0.0845560 secs] [Times: user=0.23 sys=0.03, real=0.09 secs]4.092: [GC (Allocation Failure) 4.092: [ParNew: 306688K-&gt;34048K(306688K), 0.1013723 secs] 342214K-&gt;136584K(2063104K), 0.1014307 secs] [Times: user=0.25 sys=0.05, real=0.10 secs]… cut for brevity …11.292: [GC (Allocation Failure) 11.292: [ParNew: 306686K-&gt;34048K(306688K), 0.0857219 secs] 971599K-&gt;779148K(2063104K), 0.0857875 secs] [Times: user=0.26 sys=0.04, real=0.09 secs]12.140: [GC (Allocation Failure) 12.140: [ParNew: 306688K-&gt;34046K(306688K), 0.0821774 secs] 1051788K-&gt;856120K(2063104K), 0.0822400 secs] [Times: user=0.25 sys=0.03, real=0.08 secs]12.989: [GC (Allocation Failure) 12.989: [ParNew: 306686K-&gt;34048K(306688K), 0.1086667 secs] 1128760K-&gt;931412K(2063104K), 0.1087416 secs] [Times: user=0.24 sys=0.04, real=0.11 secs]13.098: [GC (CMS Initial Mark) [1 CMS-initial-mark: 897364K(1756416K)] 936667K(2063104K), 0.0041705 secs] [Times: user=0.02 sys=0.00, real=0.00 secs]13.102: [CMS-concurrent-mark-start]13.341: [CMS-concurrent-mark: 0.238/0.238 secs] [Times: user=0.36 sys=0.01, real=0.24 secs]13.341: [CMS-concurrent-preclean-start]13.350: [CMS-concurrent-preclean: 0.009/0.009 secs] [Times: user=0.03 sys=0.00, real=0.01 secs]13.350: [CMS-concurrent-abortable-preclean-start]13.878: [GC (Allocation Failure) 13.878: [ParNew: 306688K-&gt;34047K(306688K), 0.0960456 secs] 1204052K-&gt;1010638K(2063104K), 0.0961542 secs] [Times: user=0.29 sys=0.04, real=0.09 secs]14.366: [CMS-concurrent-abortable-preclean: 0.917/1.016 secs] [Times: user=2.22 sys=0.07, real=1.01 secs]14.366: [GC (CMS Final Remark) [YG occupancy: 182593 K (306688 K)]14.366: [Rescan (parallel) , 0.0291598 secs]14.395: [weak refs processing, 0.0000232 secs]14.395: [class unloading, 0.0117661 secs]14.407: [scrub symbol table, 0.0015323 secs]14.409: [scrub string table, 0.0003221 secs][1 CMS-remark: 976591K(1756416K)] 1159184K(2063104K), 0.0462010 secs] [Times: user=0.14 sys=0.00, real=0.05 secs]14.412: [CMS-concurrent-sweep-start]14.633: [CMS-concurrent-sweep: 0.221/0.221 secs] [Times: user=0.37 sys=0.00, real=0.22 secs]14.633: [CMS-concurrent-reset-start]14.636: [CMS-concurrent-reset: 0.002/0.002 secs] [Times: user=0.00 sys=0.00, real=0.00 在点头同意这个结论之前，让我们看看来自同一个 JVM 启动收集的垃圾收集日志的输出。显然- XX ： + PrintGCDetails 告诉我们一个不同且更详细的故事： 基于这些信息，我们可以看到12次 Minor GC 后开始有些和上面不一样了。没有运行两次 Full GC，这不同的地方在于单个 GC 在永久代中不同阶段运行了两次： 最初的标记阶段，用了0.0041705秒也就是4ms左右。这个阶段会暂停“全世界（ stop-the-world）”的事件，停止所有应用程序的线程，然后开始标记。 并行执行标记和清洗阶段。这些都是和应用程序线程并行的。 最后 Remark 阶段，花费了0.0462010秒约46ms。这个阶段会再次暂停所有的事件。 并行执行清理操作。正如其名，此阶段也是并行的，不会停止其他线程。 所以，正如我们从垃圾回收日志中所看到的那样，实际上只是执行了 Major GC 去清理老年代空间而已，而不是执行了两次 Full GC。 如果你是后期做决 定的话，那么由 jstat 提供的数据会引导你做出正确的决策。它正确列出的两个暂停所有事件的情况，导致所有线程停止了共计50ms。但是如果你试图优化吞吐量，你会被误导的。清 单只列出了回收初始标记和最终 Remark 阶段，jstat的输出看不到那些并发完成的工作。 结论考虑到这种情况，最好避免以 Minor、Major、Full GC 这种方式来思考问题。而应该监控应用延迟或者吞吐量，然后将 GC 事件和结果联系起来。 随着这些 GC 事件的发生，你需要额外的关注某些信息，GC 事件是强制所有应用程序线程停止了还是并行的处理了部分事件。 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"JVM的年轻代以及GC回收细节","slug":"20170924_JVM的年轻代以及GC回收细节","date":"2020-01-15T05:50:39.641Z","updated":"2021-03-10T15:20:21.800Z","comments":true,"path":"2020/01/15/20170924_JVM的年轻代以及GC回收细节/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170924_JVM的年轻代以及GC回收细节/","excerpt":"转载自并发编程网 链接地址: http://ifeve.com/jvm-yong-generation/","text":"转载自并发编程网 链接地址: http://ifeve.com/jvm-yong-generation/ 为什么会有年轻代我们先来屡屡，为什么需要把堆分代？不分代不能完成他所做的事情么？其实不分代完全可以，分代的唯一理由就是优化GC性能。你先想想，如果没有分代，那我们所有的对象都在一块，GC的时候我们要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而我们的很多对象都是朝生夕死的，如果分代的话，我们把新创建的对象放到某一地方，当GC的时候先把这块存“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。 年轻代中的GCHotSpot JVM把年轻代分为了三部分：1个Eden区和2个Survivor区（分别叫from和to）。默认比例为8：1,为啥默认会是这个比例，接下来我们会聊到。一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理),这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。 因为年轻代中的对象基本都是朝生夕死的(80%以上)，所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。 在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。 一个对象的这一辈子我是一个普通的java对象，我出生在Eden区，在Eden区我还看到和我长的很像的小兄弟，我们在Eden区中玩了挺长时间。有一天Eden区中的人实在是太多了，我就被迫去了Survivor区的“From”区，自从去了Survivor区，我就开始漂了，有时候在Survivor的“From”区，有时候在Survivor的“To”区，居无定所。直到我18岁的时候，爸爸说我成人了，该去社会上闯闯了。于是我就去了年老代那边，年老代里，人很多，并且年龄都挺大的，我在这里也认识了很多人。在年老代里，我生活了20年(每次GC加一岁)，然后被回收。 有关年轻代的JVM参数1)-XX:NewSize和-XX:MaxNewSize 用于设置年轻代的大小，建议设为整个堆大小的1/3或者1/4,两个值设为一样大。 2)-XX:SurvivorRatio 用于设置Eden和其中一个Survivor的比值，这个值也比较重要。 3)-XX:+PrintTenuringDistribution 这个参数用于显示每次Minor GC时Survivor区中各个年龄段的对象的大小。 4).-XX:InitialTenuringThreshol和-XX:MaxTenuringThreshold 用于设置晋升到老年代的对象年龄的最小值和最大值，每个对象在坚持过一次Minor GC之后，年龄就加1。 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"JVM运行原理","slug":"20170924_JVM运行原理","date":"2020-01-15T05:50:39.639Z","updated":"2021-05-31T14:52:06.249Z","comments":true,"path":"2020/01/15/20170924_JVM运行原理/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170924_JVM运行原理/","excerpt":"1、动态编译（dynamic compilation）指的是“在运行时进行编译”；与之相对的是事前编译（ahead-of-time compilation，简称AOT），也叫静态编译（static compilation）。 2、JIT编译（just-in-time compilation）狭义来说是当某段代码即将第一次被执行时进行编译，因而叫“即时编译”。JIT编译是动态编译的一种特例。JIT编译一词后来被泛化，时常与动态编译等价；但要注意广义与狭义的JIT编译所指的区别。 3、自适应动态编译（adaptive dynamic compilation）也是一种动态编译，但它通常执行的时机比JIT编译迟，先让程序“以某种式”先运行起来，收集一些信息之后再做动态编译。这样的编译可以更加优化。","text":"1、动态编译（dynamic compilation）指的是“在运行时进行编译”；与之相对的是事前编译（ahead-of-time compilation，简称AOT），也叫静态编译（static compilation）。 2、JIT编译（just-in-time compilation）狭义来说是当某段代码即将第一次被执行时进行编译，因而叫“即时编译”。JIT编译是动态编译的一种特例。JIT编译一词后来被泛化，时常与动态编译等价；但要注意广义与狭义的JIT编译所指的区别。 3、自适应动态编译（adaptive dynamic compilation）也是一种动态编译，但它通常执行的时机比JIT编译迟，先让程序“以某种式”先运行起来，收集一些信息之后再做动态编译。这样的编译可以更加优化。 概述JVM运行原理 在部分商用虚拟机中（如HotSpot），Java程序最初是通过解释器（Interpreter）进行解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁时，就会把这些代码认定为“热点代码”。为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器称为即时编译器（Just In Time Compiler，下文统称JIT编译器）。即时编译器并不是虚拟机必须的部分，Java虚拟机规范并没有规定Java虚拟机内必须要有即时编译器存在，更没有限定或指导即时编译器应该如何去实现。但是，即时编译器编译性能的好坏、代码优化程度的高低却是衡量一款商用虚拟机优秀与否的最关键的指标之一，它也是虚拟机中最核心且最能体现虚拟机技术水平的部分。 由于Java虚拟机规范并没有具体的约束规则去限制即使编译器应该如何实现，所以这部分功能完全是与虚拟机具体实现相关的内容，如无特殊说明，我们提到的编译器、即时编译器都是指Hotspot虚拟机内的即时编译器，虚拟机也是特指HotSpot虚拟机。 为什么HotSpot虚拟机要使用解释器与编译器并存的架构？尽管并不是所有的Java虚拟机都采用解释器与编译器并存的架构，但许多主流的商用虚拟机（如HotSpot），都同时包含解释器和编译器。解释器与编译器两者各有优势：当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率。当程序运行环境中内存资源限制较大（如部分嵌入式系统中），可以使用解释器执行节约内存，反之可以使用编译执行来提升效率。此外，如果编译后出现“罕见陷阱”，可以通过逆优化退回到解释执行。 编译的时间开销解释器的执行，抽象的看是这样的：输入的代码 -&gt; [ 解释器 解释执行 ] -&gt; 执行结果而要JIT编译然后再执行的话，抽象的看则是：输入的代码 -&gt; [ 编译器 编译 ] -&gt; 编译后的代码 -&gt; [ 执行 ] -&gt; 执行结果说JIT比解释快，其实说的是“执行编译后的代码”比“解释器解释执行”要快，并不是说“编译”这个动作比“解释”这个动作快。JIT编译再怎么快，至少也比解释执行一次略慢一些，而要得到最后的执行结果还得再经过一个“执行编译后的代码”的过程。所以，对“只执行一次”的代码而言，解释执行其实总是比JIT编译执行要快。 怎么算是“只执行一次的代码”呢？粗略说，下面两个条件同时满足时就是严格的“只执行一次”1、只被调用一次，例如类的构造器（class initializer，()）2、没有循环 对只执行一次的代码做JIT编译再执行，可以说是得不偿失。对只执行少量次数的代码，JIT编译带来的执行速度的提升也未必能抵消掉最初编译带来的开销。只有对频繁执行的代码，JIT编译才能保证有正面的收益。 编译的空间开销对一般的Java方法而言，编译后代码的大小相对于字节码的大小，膨胀比达到10x是很正常的。同上面说的时间开销一样，这里的空间开销也是，只有对执行频繁的代码才值得编译，如果把所有代码都编译则会显著增加代码所占空间，导致“代码爆炸”。这也就解释了为什么有些JVM会选择不总是做JIT编译，而是选择用解释器+JIT编译器的混合执行引擎。 为何HotSpot虚拟机要实现两个不同的即时编译器？HotSpot虚拟机中内置了两个即时编译器：Client Complier和Server Complier，简称为C1、C2编译器，分别用在客户端和服务端。目前主流的HotSpot虚拟机中默认是采用解释器与其中一个编译器直接配合的方式工作。程序使用哪个编译器，取决于虚拟机运行的模式。HotSpot虚拟机会根据自身版本与宿主机器的硬件性能自动选择运行模式，用户也可以使用“-client”或“-server”参数去强制指定虚拟机运行在Client模式或Server模式。用Client Complier获取更高的编译速度，用Server Complier 来获取更好的编译质量;为什么提供多个即时编译器与为什么提供多个垃圾收集器类似，都是为了适应不同的应用场景。 哪些程序代码会被编译为本地代码？如何编译为本地代码？程序中的代码只有是热点代码时，才会编译为本地代码，那么什么是热点代码呢？运行过程中会被即时编译器编译的“热点代码”有两类：1、被多次调用的方法。2、被多次执行的循环体。两种情况，编译器都是以整个方法作为编译对象。 这种编译方法因为编译发生在方法执行过程之中，因此形象的称之为栈上替换（On Stack Replacement，OSR），即方法栈帧还在栈上，方法就被替换了 如何判断方法或一段代码或是不是热点代码呢？要知道方法或一段代码是不是热点代码，是不是需要触发即时编译，需要进行Hot Spot Detection（热点探测）。目前主要的热点探测方式有以下两种： 基于采样的热点探测 采用这种方法的虚拟机会周期性地检查各个线程的栈顶，如果发现某些方法经常出现在栈顶，那这个方法就是“热点方法”。这种探测方法的好处是实现简单高效，还可以很容易地获取方法调用关系（将调用堆栈展开即可），缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测。 基于计数器的热点探测 采用这种方法的虚拟机会为每个方法（甚至是代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阀值，就认为它是“热点方法”。这种统计方法实现复杂一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，但是它的统计结果相对更加精确严谨。 HotSpot虚拟机中使用的是哪钟热点检测方式呢？在HotSpot虚拟机中使用的是第二种——基于计数器的热点探测方法，因此它为每个方法准备了两个计数器：方法调用计数器和回边计数器。在确定虚拟机运行参数的前提下，这两个计数器都有一个确定的阈值，当计数器超过阈值溢出了，就会触发JIT编译。 方法调用计数器 顾名思义，这个计数器用于统计方法被调用的次数。 当一个方法被调用时，会先检查该方法是否存在被JIT编译过的版本，如果存在，则优先使用编译后的本地代码来执行。如果不存在已被编译过的版本，则将此方法的调用计数器值加1，然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阈值。如果超过阈值，那么将会向即时编译器提交一个该方法的代码编译请求。 如果不做任何设置，执行引擎并不会同步等待编译请求完成，而是继续进行解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成。当编译工作完成之后，这个方法的调用入口地址就会系统自动改写成新的，下一次调用该方法时就会使用已编译的版本。 回边计数器 它的作用就是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为“回边”。 如何编译为本地代码？Server Compiler和Client Compiler两个编译器的编译过程是不一样的。对Client Compiler来说，它是一个简单快速的编译器，主要关注点在于局部优化，而放弃许多耗时较长的全局优化手段。而Server Compiler则是专门面向服务器端的，并为服务端的性能配置特别调整过的编译器，是一个充分优化过的高级编译器。 参考:《深入理解Java虚拟机》http://blog.csdn.net/u010412719/article/details/47008717https://zhuanlan.zhihu.com/p/19977592http://www.zhihu.com/question/37389356/answer/73820511 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"图","slug":"20170922_map","date":"2020-01-15T05:50:39.638Z","updated":"2021-03-10T15:20:21.704Z","comments":true,"path":"2020/01/15/20170922_map/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170922_map/","excerpt":"##图: 图是由顶点集（VertexSet）和边集（EdgeSet）组成，针对图G，顶点集和边集分别记为V(G)和E(G)。依据图的边集是否为有向，可把图分为有向图和无向图，根据图是否有权重，可以分为有权图和无权图。 线性表中的元素是“一对一”的关系，树中的元素是“一对多”的关系，而图结构中的元素则是“多对多”的关系 顶点(Vertex)、弧(Arc)、弧头(初始点)、弧尾(终结点)、边(Edge)、有向图(Directed graph)、 无向图(Undigraph)、完全图(Completed grapg)、有向完全图、稀疏图(Sparse graph)、 稠密图(Dense graph)、权(weigh)、网(network)、无向网、有向网、子图(Subgraph)、 邻接点(Adjacent)、度(Degree)、入度(Indegree)、出度(Outdegree)、路径(path)、 回路(环)、简单路径、简单回路（简单环）、连通、连通图(Connected graph)、连通分量(Connected Component)、 强连通图、强连通分量(有向图中的极大强连通子图)、生成树、极小连通子图、有向树。","text":"##图: 图是由顶点集（VertexSet）和边集（EdgeSet）组成，针对图G，顶点集和边集分别记为V(G)和E(G)。依据图的边集是否为有向，可把图分为有向图和无向图，根据图是否有权重，可以分为有权图和无权图。 线性表中的元素是“一对一”的关系，树中的元素是“一对多”的关系，而图结构中的元素则是“多对多”的关系 顶点(Vertex)、弧(Arc)、弧头(初始点)、弧尾(终结点)、边(Edge)、有向图(Directed graph)、 无向图(Undigraph)、完全图(Completed grapg)、有向完全图、稀疏图(Sparse graph)、 稠密图(Dense graph)、权(weigh)、网(network)、无向网、有向网、子图(Subgraph)、 邻接点(Adjacent)、度(Degree)、入度(Indegree)、出度(Outdegree)、路径(path)、 回路(环)、简单路径、简单回路（简单环）、连通、连通图(Connected graph)、连通分量(Connected Component)、 强连通图、强连通分量(有向图中的极大强连通子图)、生成树、极小连通子图、有向树。 ##图的存储: 邻接矩阵:用一个二维数组表示图中顶点和顶点,边的关系;形成的矩阵中可以自定义边的权值表示, 例如:0表示没有边, 其他大于0的数n表示两个顶点有边且权值为n 邻接表 接矩阵与邻接表相比，它会造成空间的一定损失，它需要为每个顶点都分配n个边的空间， 其实有很多边都是不存在边，但是邻接表的实现就不一样，它只关心存在的边，不关心不存在的边。 ##图的遍历: 1.广度优先 1.从isTrav数组中选择一个未被访问的邻接点,标记为已访问 2.依次访问Vi的所有未被访问的邻接点,并标记为已被访问 3.从邻接点出发进行广度优先遍历,直到图中所有和Vi有路径相通的顶点都被访问 4.重复1-3的步骤直到所有的顶点都被访问 2.深度优先 1.从isTrav数组中选择一个未被访问的邻接点Vi,标记为已访问 2.从Vi邻接点出发进行深度优先遍历 3.重复2步骤,直到所有的和Vi有路径相通的顶点都被访问过 4.重复1-3操作,直到所有顶点都被访问过 ##代码演示 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798//邻接矩阵 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #define VERTEX_MAX 26 #define MAXVALUE 32767 //表示当权值为MAXVALUE时,两个顶点没有相连 typedef struct &#123; char Vertex[VERTEX_MAX]; //保存顶点信息（序号或字母） int Edges[VERTEX_MAX][VERTEX_MAX]; //保存边的权 int isTrav[VERTEX_MAX]; //遍历标志 int VertexNum; //顶点数量 int EdgeNum; //边数量 int GraphType; //图的类型(0无向图 1有向图) &#125; MatrixGraph; //定义邻接矩阵图结构 void CreateMatrixGraph(MatrixGraph *G); //创建邻接矩阵图 void OutMatrix(MatrixGraph *G); //输出邻接矩阵 void CreateMatrixGraph(MatrixGraph *G) &#123; int i, j, k, weight; char start, end; //边的起始顶点 printf(\"输入各顶点的信息：\\n\"); //输入顶点 for(i=0; i&lt;G-&gt;VertexNum; i++) &#123; fflush(stdin); printf(\"第%d个顶点信息：\", i+1); scanf(\"%c\", &amp;(G-&gt;Vertex[i])); &#125; printf(\"输入构成各边的两个顶点以及权值：\\n\"); for(k=0; k&lt;G-&gt;EdgeNum; k++) &#123; printf(\"第%d条边：\", k+1); fflush(stdin); scanf(\"%c %c %d\", &amp;start, &amp;end, &amp;weight); for(i=0; start!=G-&gt;Vertex[i]; i++); //查找已有的顶点中是否包含当前的\"起始顶点\" for(j=0; end!=G-&gt;Vertex[j]; j++); //同上 // printf(\"%d %d\", i, j); G-&gt;Edges[i][j] = weight; //对应位置保存权值，表示有一条边 if(G-&gt;GraphType == 0) //判断是不是无向图 &#123; G-&gt;Edges[j][i] = weight; //在对角位置保存权值 &#125; &#125; &#125; void OutMatrix(MatrixGraph *G) &#123; int i, j; printf(\" \"); for(j=0; j&lt;G-&gt;VertexNum; j++) printf(\"\\t%c\", G-&gt;Vertex[j]); //输出顶点信息 printf(\"\\n\"); for(i=0; i&lt;G-&gt;VertexNum; i++) &#123; printf(\"%c\", G-&gt;Vertex[i]); for(j=0; j&lt;G-&gt;VertexNum; j++) &#123; if(G-&gt;Edges[i][j] &gt;= MAXVALUE) //如果权值为最大值 printf(\"\\t #\"); //输出无穷大符号 else printf(\"\\t%d\", G-&gt;Edges[i][j]); //输出边的权值 &#125; printf(\"\\n\"); &#125; &#125; int main() &#123; MatrixGraph G; int i, j; printf(\"输入生成图的类型 （0无向图 1有向图）\"); scanf(\"%d\", &amp;G.GraphType); printf(\"输入图的顶点数量和边数量\"); scanf(\"%d %d\", &amp;G.VertexNum, &amp;G.EdgeNum); //输入图顶点数和边数 for(i=0; i&lt;G.VertexNum; i++) &#123; for(j=0; j&lt;G.VertexNum; j++) &#123; G.Edges[i][j] = MAXVALUE; //初始化元素值为最大值 &#125; &#125; CreateMatrixGraph(&amp;G); OutMatrix(&amp;G); return 0; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586//邻接表 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #define VERTEX_MAX 26 typedef struct edgeNode &#123; int Vertex; //顶点信息 int weight; //权值 struct edgeNode *next; //下一个顶点地址指针 &#125;EdgeNode; //边的结构 typedef struct &#123; EdgeNode* AdjList[VERTEX_MAX]; //顶点指针 int VextexNum, EdgeNum; //顶点数量,边数量 int GraphType; //图的类型(0无向图 1有向图) &#125;ListGraph; //图的结构 void CreateGraph(ListGraph *G); void OutList(ListGraph *G); void CreateGraph(ListGraph *G) &#123; int i, weight; int start, end; EdgeNode *s; for(i=0; i&lt;=G-&gt;VextexNum; i++) //初始化 G-&gt;AdjList[i] = NULL; printf(\"输入构成各边的两个顶点以及权值：\\n\"); for(i=0; i&lt;G-&gt;EdgeNum; i++) &#123; printf(\"第%d条边 开始顶点 结束顶点 权值\", i+1); fflush(stdin); scanf(\"%d %d %d\", &amp;start, &amp;end, &amp;weight); s = (EdgeNode *)malloc(sizeof(EdgeNode)); s-&gt;next = G-&gt;AdjList[start]; s-&gt;Vertex = end; s-&gt;weight = weight; G-&gt;AdjList[start] = s;//把生成的边信息赋值给图 if(G-&gt;GraphType == 0) //判断是不是有向图 &#123; s = (EdgeNode *)malloc(sizeof(EdgeNode)); s-&gt;next = G-&gt;AdjList[end]; s-&gt;Vertex = start; s-&gt;weight = weight; G-&gt;AdjList[end] = s;//把生成的边信息赋值给图 &#125; &#125; &#125; void OutList(ListGraph *G) &#123; int i; EdgeNode *s; for(i=0; i&lt;=G-&gt;VextexNum; i++) &#123; printf(\"顶点%d\", i); s = G-&gt;AdjList[i]; while(s) &#123; printf(\"-&gt;%d(%d)\", s-&gt;Vertex, s-&gt;weight); s = s-&gt;next; &#125; printf(\"\\n\"); &#125; &#125; int main() &#123; ListGraph G; printf(\"输入生成图的类型 （0无向图 1有向图）\"); scanf(\"%d\", &amp;G.GraphType); printf(\"输入图的顶点数量和边数量\"); scanf(\"%d %d\", &amp;G.VextexNum, &amp;G.EdgeNum); CreateGraph(&amp;G); OutList(&amp;G); return 0; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174//深度优先和广度优先 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include \"AdjMatrixGraph.h\" #define QUEUE_MAXSIZE 30 //队列的最大容量 typedef struct &#123; int Data[QUEUE_MAXSIZE];//数据域 int head; //队头指针 int tail; //队尾指针 &#125;SeqQueue; //队列结构 //队列操作函数 void QueueInit(SeqQueue *q); //初始化一个队列 int QueueIsEmpty(SeqQueue q); //判断队列是否为空 int QueueIn(SeqQueue *q, int n); //入队 int QueueOut(SeqQueue *q, int *ch); //出队 //图操作函数 void DFSTraverse(MatrixGraph *G); //深度优先遍历 void BFSTraverse(MatrixGraph *G); //广度优先遍历 void DFSM(MatrixGraph *G, int i); void BFSM(MatrixGraph *G, int i); void QueueInit(SeqQueue *q)&#123; q-&gt;head = q-&gt;tail = 0; &#125; int QueueIsEmpty(SeqQueue q) &#123; return q.head = q.tail; &#125; int QueueIn(SeqQueue *q, int n) &#123; if((q-&gt;tail + 1) % q-&gt;head != 0) &#123; q-&gt;Data[q-&gt;tail] = n; q-&gt;tail = (q-&gt;tail + 1) % QUEUE_MAXSIZE; return 1; &#125; else &#123; return 0; &#125; &#125; int QueueOut(SeqQueue *q, int *ch) &#123; if(q-&gt;head != q-&gt;tail) &#123; *ch = q-&gt;Data[q-&gt;head]; q-&gt;head = (q-&gt;head + 1) % QUEUE_MAXSIZE; return 1; &#125; else &#123; return 0; &#125; &#125; void DFSTraverse(MatrixGraph *G) &#123; int i; for(i=0; i&lt;G-&gt;VertexNum; i++) &#123; G-&gt;isTrav[i] = 0; &#125; printf(\"深度优先遍历\"); for(i=0; i&lt;G-&gt;VertexNum; i++) &#123; if(!G-&gt;isTrav[i]) &#123; DFSM(G, i); &#125; &#125; &#125; void BFSTraverse(MatrixGraph *G) &#123; int i; for(i=0; i&lt;G-&gt;VertexNum; i++) &#123; G-&gt;isTrav[i] = 0; &#125; printf(\"广度优先遍历\"); for(i=0; i&lt;G-&gt;VertexNum; i++) &#123; if(!G-&gt;isTrav[i]) &#123; BFSM(G, i); &#125; &#125; &#125; void DFSM(MatrixGraph *G, int i) &#123; int j; G-&gt;isTrav[i] = i; printf(\"-&gt;%c\", G-&gt;Vertex[i]); for(j=0; j&lt;G-&gt;VertexNum; j++) &#123; if(G-&gt;Edges[i][j] != MAXVALUE &amp;&amp; !G-&gt;isTrav[i]) &#123; DFSM(G, j); &#125; &#125; &#125; void BFSM(MatrixGraph *G, int k) &#123; int i, j; SeqQueue Q; QueueInit(&amp;Q); G-&gt;isTrav[k] = 1; printf(\"-&gt;%c\", G-&gt;Vertex[k]); QueueIn(&amp;Q, k); while(!QueueIsEmpty(Q)) &#123; QueueOut(&amp;Q, &amp;i); for(j=0; j&lt;G-&gt;VertexNum; j++) &#123; if(G-&gt;Edges[i][j] != MAXVALUE &amp;&amp; !G-&gt;isTrav[j]) &#123; printf(\"-&gt;%c\", G-&gt;Vertex[j]); G-&gt;isTrav[j] = 1; QueueIn(&amp;Q, j); &#125; &#125; &#125; &#125; int main() &#123; MatrixGraph G; int i, j; char select; do &#123; printf(\"输入生成图的类型: (0:无向图, 1:有向图)\"); fflush(stdin); scanf(\"%d\", &amp;G.GraphType); printf(\"输入图的顶点数量和边数量\"); fflush(stdin); scanf(\"%d %d\", &amp;G.VertexNum, &amp;G.EdgeNum); for(i=0; i&lt;G.VertexNum; i++) &#123; for(j=0; j&lt;G.VertexNum; j++) &#123; G.Edges[i][j] = MAXVALUE; &#125; &#125; CreateMatrixGraph(&amp;G); printf(\"邻接矩阵数据:\\n\"); OutMatrix(&amp;G); DFSTraverse(&amp;G); BFSTraverse(&amp;G); printf(\"两种遍历结束\"); fflush(stdin); scanf(\"%c\", &amp;select); &#125;while(select!= 'N' &amp;&amp; select != '\\n'); return 0; &#125; 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"网络协议记录","slug":"20170918_protocol","date":"2020-01-15T05:50:39.636Z","updated":"2021-03-10T15:20:21.741Z","comments":true,"path":"2020/01/15/20170918_protocol/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170918_protocol/","excerpt":"","text":"ISO: (International Organization for Standards) 国际标准化组织 OSI(参考模型): (Open Systems Interconnection) 开放式通信系统互联网参考模型：把通信功能划分为7个分层 OSI协议: OSI协议以OSI参考模型为基础界定了每个阶层的协议和每个阶层之间接口相关的标准；遵循OSI协议的的产品为OSI产品； MAC地址: (Media Access Control)介质访问控制；也叫物理地址、硬件地址； Unicast: 单播；Broadcast: 广播；Multicast: 多播；Anycast: 任播 网卡: NIC(Network Interface Card)，使计算机联网的设备 中继器: (Repeater) ，物理层上延长网络的设备(处于第一层) 由电缆传过来的电信号或光信号经由中继器的波形调整和放大再传给另一个电缆 网桥: (Bridge) 也叫2层交换机，从数据链路层上延长网络的设备(处于第二层)，根据MAC地址进行处理 能识别数据帧，并把数据帧临时存储于内存，并重新生成信号作为新的帧转发给相连的另一个网段 地址自学机制 地址过滤功能 路由器: (Router) 也叫3层交换机，通过网络层转发分组数据的设备(处于第三层)，根据IP地址处理 4~7层交换机：处理传输层以上各层网络传输的设备 网关: (Gateway) 转换协议的设备，协议转换，数据转发(从传输层到应用层的数据转换、转发) FCS: (Frame Check Sequence) 帧检验序列，(网桥)校验数据是否正确的送达目的地 CRC: (Cyclic Redundancy Check) 循环冗余校验码，CRC循环冗余码校验FCS帧检验序列 ATM: (Asynchronous Transfer Mode) 异步传输 网络协议族: (Internet Protocol Suite) 组成网际协议的一组协议 IETF: (The Internet Engineering Task Force) 国际互联网工程任务组，一个公开性质的大型民间国际团体 RFC: (Request For Comment) 记录TCP/IP协议及其实现和运用信息 互联网: (The Internet) NOC: (Network Operation Center) 网络操作中心，互联网中每个网络由NOC相连 IX: (Internet Exchange) 网络交换中心，连接异构网络(不同运营商导致)需要IX支持 ISP: (Internet Service Provider) 互联网服务提供商 IP: (Internet Protocol)跨越网络传送数据包(分组交换) ICMP: (Internet Control Message Protocol) Internet控制报文协议， 当IP数据包发送途中发生异常无法达到目的地址，需要给发送端发送一个异常的通知(可以诊断网络健康状况) ARP: (Address Resolution Protocol)从分组数据包的IP地址中解析出物理地址(MAC地址)的一种协议 TCP: (Transmission Control Protocol) 传输控制协议，面向有连接，传输层协议， UDP: (User Datagram Protocol) 用户数据报协议，面向无连接，传输层协议， WWW: (World Wide Web) HTTP: (HyperText Transfer Protocol) 超文本传输协议 SMTP: (Simple Mail Transfer Protocol) MIME: () (表示层协议) FTP: (File Transfer Protocol) 文件传输协议 TELNET: 网络远程登陆协议 SSH: (Secure Shell) SNMP: (Simple Network Management Protocol) 简单网络管理协议 (应用层协议) 在TCP/IP中进行网络管理， 采用SNMP管理的主机、网桥、路由器称为SNMP代理(Agent)，进行管理的那一段叫做管理器(Manager) Agent和Manager用到该协议 在SNMP代理端，保存网络接口的信息、通信数据量、异常数据量等信息 可以及时检查网络拥堵情况 MIB: () (表示层协议) CSMA: (Carrier Sense Multiple Access) 载波侦听多路访问，争夺获取数据传输的权力 CSMA/CD: 相对于CSMA，要求每个站提前检测冲突，发生冲突，则尽早释放信道 FDDI: (Fiber Distributed Data Interface) 光纤分布式数据接口 BPDU: (Bridge Protocol Data Unit) 生成树方式中，每个网桥必须在每1-10秒内小胡交换BPDU包，用来判断哪些端口使用哪些不使用，以便消除环路 RSTP: (Rapid Spanning Tree Protocol) 能将发生环路时的恢复时间缩短到几秒之内 无线PAN: (Personal Area Network) 通信距离10米左右，应用：蓝牙 无线LAN: (Local Area Network) 通信距离100米左右，应用：Wi-Fi 无线MAN: (Metropolitan Area Network) 通信距离1km-100km，应用：WiMAX 无线RAN: (Regional Area Network) 通信距离200k-700km 无线WAN: (Wide Area Network) 应用3G,LTE,4G等 PPP: (Point to Point Protocol) 点对点协议，相当于2层的数据链路层 ppp协议的主要功能中主要包括两个协议： 1.LCP：(Link Control Protocol)，不依赖上层， 通过两次握手进行用户名密码验证，明文传输密码，不安全 主要负责建立和断开连接，设置最大接受单元（MRU，Maximum Receive Unit）， 设置验证协议[PAP(Password Authentication Protocol) 或 CHAP(Challenge Handshake Authentication Protocol)]， 设置进行通信质量监控与否 2.NCP: (Network Control Protocol)， 依赖上层，如果上层是IP，则此时NCP也叫IPCP 使用一次性密码OTP(One Time Password)， 安全，防止窃听 IPCP主要IP地址设置以及是否进行TCP/IP首部压缩等设置 ppp协议连接时，需要进行用户名密码验证 PPPoE: (PPP over Ethernet) 互联网接入服务商在以太网上提供PPP功能，可以提供计费功能 ADSL: (Asymmetric Digital Subscriber Line) 非对称数字用户环路 FTTH: (Fiber To The Home) 光纤到户 VPN: (Virtual Private Network) 虚拟专用网络 MTU: (Maximum Transmission Unit) 最大传输单元 CIDR: (Classless Inter-Domain Routing) 无类型域间选路 CIDR: (Border Gateway Protocol) 边界网关协议 VLSM: (Variable Length Subnet Mask) 可变长子网掩码 ICANN: (Internet Corporation for Assigned Names and Numbers) 互联网名称与数字地址分配机构 NAT: (Network Address Translation) 网络地址转换 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://zj2626.github.io/categories/计算机网络/"}],"tags":[{"name":"定义","slug":"定义","permalink":"http://zj2626.github.io/tags/定义/"}]},{"title":"待完成","slug":"20170911_syc","date":"2020-01-15T05:50:39.635Z","updated":"2021-03-10T13:50:15.344Z","comments":true,"path":"2020/01/15/20170911_syc/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170911_syc/","excerpt":"http://www.cnblogs.com/XHJT/p/3897440.html http://blog.csdn.net/suifeng3051/article/details/52611233","text":"http://www.cnblogs.com/XHJT/p/3897440.html http://blog.csdn.net/suifeng3051/article/details/52611233 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"待完成","slug":"20170911_list_clone","date":"2020-01-15T05:50:39.633Z","updated":"2021-03-10T13:50:15.395Z","comments":true,"path":"2020/01/15/20170911_list_clone/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170911_list_clone/","excerpt":"http://www.cnblogs.com/lyajs/p/5779021.html","text":"http://www.cnblogs.com/lyajs/p/5779021.html package collection; import org.junit.Test; import java.util.ArrayList; import java.util.ArrayList; /** * Created by zj on 2017/9/11. */ public class Link { @Test public void test() { ArrayList&lt;Student&gt; list = new ArrayList&lt;&gt;(); //添加两个元素 Student stJack = new Student(&quot;Jack&quot;, &quot;AAAA&quot;); Student stTom = new Student(&quot;Tom&quot;, &quot;BBBBB&quot;); list.add(stJack); list.add(stTom); //克隆 ArrayList&lt;Student&gt; listCopy = new ArrayList&lt;&gt;(); /*list.forEach(li -&gt; { listCopy.add(li); });*/ listCopy = (ArrayList&lt;Student&gt;) list.clone(); listCopy.get(1).setId(&quot;FFFFFFFFFFF&quot;); System.out.println(list); System.out.println(list.get(1).hashCode()); System.out.println(listCopy); System.out.println(listCopy.get(1).hashCode()); /*ArrayList&lt;String&gt; ArrayList = new ArrayList&lt;&gt;(); ArrayList.add(&quot;A&quot;); ArrayList.add(&quot;B&quot;); ArrayList.add(&quot;C&quot;); ArrayList.add(&quot;D&quot;); ArrayList.add(&quot;E&quot;); System.out.println(ArrayList.clone()); ArrayList.forEach(li -&gt; { System.out.println(li); });*/ } } package collection; import java.util.HashSet; import java.util.Set; /** * Created by zj on 2017/9/10. */ public class Student { private String id; private String name; private Set courses; public Student() { } public Student(String id, String name) { this.id = id; this.name = name; this.courses = new HashSet(); } public Student(String id, String name, Set courses) { this.id = id; this.name = name; this.courses = courses; } @Override public String toString() { return &quot;Student{&quot; + &quot;id=&apos;&quot; + id + &apos;\\&apos;&apos; + &quot;, name=&apos;&quot; + name + &apos;\\&apos;&apos; + &quot;, courses=&quot; + courses + &apos;}&apos;; } @Override protected Object clone() throws CloneNotSupportedException { return new Student(this.id, this.name); } public String getId() { return id; } public void setId(String id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Set getCourses() { return courses; } public void setCourses(Set courses) { this.courses = courses; } } public static void main(String[] args) { Map&lt;String, Student&gt; map = new HashMap&lt;String, Student&gt;(); map.put(&quot;a&quot;, new Student(&quot;A&quot;, &quot;FFF&quot;)); map.put(&quot;b&quot;, new Student(&quot;B&quot;, &quot;AAA&quot;)); map.put(&quot;d&quot;, new Student(&quot;D&quot;, &quot;KKK&quot;)); map.put(&quot;c&quot;, new Student(&quot;C&quot;, &quot;KKK&quot;)); List&lt;Map.Entry&lt;String, Student&gt;&gt; list = new ArrayList&lt;&gt;(map.entrySet()); Collections.sort(list, new Comparator&lt;Map.Entry&lt;String, Student&gt;&gt;() { @Override public int compare(Map.Entry&lt;String, Student&gt; o1, Map.Entry&lt;String, Student&gt; o2) { return o1.getValue().compareTo(o2.getValue()); } }); for (Map.Entry&lt;String, Student&gt; mapping : list) { System.out.println(mapping.getKey() + &quot;:&quot; + mapping.getValue()); } } 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"哈夫曼(霍夫曼)树以及哈夫曼编码","slug":"20170908_hfms","date":"2020-01-15T05:50:39.632Z","updated":"2021-03-10T15:20:21.711Z","comments":true,"path":"2020/01/15/20170908_hfms/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170908_hfms/","excerpt":"哈夫曼树：又称最优二叉树，是一种带权路径长度最短的二叉树；哈夫曼编码：哈夫曼树的一个应用，如JPEG中就应用； 所谓树的带权路径长度，就是树中所有的叶结点的权值乘上其到根结点的路径长度 （若根结点为0层，叶结点到根结点的路径长度为叶结点的层数）。 树的带权路径长度记为WPL = (W1*L1+W2*L2+W3*L3+...+Wn*Ln)， N个权值Wi(i=1,2,...n)构成一棵有N个叶结点的二叉树，相应的叶结点的路径长度为Li(i=1,2,...n)。 可以证明哈夫曼树的WPL是最小的。 一般权值用来表示频率大小，频率越大则权值越高","text":"哈夫曼树：又称最优二叉树，是一种带权路径长度最短的二叉树；哈夫曼编码：哈夫曼树的一个应用，如JPEG中就应用； 所谓树的带权路径长度，就是树中所有的叶结点的权值乘上其到根结点的路径长度 （若根结点为0层，叶结点到根结点的路径长度为叶结点的层数）。 树的带权路径长度记为WPL = (W1*L1+W2*L2+W3*L3+...+Wn*Ln)， N个权值Wi(i=1,2,...n)构成一棵有N个叶结点的二叉树，相应的叶结点的路径长度为Li(i=1,2,...n)。 可以证明哈夫曼树的WPL是最小的。 一般权值用来表示频率大小，频率越大则权值越高 参考博客1： http://www.cnblogs.com/junyuhuang/p/4127095.html 参考博客2： http://www.cnblogs.com/Jezze/archive/2011/12/23/2299884.html ####哈弗曼编码原理(转载) 哈夫曼编码使用一种特别的方法为信号源中的每个符号设定二进制码。出现频率更大的符号将获得更短的比特，出现频率更小的符号将被分配更长的比特，以此来提高数据压缩率，提高传输效率。具体编码步骤主要为， 1、统计： 在开始编码时，通常都需要对信号源，也就是本文的一段文字，进行处理，计算出每个符号出现的频率，得到信号源的基本情况。接下来就是对统计信息进行处理了 2、构造优先对列： 把得到的符号添加到优先队列中，此优先队列的进出逻辑是频率低的先出，因此在设计优先队列时需要如此设计，如果不熟悉优先队列，请阅读相关书籍，在此不做过多概述。得到包含所有字符的优先队列后，就是处理优先队列中的数据了。 3、构造哈夫曼树： 哈夫曼树是带权值得二叉树，我们使用的哈夫曼树的权值自然就是符号的频率了，我们构建哈夫曼树是自底向上的，先构建叶子节点，然后逐步向上，最终完成整颗树。先把队列中的一个符号出列，也就是最小频率的符号，，然后再出列一个符号。这两个符号将作为哈夫曼树的节点，而且这两个节点将作为新节点，也就是它们父节点，的左右孩子节点。新节点的频率，即权值，为孩子节点的和。把这个新节点添加到队列中(队列会重新根据权值排序)。重复上面的步骤，两个符号出列，构造新的父节点，入列……直到队列最后只剩下一个节点，这个节点也就是哈夫曼树的根节点了。 4、为哈弗曼树编码： 哈夫曼树的来自信号源的符号都是叶子节点，需要知道下。树的根节点分配比特0，左子树分配0，右字数分配1。然后就可以得到符号的码值了。 ####哈夫曼编码步骤 1.首先构建一个元素为哈夫曼树结点的数组用于存储哈夫曼树（线性）； 哈夫曼树数据结构包括元素数据、权值、父结点位置（数组下标）、两个子结点位置 typedef struct { int weight; int parent; int lchild; int rchild; int value; } HNodeType 2.初始化数组，设置树元素的默认属性；然后输入要编码的数据及其权值，存储到数组前几位，这几个即为哈夫曼树的叶子结点； 哈夫曼树中有效的数据仅仅是叶子结点， 而非叶子结点是为了构建哈夫曼树而加入的 3.开始构建哈夫曼树：找出整个数组中有数据且权值最低的两个作为新构造的二叉树的左右子树，新二叉树的根结点的权值为其左右子树的根结点的权值之和； 然后把新构建的根结点存放到数中空位置，然后继续从整个数组中寻找。。。直到有效元素全部读取。 4.编码,树的根节点分配比特0，左子树分配0，右字数分配1; 5.解码,思路就是 把要解码的字符串像学中学方程一样代入到哈夫曼树中，按照左子树分配0，右字数分配1的原则，一个一个遍历出来 示例(转载)： 假如我有A,B,C,D,E五个字符，出现的频率（即权值）分别为5,4,3,2,1, 那么我们第一步先取两个最小权值作为左右子树构造一个新树，即取1，2构成新树，其结点为1+2=3，如图： 虚线为新生成的结点，第二步再把新生成的权值为3的结点放到剩下的集合中，所以集合变成{5,4,3,3}，再根据第二步，取最小的两个权值构成新树，如图： 再依次建立哈夫曼树，如下图： 其中各个权值替换对应的字符即为下图： 如下图也可以加深大家的理解： 代码实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210/*------------------------------------------------------------------------- * Name: 哈夫曼编码源代码。 * Date: 2011.04.16 * Author: Jeffrey Hill+Jezze(解码部分) * 在 Win-TC 下测试通过 * 实现过程：着先通过 HuffmanTree() 函数构造哈夫曼树，然后在主函数 main()中 * 自底向上开始(也就是从数组序号为零的结点开始)向上层层判断，若在 * 父结点左侧，则置码为 0,若在右侧,则置码为 1。最后输出生成的编码。 *------------------------------------------------------------------------*///结点个数 = 叶子结点个数 * 2 - 1#include &lt;stdio.h&gt;#include&lt;stdlib.h&gt;#define MAXBIT 100#define MAXVALUE 10000#define MAXLEAF 30#define MAXNODE MAXLEAF*2 -1typedef struct&#123; int bit[MAXBIT]; //结点的编码 int start; //结点编码的起始位，有效位置，如当start=2， 则该结点的编码从bit[2]开始&#125; HCodeType; /* 编码结构体 */typedef struct&#123; int weight; int parent; int lchild; int rchild; int value;&#125; HNodeType; /* 结点结构体 *//* 构造一颗哈夫曼树 */void HuffmanTree(HNodeType HuffNode[MAXNODE], int n)&#123; /* i、j： 循环变量， m1、m2：构造哈夫曼树不同过程中两个最小权值结点的权值， x1、x2：构造哈夫曼树不同过程中两个最小权值结点在数组中的序号。*/ int i, j, m1, m2, x1, x2; /* 初始化存放哈夫曼树数组 HuffNode[] 中的结点 */ for(i = 0; i &lt; 2 * n - 1; i++) &#123; HuffNode[i].weight = 0;//权值 HuffNode[i].parent = -1;//父结点位置初始化为-1，表示没有父结点，到时候要通过该属性进行判断，排除掉已加入到树的元素 HuffNode[i].lchild = -1;//初始化左子树根节点位置 HuffNode[i].rchild = -1;//初始化右子树根节点位置 HuffNode[i].value = i; //实际值，可根据情况替换为字母 &#125; /* end for */ /* 用户输入 n 个叶子结点的权值 */ for(i = 0; i &lt; n; i++) &#123; printf(\"请输入第 %d 个元素的权值: \\n\", i); scanf(\"%d\", &amp;HuffNode[i].weight); &#125; /* end for */ /* 循环构造 Huffman 树 */ for(i = 0; i &lt; n - 1; i++) // 循环叶子结点的个数，一次循环要形成一个“新”的二叉树 &#123; m1 = m2 = MAXVALUE; //m1、m2中存放两个无父结点且结点权值最小的两个结点 x1 = x2 = 0; //找出所有结点中权值最小、无父结点的两个结点，并合并之为一颗二叉树 for(j = 0; j &lt; n + i; j++) //循环数组中元素个数 &#123; //要找到当前数组中所有的元素中最小的两位，处理之后又把结果存到数组中所以要(n+i) if(HuffNode[j].weight &lt; m1 &amp;&amp; HuffNode[j].parent == -1) &#123; //当前的权值更小，把当前元素赋值给m1，把原来m1的赋值给m2 m2 = m1; x2 = x1; m1 = HuffNode[j].weight; x1 = j; &#125; else if(HuffNode[j].weight &lt; m2 &amp;&amp; HuffNode[j].parent == -1) &#123; //当前的权值大于m1但是小于m2，把其赋值给m2 m2 = HuffNode[j].weight; x2 = j; &#125; &#125; /* end for */ /* 最终，m1每次存放最小权值，m2存放次小的 */ /* 设置 找到的两个子结点 x1、x2 的父结点信息 */ /* 父结点存放到数组的下标为(n + i)的位置 */ HuffNode[x1].parent = n + i; HuffNode[x2].parent = n + i; /* 设置 父结点的属性 */ HuffNode[n + i].weight = HuffNode[x1].weight + HuffNode[x2].weight; HuffNode[n + i].lchild = x1; HuffNode[n + i].rchild = x2; printf(\"第 %d 次循环的两个结果的权值为: %d, %d\\n\", i + 1, HuffNode[x1].weight, HuffNode[x2].weight); /* 用于测试 */ printf(\"\\n\"); &#125; /* end for */ /* for(i=0;i&lt;n+2;i++) &#123; printf(\" Parents:%d,lchild:%d,rchild:%d,value:%d,weight:%d\\n\",HuffNode[i].parent,HuffNode[i].lchild,HuffNode[i].rchild,HuffNode[i].value,HuffNode[i].weight); &#125;*///测试&#125; /* end HuffmanTree *///解码void decodeing(char string[], HNodeType Buf[], int Num)&#123; //tmp：循环中临时存放哈夫曼树数组的元素下标，从大到小 int i, tmp = 0, code[1024]; int m = 2 * Num - 1; char *nump; char num[1024]; int len = strlen(string); for(i = 0; i &lt; len; i++) &#123; if(string[i] == '0') num[i] = 0; else num[i] = 1; &#125; i = 0; nump = &amp;num[0];//nump指向要解码的字符数组的第一个元素的地址 printf(\" 解码结果为： \"); while(nump &lt; (&amp;num[len]))//循环遍历要解码的字符数组（即输入的解码前字符串），直到最后一个数组元素 &#123; tmp = m - 1;//每次循环设置初始元素下标，设置为 哈夫曼树数组 的最后一个有效数据元素的下标（树的根节点） while((Buf[tmp].lchild != -1) &amp;&amp; (Buf[tmp].rchild != -1))//循环判断该元素有没有子结点，直到没有子结点，则说明遍历到叶子结点，则说明找到一个解码的结果 &#123; if(*nump == 0) //判断要解码的字符数组的当前元素是否为0 0表示左结点 1表示有结点 &#123; tmp = Buf[tmp].lchild ; &#125; else &#123; tmp = Buf[tmp].rchild; &#125; nump++; //数组元素是字符，每个元素只占一个字节，所以++也就是地址加一，指向数组下一个元素 &#125; printf(\" %d\", nump, &amp;num[strlen(string)], Buf[tmp].value); &#125;&#125;int main(void)&#123; HNodeType HuffNode[MAXNODE]; /* 定义一个结点结构体数组 */ HCodeType HuffCode[MAXLEAF], cd; /* 定义一个编码结构体数组， 同时定义一个临时变量来存放求解编码时的信息(即cd.bit存放当前结点的编码的倒序，cd.start存放结点编码开始位置) */ /* i、j： 循环变量， c 循环体中当前的结点在数组中的下标 p 当前结点的父结点在数组中的下标 n 有效数据的个数（叶子结点的个数） */ int i, j, c, p, n; char pp[100]; printf(\"Please input n:\\n\"); scanf(\"%d\", &amp;n); HuffmanTree(HuffNode, n);//生成哈夫曼树 /*对哈夫曼树进行编码*/ for(i = 0; i &lt; n; i++)//循环所有的有效数据，一个一个进行编码 (0 ~ n-1) &#123; cd.start = n - 1; // c = i; //c 当前结点在数组中的下标 整体上来说可以表示循环在“树”中走过的结点下标 p = HuffNode[c].parent; //p 当前结点的父结点在数组中的下标 while(p != -1) /* 判断父结点存在 */ &#123; if(HuffNode[p].lchild == c) //判断当前结点是不是父结点的左子树根节点 如果是的话就 赋值0 cd.bit[cd.start] = 0; else //如果不是的话就 赋值1 &gt;&gt;&gt;&gt; 因为“左子树分配0，右字数分配1” cd.bit[cd.start] = 1; cd.start--; /* 求编码的低一位 */ /* 设置下一循环条件 */ c = p; //设置c为父结点的下标 准备进行下次while循环，则那时候的“当前的结点”就会变成现在结点的父结点 p = HuffNode[c].parent; //同理 &#125;/* end while */ /* 保存 求出的每个叶结点的哈夫曼编码和编码的起始位 */ for(j = cd.start + 1; j &lt; n; j++) &#123; HuffCode[i].bit[j] = cd.bit[j]; &#125; HuffCode[i].start = cd.start + 1; //编码的起始位 &#125; /* end for */ /*对哈夫曼树进行编码结束*/ /* 打印已保存好的所有存在编码的哈夫曼编码 */ for(i = 0; i &lt; n; i++) &#123; printf(\"第%d位置的树结点的编码为：: \", i); for(j = HuffCode[i].start; j &lt; n; j++)//从有效位置开始输出该结点的编码 &#123; printf(\"%d\", HuffCode[i].bit[j]); &#125; printf(\" 结点的属性bit数组中有效的编码开始位置为:bit[%d]\\n\", HuffCode[i].start); &#125; /* 打印结束 */ printf(\"Decoding?Please Enter code:\\n\"); scanf(\"%s\", &amp;pp); decodeing(pp, HuffNode, n); getch(); return 0;&#125; 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"线索二叉树","slug":"20170906_xsecs","date":"2020-01-15T05:50:39.630Z","updated":"2021-03-10T15:20:21.774Z","comments":true,"path":"2020/01/15/20170906_xsecs/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170906_xsecs/","excerpt":"线索二叉树：二叉树存储结构完全依靠链表，而二叉树的链表表示的关系是父结点和子结点（子树）的关系， 而无法直接获得前驱-后继的关系，即，当要求某个结点的前驱结点or后继结点比较麻烦； 为了在不增加指针的情况下直接快速找到前驱/后继结点，可以使用 线索二叉树 来实现；","text":"线索二叉树：二叉树存储结构完全依靠链表，而二叉树的链表表示的关系是父结点和子结点（子树）的关系， 而无法直接获得前驱-后继的关系，即，当要求某个结点的前驱结点or后继结点比较麻烦； 为了在不增加指针的情况下直接快速找到前驱/后继结点，可以使用 线索二叉树 来实现； 由于遍历方法不同时，产生的元素顺序不同，则每个元素的前驱/后继结点也不一定相同， 所以线索二叉树就由此分为先序线索二叉树，中序线索二叉树和后序线索二叉树； 上图为 中序线索二叉树，由上图二叉树结构可知，其中序遍历结果为 B F D A C G E H 其中 B、D、F、C等元素拥有空的指针域； 这些空的指针域可以用来存放前驱或者后继结点的地址，这种指针称为线索（Thread）； 而为了与存放子树（子树）的指针区分开来，增加了两个标志lflag，rflag表示左/右指针是哪种指针； 由此可得 线索二叉树 结构为： 12345678910111213typedef char DATA; //定义树结点的元素类型typedef enum&#123; SubTree, Thread&#125;NodeFlag; //定义枚举类型NodeFlag，包含SubTree（表示子树）和Thread（表示线索），分别为 0，1typedef struct ChainTree&#123; //定义二叉树结点类型 DATA data; //结点数据 NodeFlag lflag; //左标志：用来表示左指针是子树指针还是线索指针 NodeFlag rflag; //右标志：用来表示右指针是子树指针还是线索指针 struct ChainTree *left; //左子树结点指针 struct ChainTree *right;//右子树结点指针&#125;ChainBinTree; 线索二叉树实例代码本实例是在二叉树代码的基础上增加和修改的 这里只展示新增和修改的部分， 原来的代码见: http://zj2626.github.io/2017/08/27/20170827_ecs/ BinTree.h 12345678910111213141516171819202122232425262728293031/* 修改结构体为：*/typedef char DATA; //定义树结点的元素类型typedef enum&#123; SubTree, Thread&#125;NodeFlag; //定义枚举类型NodeFlag，包含SubTree（表示子树）和Thread（表示线索），分别为 0，1typedef struct ChainTree&#123; //定义二叉树结点类型 DATA data; //结点数据 NodeFlag lflag; //左标志：用来表示左指针是子树指针还是线索指针 NodeFlag rflag; //右标志：用来表示右指针是子树指针还是线索指针 struct ChainTree *left; //左子树结点指针 struct ChainTree *right;//右子树结点指针&#125;ChainBinTree;/* 增加的函数*//*二叉树按中序线索化*/void BinTreeThreading_LDR(ChainBinTree *bt);/*中序线索二叉树 找到后继结点*/ChainBinTree *BinTreeNext_LDR(ChainBinTree *bt);/*中序线索二叉树遍历*/void ThreadBinTree_LDR(ChainBinTree *bt, void (*oper)(ChainBinTree *p)); BinTree.c 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/* 增加的函数*/ /********************************线索二叉树***************************/ChainBinTree *Previous = NULL;//保存前驱结点指针/*二叉树按中序线索化*/void BinTreeThreading_LDR(ChainBinTree *bt)&#123; if(bt)&#123;//判断结点非空 //左子树操作 BinTreeThreading_LDR(bt-&gt;left); //递归调用，线索化左子树 //当前结点操作 bt-&gt;lflag = (bt-&gt;left) ? SubTree : Thread; //设置左指针域标志 bt-&gt;rflag = (bt-&gt;right) ? SubTree : Thread; //设置右指针域标志 if(Previous)&#123; //判断前驱结点是否存在（就第一个没有前驱） if(Previous-&gt;rflag == Thread) //判断起前驱结点的右标志是否为线索，如果不是，则说明该前驱结点存在右子树 Previous-&gt;right = bt; //设置前驱结点的右线索指向后继结点（当前） if(bt-&gt;lflag == Thread) //判断当前结点的左标志是否为线索，如果不是，则说明当前结点存在左子树 bt-&gt;left = Previous; //设置当前结点的左线索指向前驱结点 &#125; Previous = bt;//保存刚访问的结点到Previous，作为下一个结点的前驱结点 //右子树操作 BinTreeThreading_LDR(bt-&gt;right);//递归调用，线索化右子树 &#125;&#125;/*中序线索二叉树 找到后继结点*/ChainBinTree *BinTreeNext_LDR(ChainBinTree *bt)&#123; ChainBinTree *nextNode; //存放后继结点 if(!bt) return NULL; if(bt-&gt;rflag == Thread)&#123; //判断当前结点右标志是否为线索，如果是则说明right存放的是后继结点的地址，直接返回 return bt-&gt;right; &#125;else&#123; nextNode = bt-&gt;right; //暂时存放当前结点的右子树的根节点 while(nextNode-&gt;lflag == SubTree)&#123; //循环获取右子树的“最左结点”，这就是要求的后继结点 nextNode = nextNode-&gt;left; &#125; return nextNode; &#125;&#125;/*中序线索二叉树遍历*/void ThreadBinTree_LDR(ChainBinTree *bt, void (*oper)(ChainBinTree *p))&#123; if(bt)&#123; while(bt-&gt;lflag == SubTree)&#123; //循环找到第一个中序遍历的结点 bt = bt-&gt;left; &#125; do&#123; oper(bt); bt = BinTreeNext_LDR(bt); //获取后继结点，把地址赋值给bt &#125;while(bt); &#125;&#125; main.c 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* 修改的main函数为：*/int main()&#123; ChainBinTree *root = NULL; //root为指向二叉树根节点的指针 char select; void (*oper1)(); //指向函数的指针 oper1 = oper; //指向具体操作的函数 do&#123; printf(\"\\n1.设置二叉树根元素 2.添加二叉树结点 3.先序 4.中序 5.后序 6.按层 7.二叉树深度 8.生成中序线索二叉树 9.遍历中序线索二叉树 0.退出\"); select = getch(); switch(select)&#123; case '1': root = initRoot(); break; case '2': addNode(root); break; case '3': binTree_DLR(root, oper1); printf(\"\\n\"); break; case '4': binTree_LDR(root, oper1); printf(\"\\n\"); break; case '5': binTree_LRD(root, oper1); printf(\"\\n\"); break; case '6': binTree_Level(root, oper1); printf(\"\\n\"); break; case '7': printf(\"%d\", binTreeDepth(root)); break; case '8': BinTreeThreading_LDR(root); break; case '9': ThreadBinTree_LDR(root, oper1); break; &#125; &#125;while(select != '0'); binTreeClear(root); root = NULL; return 0;&#125; 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"普通二叉树","slug":"20170826_ecs","date":"2020-01-15T05:50:39.629Z","updated":"2021-03-10T15:20:21.835Z","comments":true,"path":"2020/01/15/20170826_ecs/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170826_ecs/","excerpt":"二叉树： 二叉树性质： 1.在二叉树的第i层的结点总数最多有2^(i-1)个结点 2.深度为k的二叉树最多有2^(k) - 1个结点，最少有k个结点 3.二叉树，如果其叶结点为n0，而度为2的结点总数为n2，则n0=n2+1 4.有n个结点的完全二叉树的深度k为：k=[log2(n)]+1 5.有n个结点的完全二叉树各结点如果用顺序表存储，对任意结点i，有如下关系： 如果 i != 1，则其父节点的编号为i/2 如果 2*i &lt;= n，则其左子树根节点的编号为2*i；若 2*i&gt;n，则无左子树 如果 2*i+1 &lt;= n，则右子树根节点的编号为2*i+1；若 2*i+1&gt;n，则无右子树 二叉树的存储：","text":"二叉树： 二叉树性质： 1.在二叉树的第i层的结点总数最多有2^(i-1)个结点 2.深度为k的二叉树最多有2^(k) - 1个结点，最少有k个结点 3.二叉树，如果其叶结点为n0，而度为2的结点总数为n2，则n0=n2+1 4.有n个结点的完全二叉树的深度k为：k=[log2(n)]+1 5.有n个结点的完全二叉树各结点如果用顺序表存储，对任意结点i，有如下关系： 如果 i != 1，则其父节点的编号为i/2 如果 2*i &lt;= n，则其左子树根节点的编号为2*i；若 2*i&gt;n，则无左子树 如果 2*i+1 &lt;= n，则右子树根节点的编号为2*i+1；若 2*i+1&gt;n，则无右子树 二叉树的存储： 1.顺序存储结构：若是完全二叉树，则某个结点的父节点=（该节点的位置/2），其子节点为（该节点的位置*2）和（该节点的位置*2+1），从1开始计算； 若不是完全二叉树，可以在没有结点数据的位置置为空，模拟成完全二叉树（然后同上）； 如图二叉树，如果使用顺序存储结则数据结构定义为如下sqTree数组： #definde MAXSIZE 100 typedef int DATA; typedef DATA SeqBinTree[MAXSIZE]; SeqBinTree sqTree; //顺序存储结构 对于上面的完全二叉树，最终使用顺序存储结构后，得到的效果为如下图： 通过图中规律可发现： 1.求某个结点的子结点，只需把该结点在数组中的位置（非下标，而是下标+1）乘2，则子节点为所得的位置的结点以及其下一个结点； 2.求某个结点的父结点，只需把该结点在数组中的位置除以2，说的的商即为父结点位置； 3.对于非完全二叉树，可以模拟为完全二叉树使用，即把没有结点的位置“空出来”，表示没有结点，如图，假设I节点不存在，则9的位置即为空 顺序存储结构问题：占用内存连续且必须提前分配足够的内存，不能扩容，不够灵活，所以一般使用链式存储结构存储树； 2.二叉链式存储结构：数据结构定义包括一个数据，一个指向左子树的指针，一个指向右子树的指针（没有则赋值为空）； 对于链式存储结构，可以使用树的基本原理，即树相当于多个子树嵌套，树中包含多个子树，而子树也是一个树结构，所以算法中经常涉及到递归调用，递归查询； 其中left指针存放左子树的根节点的地址，right指针存放右子树的根节点的地址； 2.三叉链式存储结构：数据结构定义包括一个数据，一个指向左子树的指针，一个指向右子树的指针以及一个指向父结点的指针 二叉树的遍历: 1.先序遍历(DLR): 顺序:根-左-右 2.中序遍历(LDR): 顺序:左-根-右 3.后序遍历(LRD)&quot; 顺序:左-右-跟 4.按层遍历 二叉顺序存储结构二叉链式存储结构 BinTree.h 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;stdio.h&gt;#define QUEUE_MAXSIZE 50typedef char DATA; //定义树结点的元素类型typedef struct ChainTree&#123; //定义二叉树结点类型 DATA data; //结点数据 struct ChainTree *left; //左子树结点指针 struct ChainTree *right;//右子树结点指针&#125;ChainBinTree;/*初始化二叉树根节点*/ChainBinTree *binTreeInit(ChainBinTree *node);/*添加数据到二叉树*/int binTreeAddNode(ChainBinTree *bt, ChainBinTree *node, int n);/*返回左子节点和右子节点*/ChainBinTree *binTreeLeft(ChainBinTree *bt);ChainBinTree *binTreeRight(ChainBinTree *bt);/*判断二叉树是否为空*/int binTreeIsEmpty(ChainBinTree *bt);/*求二叉树深度*/int binTreeDepth(ChainBinTree *bt);/*寻找值为data的结点*/ChainBinTree *binTreeFind(ChainBinTree *bt, DATA data);/*清空树*/void binTreeClear(ChainBinTree *bt);/********************************树的遍历***************************//*遍历树要进行的操作*/void oper(ChainBinTree *p);/*先序遍历*/void binTree_DLR(ChainBinTree *bt, void (*oper) (ChainBinTree *p));/*中序遍历*/void binTree_LDR(ChainBinTree *bt, void (*oper) (ChainBinTree *p));/*后序遍历*/void binTree_LRD(ChainBinTree *bt, void (*oper) (ChainBinTree *p));/*按层遍历*/void binTree_Level(ChainBinTree *bt, void (*oper) (ChainBinTree *p)); BinTree.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189#include \"BinTree.h\"/*初始化二叉树根节点*/ChainBinTree *binTreeInit(ChainBinTree *node)&#123; if(node != NULL) return node; else return NULL;&#125;/*添加数据到二叉树 bt为要添加的位置的父节点 node为添加的节点 n=1表示左子树 n=2表示右子树*/int binTreeAddNode(ChainBinTree *bt, ChainBinTree *node, int n)&#123; if(bt == NULL)&#123; printf(\"父节点不存在!\\n\"); return 0; &#125; switch(n)&#123; //添加到左子树 case 1: if(bt-&gt;left)&#123; printf(\"左子树不为空, 不能添加!\\n\"); return 0; &#125;else&#123; bt-&gt;left = node; &#125; break; case 2: if(bt-&gt;right)&#123; printf(\"右子树不为空, 不能添加!\\n\"); return 0; &#125;else&#123; bt-&gt;right = node; &#125; break; default: printf(\"参数错误\"); return 0; &#125; return 1;&#125;/*返回左子节点和右子节点*/ChainBinTree *binTreeLeft(ChainBinTree *bt)&#123; if(bt) return bt-&gt;left; else return NULL;&#125;ChainBinTree *binTreeRight(ChainBinTree *bt)&#123; if(bt) return bt-&gt;right; else return NULL;&#125;/*判断二叉树是否为空*/int binTreeIsEmpty(ChainBinTree *bt)&#123; if(bt) return 0; else return 1;&#125;/*求二叉树深度*/int binTreeDepth(ChainBinTree *bt)&#123; int dep1,dep2; if(bt == NULL)&#123; return 0; //空树 &#125;else&#123; //递归调用 递归子树直到最后的叶子结点没有子节点,返回0 dep1 = binTreeDepth(bt-&gt;left); dep2 = binTreeDepth(bt-&gt;right); //返回子树中深度更深的子树的深度 if(dep1 &gt; dep2)&#123; return dep1 + 1; &#125;else&#123; return dep2 + 1; &#125; &#125;&#125;/*寻找值为data的结点*/ChainBinTree *binTreeFind(ChainBinTree *bt, DATA data)&#123; ChainBinTree *p; if(bt == NULL) return NULL; else&#123; if(bt-&gt;data == data)&#123; return bt; &#125;else&#123; //递归调用 if(p = binTreeFind(bt-&gt;left, data)) return p; else if(p = binTreeFind(bt-&gt;right, data)) return p; else return NULL; &#125; &#125;&#125;/*清空树*/void binTreeClear(ChainBinTree *bt)&#123; if(bt)&#123; binTreeClear(bt-&gt;left); binTreeClear(bt-&gt;right); free(bt); &#125; return;&#125;/********************************树的遍历***************************//*遍历树要进行的操作*/void oper(ChainBinTree *p)&#123; printf(\"%c \\t\", p-&gt;data); return;&#125;/*先序遍历*/void binTree_DLR(ChainBinTree *bt, void (*oper)(ChainBinTree *p))&#123; if(bt)&#123; oper(bt); binTree_DLR(bt-&gt;left, oper); binTree_DLR(bt-&gt;right, oper); &#125; return;&#125;/*中序遍历*/void binTree_LDR(ChainBinTree *bt, void (*oper) (ChainBinTree *p))&#123; if(bt)&#123; binTree_LDR(bt-&gt;left, oper); oper(bt); binTree_LDR(bt-&gt;right, oper); &#125; return;&#125;/*后序遍历*/void binTree_LRD(ChainBinTree *bt, void (*oper) (ChainBinTree *p))&#123; if(bt)&#123; binTree_LRD(bt-&gt;left, oper); binTree_LRD(bt-&gt;right, oper); oper(bt); &#125; return;&#125;/*按层遍历*/void binTree_Level(ChainBinTree *bt, void (*oper) (ChainBinTree *p))&#123; ChainBinTree *p; ChainBinTree *q[QUEUE_MAXSIZE]; //定义一个顺序队列,先进先出 int head = 0, tail = 0; //队首队尾序号 if(bt)&#123; //如果队首指针不为空 tail = (tail + 1) % QUEUE_MAXSIZE; //计算循环队列队尾序号 q[tail] = bt; //把二叉树根指针进队 &#125; //本质上：每次tail进行两次改变（只有当是完全二叉树,其他情况则有不同），然后head进行一次改变，实现按层把树的元素放到队列中去 //即每次把head指向的结点的两个子节点存放到队列，并且把该结点进行操作（执行oper方法）； //当tail不再增加，也就是说再也没有哪个未读取得结点还拥有子节点了，则剩下的就是把队列中剩余未操作的结点进行操作，直到队列为空，即head==tail，退出循环 while(head != tail)&#123; //队列不为空, 进行循环 head = (head + 1) % QUEUE_MAXSIZE; //计算循环队列的队首序号 p = q[head]; //获取队列元素 oper(p); //处理队首元素 if(p-&gt;left != NULL)&#123; //若结点存在左子树, 则左子树指针进队 tail = (tail + 1) % QUEUE_MAXSIZE; q[tail] = p-&gt;left; &#125; if(p-&gt;right != NULL)&#123; //若结点存在右子树, 则右子树指针进队 tail = (tail + 1) % QUEUE_MAXSIZE; q[tail] = p-&gt;right; &#125; &#125; return;&#125; 按层遍历过程。。。 main.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#include &lt;stdio.h&gt;#include \"BinTree.h\"ChainBinTree *initRoot()&#123; ChainBinTree *node; if(node = (ChainBinTree *)malloc(sizeof(ChainBinTree)))&#123; printf(\"\\n输入根数据结点\"); scanf(\"%s\", &amp;node-&gt;data); node-&gt;left = NULL; node-&gt;right = NULL; return binTreeInit(node); &#125; return NULL;&#125;void addNode(ChainBinTree *bt)&#123; ChainBinTree *node, *parent;//存放新增的结点和要挂接的父节点 DATA data; char select; if(node = (ChainBinTree *)malloc(sizeof(ChainBinTree)))&#123;//分配内存 printf(\"\\n输入二叉树结点数据：\"); fflush(stdin); scanf(\"%s\", &amp;node-&gt;data); node-&gt;left = NULL; node-&gt;right = NULL; printf(\"输入父结点数据：\"); fflush(stdin); scanf(\"%s\",&amp;data); parent = binTreeFind(bt, data);//查找结点 if(!parent)&#123; printf(\"未找到结点\\n\"); free(node); return; &#125; printf(\"1.添加到左子树\\n2.添加到右子树\"); do&#123; select = getch(); select -= '0'; if(select == 1 || select == 2)&#123; binTreeAddNode(parent, node, select);//添加结点到二叉树 &#125; &#125;while(select != 1 &amp;&amp; select != 2); return; &#125;&#125;int main()&#123; ChainBinTree *root = NULL; //root为指向二叉树根节点的指针 char select; void (*oper1)(); //指向函数的指针 oper1 = oper; //指向具体操作的函数 do&#123; printf(\"\\n1.设置二叉树根元素 2.添加二叉树结点 3.先序 4.中序 5.后序 6.按层 7.二叉树深度 0.退出\"); select = getch(); switch(select)&#123; case '1': root = initRoot(); break; case '2': addNode(root); break; case '3': binTree_DLR(root, oper1); printf(\"\\n\"); break; case '4': binTree_LDR(root, oper1); printf(\"\\n\"); break; case '5': binTree_LRD(root, oper1); printf(\"\\n\"); break; case '6': binTree_Level(root, oper1); printf(\"\\n\"); break; case '7': printf(\"%d\", binTreeDepth(root)); break; &#125; &#125;while(select != '0'); binTreeClear(root); root = NULL; return 0;&#125; 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"栈实例（转载）","slug":"20170817_z","date":"2020-01-15T05:50:39.627Z","updated":"2021-03-10T13:50:15.337Z","comments":true,"path":"2020/01/15/20170817_z/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170817_z/","excerpt":"栈：只允许在一端进行插入和删除操作，（后进先出） 实现简单的四则运算 包括 +-*/以及() 参考博客： http://blog.csdn.net/zhaishaojiang/article/details/40017791","text":"栈：只允许在一端进行插入和删除操作，（后进先出） 实现简单的四则运算 包括 +-*/以及() 参考博客： http://blog.csdn.net/zhaishaojiang/article/details/40017791 工程一共包含5个文件(由于代码不多，未分成头文件和实现) OptrStack.h OptrStack.c 操作符栈 包含基本的栈结构定义和操作方法 OpndStack.h OpndStack.c 操作数栈 包含基本的栈结构定义和操作方法 main.c ： 测试文件 包含运算的方法 定义两个栈分别用于存储操作符和操作数； 栈所具有的功能有：置栈空，判栈空，入栈，出栈，取栈顶； 将输入的算术表达式存入字符数组中； 将表达式中的运算符划分优先级； 进行双目运算，即+，-，*，/； 将表达式压入栈中，并计算表达式结果。（思路：将操作符压入操作符栈中，将操作数压入操作数栈中。过程：判断当前运算符与操作符栈栈顶元素的优先级，如果高于栈顶元素，则入栈；小于栈顶元素，则从操作数栈中依次出两个数，并将操作符栈中栈顶元素出栈，再将从操作数栈中出的两个数，按从操作符栈栈中出的运算符运算，并将结果压入操作数栈中，再将当前的操作符压入操作符栈中。） OpndStack.h #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #define MAXSIZE2 100 typedef struct { double date[MAXSIZE2]; int top; }OpndStack; //操作数结构体 /*-------操作数相关操作-------*/ OpndStack *Init_OpndStack();/*置栈空*/ int Empty_OpndStack(OpndStack *t);/*判空栈*/ int Push_OpndStack(OpndStack *t, double y);/*入栈(注意：判断栈是否已满)*/ double Pop_OpndStack(OpndStack *t);/*出栈(注意：判断栈是否已空)*/ double GetTop_OpndStack(OpndStack *t);/*取栈顶元素*/ OpndStack.c #include &quot;OpndStack.h&quot; /*-------操作数相关操作-------*/ OpndStack *Init_OpndStack()/*置栈空*/ { OpndStack *t; t = (OpndStack *)malloc(sizeof(OpndStack)); t-&gt;top = -1; return t; } int Empty_OpndStack(OpndStack *t)/*判空栈*/ { if(t-&gt;top == -1) { return 1; } else { return 0; } } int Push_OpndStack(OpndStack *t, double y)/*入栈(注意：判断栈是否已满)*/ { if(t-&gt;top == MAXSIZE2 - 1) { return 0; } else { t-&gt;top ++; t-&gt;date[t-&gt;top] = y; return 1; } } double Pop_OpndStack(OpndStack *t)/*出栈(注意：判断栈是否已空)*/ { double y; //接收要出栈的元素 if( Empty_OpndStack(t) ) { return 0; } y = t-&gt;date[t-&gt;top]; t-&gt;top --; return y; } double GetTop_OpndStack(OpndStack *t)/*取栈顶元素*/ { if( Empty_OpndStack(t) ) { return 0; } else { return (t-&gt;date[t-&gt;top]); } } OptrStack.h #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #define MAXSIZE1 100 typedef struct { char date[MAXSIZE1]; int top; }OptrStack; //操作符结构体 /*-------操作符相关操作-------*/ OptrStack *Init_OptrStack(); /*置栈空*/ int Empty_OptrStack(OptrStack *s);/*判空栈*/ int Push_OptrStack(OptrStack *s, char x);/*入栈(注意：判断栈是否已满)*/ char Pop_OptrStack(OptrStack *s);/*出栈(注意：判断栈是否已空)*/ char GetTop_OptrStack(OptrStack *s);/*取栈顶元素，先判空*/ OptrStack.c #include &quot;OptrStack.h&quot; /*-------操作符相关操作-------*/ OptrStack *Init_OptrStack() /*置栈空*/ { OptrStack *s; s = (OptrStack *)malloc(sizeof(OptrStack)); s-&gt;top = -1; return s; } int Empty_OptrStack(OptrStack *s)/*判空栈*/ { if(s-&gt;top == -1) { return 1; //如果栈为空，则返回真数 } else { return 0; //反之，返回零 } } int Push_OptrStack(OptrStack *s, char x)/*入栈(注意：判断栈是否已满)*/ { if(s-&gt;top == MAXSIZE1 - 1) { return 0; } else { s-&gt;top ++; //栈顶指针向上移，再赋值 s-&gt;date[s-&gt;top] = x; return 1; } } char Pop_OptrStack(OptrStack *s)/*出栈(注意：判断栈是否已空)*/ { int x; //接收要出栈的元素 if( Empty_OptrStack(s) ) { return 0; } x = s-&gt;date[s-&gt;top]; s-&gt;top --; return x; } char GetTop_OptrStack(OptrStack *s)/*取栈顶元素，先判空*/ { if( Empty_OptrStack(s) ) { return 0; } else { return (s-&gt;date[s-&gt;top]); } } main.c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &quot;OpndStack.h&quot; #include &quot;OptrStack.h&quot; int Rank(char op); //划分运算符的优先级 double Operate(double a, double b, char op); //运算操作 void Handle_str(char str[]); //将储存表达式的字符数组压入栈内,并运算 int main() { char str[100]; printf(&quot;请输入算术表达式(功能：+，-，*，/。可带括号！):\\n&quot;); scanf(&quot;%s&quot;, str); Handle_str(str); return 0; } int Rank(char op) //划分运算符的优先级 { int x; switch(op) { case &apos;#&apos;: x = 0;break; case &apos;(&apos;: x = 1;break; case &apos;+&apos;: case &apos;-&apos;: x = 2;break; case &apos;*&apos;: case &apos;/&apos;: x = 3;break; } return x; } double Operate(double a, double b, char op) //运算操作 { double c; switch(op) { case &apos;+&apos;: c = a + b;break; case &apos;-&apos;: c = a - b;break; case &apos;*&apos;: c = a * b;break; case &apos;/&apos;: if(b == 0) { printf(&quot;分母为零!\\n&quot;); return 0; } else c = a / b;break; default: printf(&quot;输入的字符非法!\\n&quot;); break; } return c; } void Handle_str(char str[]) //将储存表达式的字符数组压入栈内 { OptrStack *optr = Init_OptrStack(); //初始化操作符栈 OpndStack *opnd = Init_OpndStack(); //初始化操作数栈 int i,j; //i,j为循环变量，a,b接收从操作数栈中出栈的元素 double f,a,b; //接收将字符数转换为浮点数的值 char d[100]; //储存字符串中连续的‘数’ char op; //接收从操作符栈中出栈的元素 Push_OptrStack(optr, &apos;#&apos;); //先往操作符栈中压入&apos;#&apos; for (i = 0; str[i]; i++) { switch(str[i]){ case &apos;+&apos;: case &apos;-&apos;: /*先判断当前运算符与操作符栈栈顶元素的优先级，如果高于栈顶元素，则入栈； 小于栈顶元素，则从操作数栈中依次出两个数，并将操作符栈中栈顶元素出栈， 再将从操作数栈中出的两个数，按从操作符栈栈中出的运算符运算，并将结果压入操作数栈中， 再将当前的操作符压入操作符栈中。*/ if(GetTop_OptrStack(optr) == &apos;#&apos; || GetTop_OptrStack(optr) == &apos;(&apos;) { Push_OptrStack(optr, str[i]);//入栈 } else { a = Pop_OpndStack(opnd);//接收从操作数栈中出栈的元素 b = Pop_OpndStack(opnd);//接收从操作数栈中出栈的元素 op = Pop_OptrStack(optr);//接收从操作符栈中出栈的元素 Push_OpndStack(opnd, Operate(b, a, op));//将计算后的值压入操作数栈中 Push_OptrStack(optr, str[i]); } break; case &apos;*&apos;: case &apos;/&apos;: if(Rank(str[i]) &gt; Rank(GetTop_OptrStack(optr)) || GetTop_OptrStack(optr) == &apos;(&apos;) { Push_OptrStack(optr, str[i]); } else { a = Pop_OpndStack(opnd); b = Pop_OpndStack(opnd); op = Pop_OptrStack(optr); Push_OpndStack(opnd, Operate(b, a, op));//将计算后的值压入操作数栈中 Push_OptrStack(optr, str[i]); } break; case &apos;(&apos;: Push_OptrStack(optr, str[i]); break; case &apos;)&apos;: while(GetTop_OptrStack(optr) != &apos;(&apos;) { a = Pop_OpndStack(opnd); b = Pop_OpndStack(opnd); op = Pop_OptrStack(optr); Push_OpndStack(opnd, Operate(b, a, op)); //将计算后的值压入操作数栈中 } Pop_OptrStack(optr); break; default: j=0; do{ d[j++]=str[i]; i++; }while(str[i]&gt;=&apos;0&apos; &amp;&amp; str[i]&lt;=&apos;9&apos;|| str[i]==&apos;.&apos;); //可存入一个或多个数字字符 d[j]=&apos;\\0&apos;; //将输入的连续多个数字字符拼成了字符串 i--; f=atof(d); //调用库函数atof()将字符数转换为浮点数 Push_OpndStack(opnd, f); //将转换后的数压入操作数栈中 break; } } while(GetTop_OptrStack(optr) != &apos;#&apos;) { a = Pop_OpndStack(opnd); b = Pop_OpndStack(opnd); op = Pop_OptrStack(optr); Push_OpndStack(opnd, Operate(b, a, op));//将计算后的值压入操作数栈中 } printf(&quot;表达式%s = %g\\n&quot;, str, GetTop_OpndStack(opnd));//将操作数栈中的元素(即表达式的最终结果)打印出来 } 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"队列实例（全）","slug":"20170816_dl","date":"2020-01-15T05:50:39.626Z","updated":"2021-03-10T13:50:15.242Z","comments":true,"path":"2020/01/15/20170816_dl/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170816_dl/","excerpt":"队列：只允许在前端（队头）进行删除操作，在后端（队尾）进行插入操作，（先进先出） 实现银行摇号排队共功能","text":"队列：只允许在前端（队头）进行删除操作，在后端（队尾）进行插入操作，（先进先出） 实现银行摇号排队共功能 工程一共包含4个文件(由于代码不多，未分成头文件和实现) Entity.h ：声明线性表的元素的类型。可以是基本数据类型也可以是结构体 SeqQueue.h ：普通的队列以及一般功能的实现 CycleQueue.h ：循环队列以及功能的实现（实例） main.c ： 测试文件 操作：1.初始化队列 2.进队 3.出队 4.获取长度 5.获取第一个元素 Entity.h typedef struct{ int num; //顾客编号 long time; //进入队列时间 } DATA; main.c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;time.h&gt; #include &quot;CycleQueue.h&quot; int num;//顾客编号 void add(CycQueue *q){//新增顾客排序 DATA data; if(!CycQueueIsFull(q)){ data.num = ++ num; data.time = time(NULL); CycQueueIn(q, data); } } void next(CycQueue *q){ //为当前顾客办理业务并通知下一个顾客准备 DATA *data; if(!CycQueueIsEmpty(q)){ data = CycQueueOut(q); printf(&quot;\\n请编号为%d的顾客办理业务\\n&quot;,data-&gt;num); } if(!CycQueueIsEmpty(q)){ data = CycQueuePeek(q); printf(&quot;请编号为%d的顾客准备办理\\n&quot;, data-&gt;num); } } void CycQueueList(CycQueue *q){ //遍历当前队列 int begin, end; begin = q-&gt;head; end = q-&gt;tail; if(!CycQueueIsEmpty(q)){ while(1){ if(begin != end){ printf(&quot;-数组中实际位置(从0开始)：%d；顾客编号：%d \\n&quot;,begin, q-&gt;data[begin].num); begin = (begin +1) % QUEUEMAX; }else{ break; } } } } int main() { CycQueue *queue1; int n; num = 0; //顾客编号 queue1 = CycQueueInit();//初始化 if(queue1 == NULL){ printf(&quot;初始化队列失败&quot;); return 0; } do{ printf(&quot;\\n\\n\\n输入操作： 1.新顾客 2.办理业务 3.查看所有等待的顾客 0.退出\\n&quot;); fflush(stdin); scanf(&quot;%d&quot;, &amp;n); switch(n){ case 1: add(queue1); printf(&quot;当前有%d个顾客等待\\n&quot;, CycQueueLen(queue1)); break; case 2: next(queue1); printf(&quot;当前有%d个顾客等待\\n&quot;, CycQueueLen(queue1)); break; case 3: CycQueueList(queue1); break; case 0: break; } }while(1); return 0; } CycleQueue.c /* 头文件：数据结构的定义和操作原型 */ #include &lt;stdio.h&gt; #include &lt;malloc.h&gt; #include &quot;Entity.h&quot; #define QUEUEMAX 15 //设置队列最大容量 typedef struct{ DATA data[QUEUEMAX]; //队列数组 int head; int tail; } CycQueue; CycQueue *CycQueueInit(){ CycQueue *q; if(q = (CycQueue *)malloc(sizeof(CycQueue))){ q-&gt;head = 0; q-&gt;tail = 0; return q; }else{ return NULL; } } void CycQueueFree(CycQueue *q){ //释放队列内存 if(q != NULL){ free(q); } } int CycQueueIsEmpty(CycQueue *q){//判断队列是否为空 return (q-&gt;head == q-&gt;tail); } int CycQueueIsFull(CycQueue *q){ //判断队列是否为满 return ((q-&gt;tail+1) % QUEUEMAX == q-&gt;head); } int CycQueueLen(CycQueue *q){ //获取队列长度 int n; n = q-&gt;tail - q-&gt;head; if(n &lt; 0){ n = QUEUEMAX + n; } return n; } /*入队*/ int CycQueueIn(CycQueue *q, DATA data){ if(CycQueueIsFull(q)){ printf(&quot;队列已满！&quot;); return 0; }else{ q-&gt;data[q-&gt;tail] = data; q-&gt;tail = (q-&gt;tail+1) % QUEUEMAX;//tail++ 当tail到达最大值后就变1 return 1; } } /*出队*/ DATA *CycQueueOut(CycQueue *q){ DATA * data; if(CycQueueIsEmpty(q)){ printf(&quot;队列为空&quot;); return 0; }else{ data = &amp;(q-&gt;data[q-&gt;head]); q-&gt;head = (q-&gt;head+1) % QUEUEMAX; return data; } } DATA *CycQueuePeek(CycQueue *q){//获取队列头部的元素 if(CycQueueIsEmpty(q)){ printf(&quot;队列为空&quot;); return NULL; }else{ return &amp;(q-&gt;data[(q-&gt;head) % QUEUEMAX]); } } SeqQueue.h /* 头文件：数据结构的定义和操作原型 */ #include &lt;stdio.h&gt; #include &lt;malloc.h&gt; #include &quot;Entity.h&quot; #define QUEUEMAX 15 //设置队列最大容量 typedef struct{ DATA data[QUEUEMAX]; //队列数组 int head; int tail; } SeqQueue; SeqQueue *SeqQueueInit(){ SeqQueue *q; if(q = (SeqQueue *)malloc(sizeof(SeqQueue))){ // 申请保存队列的内存 q-&gt;head = 0; q-&gt;tail = 0; return q; }else{ return NULL; } } void SeqQueueFree(SeqQueue *q){ //释放队列内存 if(q != NULL){ free(q); } } int SeqQueueIsEmpty(SeqQueue *q){//判断队列是否为空 return (q-&gt;head == q-&gt;tail); } int SeqQueueIsFull(SeqQueue *q){ //判断队列是否为满 return (q-&gt;tail == QUEUEMAX); } int SeqQueueLen(SeqQueue *q){ //获取队列长度 return (q-&gt;tail - q-&gt;head); } /*入队*/ int SeqQueueIn(SeqQueue *q, DATA data){ if(SeqQueueIsFull(q)){ printf(&quot;队列已满！&quot;); return 0; }else{ q-&gt;data[q-&gt;tail++] = data;//先插入data数据到tail位置，然后tail++ return 1; } } /*出队*/ DATA *SeqQueueOut(SeqQueue *q){ if(SeqQueueIsEmpty(q)){ printf(&quot;队列为空&quot;); return 0; }else{ return &amp;(q-&gt;data[q-&gt;head++]); //先得到data[head]的元素，然后head++ } } DATA *SeqQueuePeek(SeqQueue *q){//获取队列头部的元素 if(SeqQueueIsEmpty()){ printf(&quot;队列为空&quot;); return NULL; }else{ return &amp;(q-&gt;data[q-&gt;head]); } } 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"普通链表实例（全）","slug":"20170812_lb","date":"2020-01-15T05:50:39.625Z","updated":"2021-03-10T14:49:39.868Z","comments":true,"path":"2020/01/15/20170812_lb/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170812_lb/","excerpt":"链表的插入，删除，遍历等功能的实例 工程一共包含4个文件 Entity.h ：声明表的元素的类型。可以是基本数据类型也可以是结构体 ChainList.h ：定义表结构体，声明全局的宏定义，函数的声明 ChainList.c ：具体的函数实现 main.c ： 测试文件 参考博客文章： http://www.cnblogs.com/laojie4321/archive/2012/03/30/2425015.html参考博客文章： http://blog.163.com/jiaoruijun07@126/blog/static/68943278201042064246409/","text":"链表的插入，删除，遍历等功能的实例 工程一共包含4个文件 Entity.h ：声明表的元素的类型。可以是基本数据类型也可以是结构体 ChainList.h ：定义表结构体，声明全局的宏定义，函数的声明 ChainList.c ：具体的函数实现 main.c ： 测试文件 参考博客文章： http://www.cnblogs.com/laojie4321/archive/2012/03/30/2425015.html参考博客文章： http://blog.163.com/jiaoruijun07@126/blog/static/68943278201042064246409/ Entity.h typedef struct{ char key[15]; //结点的关键字 char name[20]; int age; } DATA; //定义结点类型 可定义为简单类型或者结构体 ChainList.h /* 头文件：数据结构的定义和操作原型 */ #include &lt;stdio.h&gt; #include &quot;Entity.h&quot; typedef struct Node{ DATA data; //数据域 struct Node *next; //指针域，指向下一个结点的地址 } ChainListType; ChainListType *ChainListAddEnd(ChainListType *head, DATA data); //添加结点到链表结尾 ChainListType *ChainListAddFirst(ChainListType *head, DATA data); //添加结点到头部 ChainListType *ChainListInsert(ChainListType *head, char *findKey, DATA data);//把数据插入链表（插入到某个关键字之后） ChainListType *ChainListFind(ChainListType *head, char *key); //按关键字查找 int ChainListDelete(ChainListType *head, char *key); //删除指定关键字的结点 int ChainListLength(ChainListType *head); //获取链表结点数量 ChainList.c #include &lt;string.h&gt; #include &lt;malloc.h&gt; #include &quot;ChainList.h&quot; /*添加结点到链表结尾*/ ChainListType *ChainListAddEnd(ChainListType *head, DATA data){ ChainListType *node, *h; //临时变量 用于保存新结点的地址和链表当前（头结点和循环时候的）结点的地址（即head） if(! (node = (ChainListType *)malloc(sizeof(ChainListType)))){//申请赋予内存地址用来保存新结点 //如果失败 printf(&quot;申请内存失败\\n&quot;); return NULL; } //分配成功 node-&gt;data = data; //设置数据域 node-&gt;next = NULL; //设置指针域指向空（这是一个结点） //把新加的结点连接到链表 if(head == NULL){ //如果头结点为空 表示没有实际结点 head = node; //头结点指向这个新结点 printf(&quot;|||||&quot;); ChainListLength(head); printf(&quot;|||||&quot;); return head; }else{ //头结点不为空 遍历到达当前链表的最后一个结点 h = head; while(h-&gt;next != NULL){ h = h-&gt;next; } h-&gt;next = node;//到达最后一个结点 赋值 return head; } } /*添加结点到头部*/ ChainListType *ChainListAddFirst(ChainListType *head, DATA data){ ChainListType *node; //临时变量 用于保存新结点的地址和链表当前（头结点和循环时候的）结点的地址（即head） if(! (node = (ChainListType *)malloc(sizeof(ChainListType)))){//申请赋予内存地址用来保存新结点 //如果失败 printf(&quot;申请内存失败\\n&quot;); return NULL; } //分配成功 node-&gt;data = data; //设置数据域 node-&gt;next = head; //设置指针域指向原来头指针指向的地址 head = node; //头结点指向新增结点 return head; } /*把数据插入链表（插入到某个关键字之后）*/ ChainListType *ChainListInsert(ChainListType *head, char *findKey, DATA data){ ChainListType *node, *node1; //临时变量 用于保存新结点的地址 if(! (node = (ChainListType *)malloc(sizeof(ChainListType)))){//申请赋予内存地址用来保存新结点 //如果失败 printf(&quot;申请内存失败\\n&quot;); return NULL; } //分配成功 node-&gt;data = data; //设置数据域 node1 = ChainListFind(head, findKey); //查找指定关键字的结点 if(node1){ //如果找到该结点 node-&gt;next = node1-&gt;next; //把找到的结点的下一个结点的地址赋值给新结点 node1-&gt;next = node; //把找到的结点的指针域指向新结点 }else{ free(node); //释放内存 printf(&quot;没有找到结点&quot;); } return head; } /*按关键字查找*/ ChainListType *ChainListFind(ChainListType *head, char *key){ ChainListType *h; h = head; while(h){ if(strcmp(h-&gt;data.key, key) == 0){ //字符串对比函数 相同则返回0 return h; } h = h-&gt;next; } return NULL; } /*删除指定关键字的结点*/ int ChainListDelete(ChainListType *head, char *key){ ChainListType *node, *h; //h指向循环当前结点 node指向h的前一个结点 node = h = head; while(h){ if(strcmp(h-&gt;data.key, key) == 0){ //字符串对比函数 相同则返回0 node-&gt;next = h-&gt;next; free(h); //释放 删除 return 1; }else{ node = h; //把h赋值给node h = h-&gt;next; //h指向h的下一个结点 } } return 0; } /*获取链表结点数量*/ int ChainListLength(ChainListType *head){ ChainListType *h; int i = 0; h = head; if(h == NULL){ printf(&quot;没有数据！！！&quot;); return 0; } while(h){ h = h-&gt;next; i++; } return i; } main.c /* 测试文件：调用测试函数*/ #include &lt;stdio.h&gt; #include &quot;ChainList.h&quot; /*遍历链表的数据*/ void ChainListAll(ChainListType *head){ ChainListType *h; h = head; printf(&quot;链表所有的数据：\\n&quot;); while(h){ //判断当前结点的存在 printf(&quot;%s %s %d \\t&quot;, h-&gt;data.key, h-&gt;data.name, h-&gt;data.age); h = h-&gt;next; } return; } int main(void){ ChainListType *node, *head = NULL; DATA data; int k, i; char key[15]; while(1){ fflush(stdin); printf(&quot;\\n\\n输入操作\\n1.插入到末尾\\t2.内容查询\\t3.插入到头部\\t4.插入到指定结点之后\\t5.删除\\t6.求长度\\t7.遍历\\t8.退出\\n：&quot;); scanf(&quot;%d&quot;, &amp;k); if(k == 8){ break; } switch(k){ case 1: printf(&quot;插入到末尾：输入元素内容：&quot;); scanf(&quot;%s %s %d&quot;, &amp;data.key, &amp;data.name, &amp;data.age); head = ChainListAddEnd(head, data); printf(&quot;插入的元素为：(%s %s %d) \\n&quot;, head-&gt;data.key, head-&gt;data.name, head-&gt;data.age); break; case 2: printf(&quot;输入元素key：&quot;); scanf(&quot;%s&quot;, &amp;key); node = ChainListFind(head, &amp;key); printf(&quot;元素为：(%s %s %d) \\n&quot;, node-&gt;data.key, node-&gt;data.name, node-&gt;data.age); break; case 3: printf(&quot;插入到头部：输入元素内容：&quot;); scanf(&quot;%s %s %d&quot;, &amp;data.key, &amp;data.name, &amp;data.age); head = ChainListAddFirst(head, data); printf(&quot;插入的元素为：(%s %s %d) \\n&quot;, head-&gt;data.key, head-&gt;data.name, head-&gt;data.age); break; case 4: printf(&quot;插入到指定结点之后：输入位置元素key和元素内容：&quot;); scanf(&quot;%s %s %s %d&quot;, &amp;key, &amp;data.key, &amp;data.name, &amp;data.age); head = ChainListInsert(head, &amp;key, data); printf(&quot;插入的元素为：(%s %s %d) \\n&quot;, head-&gt;data.key, head-&gt;data.name, head-&gt;data.age); break; case 5: printf(&quot;输入要删除的元素key：&quot;); scanf(&quot;%s&quot;, &amp;key); i = ChainListDelete(head, &amp;key); if(i == 1){ printf(&quot;删除成功\\n&quot;); }else{ printf(&quot;删除失败\\n&quot;); } break; case 6: printf(&quot;-----%d------\\n&quot;, ChainListLength(head)); break; case 7: ChainListAll(head); break; } } return 0; } 个人博客 欢迎来访： http://zj2626.com","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"顺序表实例（全）","slug":"20170811_xxb","date":"2020-01-15T05:50:39.623Z","updated":"2021-03-10T13:50:15.332Z","comments":true,"path":"2020/01/15/20170811_xxb/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170811_xxb/","excerpt":"顺序表的初始化，增加，插入，删除等功能的实例 工程一共包含4个文件 Entity.h ：声明线性表的元素的类型。可以是基本数据类型也可以是结构体 SeqList.h ：定义线性表结构体，声明全局的宏定义，函数的声明 SeqList.c ：具体的函数实现 main.c ： 测试文件 参考博客文章： http://www.cnblogs.com/laojie4321/archive/2012/03/30/2425015.html参考博客文章： http://blog.163.com/jiaoruijun07@126/blog/static/68943278201042064246409/","text":"顺序表的初始化，增加，插入，删除等功能的实例 工程一共包含4个文件 Entity.h ：声明线性表的元素的类型。可以是基本数据类型也可以是结构体 SeqList.h ：定义线性表结构体，声明全局的宏定义，函数的声明 SeqList.c ：具体的函数实现 main.c ： 测试文件 参考博客文章： http://www.cnblogs.com/laojie4321/archive/2012/03/30/2425015.html参考博客文章： http://blog.163.com/jiaoruijun07@126/blog/static/68943278201042064246409/ Entity.h typedef struct{ char key[15]; //结点的关键字 char name[20]; int age; } DATA; //定义结点类型 可定义为简单类型或者结构体 SeqList.h /* 头文件：数据结构的定义和操作原型 */ #include &lt;stdio.h&gt; #include &lt;string.h&gt; #include &quot;Entity.h&quot; #define MAXSIZE 100 //定义线性表最大长度 typedef struct { DATA ListData[MAXSIZE + 1]; //保存顺序表的数组(真正的数据从下标为1的位置开始) int ListLen; //顺序表结点个数（已存结点）；默认为0，表示没有数据 } SeqListType; void SeqListInit(SeqListType *SL); //初始化顺序表 int SeqListLength(SeqListType *SL); // 返回顺序表的元素数量 int SeqListAdd(SeqListType *SL, DATA data); // 向顺序表中添加元素 int SeqListInsert(SeqListType *SL, int n, DATA data); // 向顺序表中插入元素 int SeqListDelete(SeqListType *SL, int n); // 删除顺序表中的数据 DATA *SeqListFindByNum(SeqListType *SL, int n); // 根据序号返回元素 int SeqListFindByCont(SeqListType *SL, char *key); // 按关键字查找 int SeqListAll(SeqListType *SL); // 遍历顺序表 SeqList.c /*函数文件：具体的函数实现代码*/ #include &quot;SeqList.h&quot; /* 初始化顺序表 */ void SeqListInit(SeqListType *SL){ SL-&gt;ListLen = 0; } /* 返回顺序表元素数量 */ int SeqListLength(SeqListType *SL){ return (SL-&gt;ListLen); } /* 添加元素到顺序表尾 */ int SeqListAdd(SeqListType *SL, DATA data){ if(SL-&gt;ListLen &gt;= MAXSIZE){ // 顺序表已满 printf(&quot;顺序表已经满了 不能再添加&quot;); return 0; //返回失败 } SL-&gt;ListData[++SL-&gt;ListLen] = data; // 把数据插入到下标为（ListLen+1）的位置 return 1;//返回成功 } /* 插入元素到顺序表指定位置 */ int SeqListInsert(SeqListType *SL, int n, DATA data){ int i; if(SL-&gt;ListLen &gt;= MAXSIZE){ // 顺序表已满 printf(&quot;顺序表已经满了 不能再插入\\n&quot;); return 0; } if(n &lt; 1 || n &gt; SL-&gt;ListLen){ printf(&quot;要插入的位置错误\\n&quot;); return 0; } for(i = SL-&gt;ListLen; i&gt;=n; i--){ //移动要插入数据的后面的数据 SL-&gt;ListData[i+1] = SL-&gt;ListData[i]; } SL-&gt;ListData[n] = data; //插入数据 SL-&gt;ListLen++; //数据个数加一 return 1; } int SeqListDelete(SeqListType *SL, int n){ int i; if(n &lt; 1 || n &gt; SL-&gt;ListLen+1){ printf(&quot;结点错误 不能删除\\n&quot;); return 0; } for(i=n; i&lt;SL-&gt;ListLen; i++){ //移动要删除数据的后面的数据 SL-&gt;ListData[i] = SL-&gt;ListData[i + 1]; } SL-&gt;ListLen--; return 1; } DATA *SeqListFindByNum(SeqListType *SL, int n){ if(n &lt; 1 || n &gt; SL-&gt;ListLen+1){ printf(&quot;序号错误 获取失败&quot;); return NULL; } return &amp;(SL-&gt;ListData[n]); // 返回指针增加通用性 } int SeqListFindByCont(SeqListType *SL, char *key){ int i; for(i = 0; i &lt;= SL-&gt;ListLen; i++){ if(strcmp(SL-&gt;ListData[i].key, key) == 0){ return i; } } return 0; //遍历没有找到 } main.c /* 测试文件：调用测试函数*/ #include &lt;stdio.h&gt; #include &quot;SeqList.h&quot; /*遍历顺序表中结点*/ int SeqListAll(SeqListType *SL){ int i; for(i = 0; i &lt;= SL-&gt;ListLen; i++){ //输出中第一个是0， 即下标为0的位置的存储的数据 printf(&quot;(%s %s %d) \\n&quot;, SL-&gt;ListData[i].key, SL-&gt;ListData[i].name, SL-&gt;ListData[i].age); } return 0; } int main(void){ int i, k; SeqListType SL; //定义顺序表变量 DATA data, *data1; //定义结点保存数据类型变量和指针变量 char key[15]; //保存关键字 SeqListInit(&amp;SL); //初始化数据表 do{ printf(&quot;请输入学号 姓名 年龄: &quot;); fflush(stdin); //清空输入缓冲区 scanf(&quot;%s %s %d&quot;, &amp;data.key, &amp;data.name, &amp;data.age); if(data.age){ //年龄不是0 退出循环 if(!SeqListAdd(&amp;SL, data)){//添加元素到顺序表 break; //当添加失败 退出循环 } }else{ //当年龄为0 退出循环 break; } }while(1); printf(&quot;顺序表为： \\n&quot;); SeqListAll(&amp;SL); while(1){ fflush(stdin); printf(&quot;\\n\\n输入操作\\n1.获取结点位置元素\\t2.内容查询\\t3.添加\\t4.插入\\t5.删除\\t6.求长度\\t7.遍历\\t8.退出\\n：&quot;); scanf(&quot;%d&quot;, &amp;k); if(k == 8){ break; } switch(k){ case 1: printf(&quot;输入元素位置：&quot;); scanf(&quot;%d&quot;, &amp;i); data1 = SeqListFindByNum(&amp;SL, i); printf(&quot;元素为：(%s %s %d) \\n&quot;, data1-&gt;key, data1-&gt;name, data1-&gt;age); break; case 2: printf(&quot;输入元素key(学号)：&quot;); scanf(&quot;%s&quot;, &amp;key); i = SeqListFindByCont(&amp;SL, key); if(i == 0){ printf(&quot;没有找到对应元素！&quot;); break; } data1 = SeqListFindByNum(&amp;SL, i); printf(&quot;位置为： %d ,元素为：(%s %s %d) \\n&quot;, i, data1-&gt;key, data1-&gt;name, data1-&gt;age); break; case 3: printf(&quot;输入元素内容：&quot;); scanf(&quot;%s %s %d&quot;, &amp;data.key, &amp;data.name, &amp;data.age); SeqListAdd(&amp;SL, data); break; case 4: printf(&quot;输入位置和元素内容：&quot;); scanf(&quot;%d %s %s %d&quot;, &amp;i, &amp;data.key, &amp;data.name, &amp;data.age); SeqListInsert(&amp;SL, i, data); break; case 5: printf(&quot;输入要删除的位置：&quot;); scanf(&quot;%d&quot;, &amp;i); SeqListDelete(&amp;SL, i); break; case 6: printf(&quot;-----%d------\\n&quot;, SeqListLength(&amp;SL)); break; case 7: SeqListAll(&amp;SL); break; } } return 0; } 个人博客 欢迎来访： http://zj2626.github.io","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"模拟法 (实例)","slug":"20170810_mn","date":"2020-01-15T05:50:39.621Z","updated":"2018-01-13T02:29:22.175Z","comments":true,"path":"2020/01/15/20170810_mn/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170810_mn/","excerpt":"使用分治法解决猜数游戏在程序设计语言中， 可使用随机函数来模拟自然界中发生的不可预测情况。C语言中使用srand()和rand()函数可生成随机数。","text":"使用分治法解决猜数游戏在程序设计语言中， 可使用随机函数来模拟自然界中发生的不可预测情况。C语言中使用srand()和rand()函数可生成随机数。 #include &lt;stdio.h&gt; #include &lt;time.h&gt; int main() { int n, m, i = 0; srand(time(NULL)); n = rand() % 100 + 1; do{ printf(&quot;输入数字: &quot;); scanf(&quot;%d&quot;, &amp;m); i++; if(m &gt; n){ printf(&quot;输入的数太大了&quot;); }else if(m &lt; n){ printf(&quot;输入的数太小了&quot;); } }while(m != n); printf(&quot;对了 猜了 %d 次&quot;, i); return 0; }","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"贪心算法 (实例)","slug":"20170807_tx","date":"2020-01-15T05:50:39.620Z","updated":"2021-03-10T15:20:21.716Z","comments":true,"path":"2020/01/15/20170807_tx/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170807_tx/","excerpt":"使用贪心算法解决购物找零问题 要求: 输入要找零的金额，求得所需各种面值的纸币的个数 定义： 所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。 贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。","text":"使用贪心算法解决购物找零问题 要求: 输入要找零的金额，求得所需各种面值的纸币的个数 定义： 所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。 贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。 所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。 不能保证得到的是最优解 不能用来求最大或者最小解的问题 只能求满足某些条件的可行解的范围 分解复杂问题为简单的组合， 如图 #include &lt;stdio.h&gt; #include&lt;conio.h&gt; #define MAXN 9 // 以分为单位 下面表示国内的9种面值的纸币 int parvalue[MAXN] = {10000, 5000, 1000, 500, 200, 100, 50, 20, 10}; //num数组存放需要每个面值纸币的个数（数组的9个元素表示对应的面值纸币的个数） int num[MAXN] = {0}; int exchange(int n){ int i, j; for(i = 0; i &lt; MAXN; i++){ // 寻找比输入的钱低的最大面值 if(n &gt; parvalue[i]){ break; } } while(n &gt; 0 &amp;&amp; i &lt; MAXN){ //循环遍历数组（即从大到小对比面值和剩余的钱） if(n &gt;= parvalue[i]){ // 剩余钱数大于当前的面值， 则需要该面值的纸币 该纸币个数+1 然后吧剩余钱数减去面值 n -= parvalue[i]; num[i]++; }else if(n &lt; 10 &amp;&amp; n &gt;= 5){ // 如果钱数小于10分 则退出循环 num[MAXN - 1]++; break; }else{ // 开始循环下一个面值的纸币 i++; } } return 0; } int main(){ int i; float m; printf(&quot;亲输入找零的金额 ：&quot;); scanf(&quot;%f&quot;, &amp;m); exchange((int)100 * m); printf(&quot;\\n %.2f元零钱的组成：\\n&quot;, m); for(i = 0; i &lt; MAXN; i++){ if(num[i] &gt; 0){ printf(&quot;%6.2f: %d张\\n&quot;, (float)parvalue[i] / 100.0, num[i]); } } getch(); return 0; }","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"回溯算法 (实例)","slug":"20170807_hs","date":"2020-01-15T05:50:39.619Z","updated":"2021-03-10T15:20:21.760Z","comments":true,"path":"2020/01/15/20170807_hs/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170807_hs/","excerpt":"使用回溯算法解决N皇后问题 回溯算法也叫试探法，它是一种系统地搜索问题的解的方法。回溯算法的基本思想是：从一条路往前走，能进则进，不能进则退回来，换一条路再试。用回溯算法解决问题的一般步骤为： 定义一个解空间，它包含问题的解。 利用适于搜索的方法组织解空间。 利用深度优先法搜索解空间。 利用限界函数避免移动到不可能产生解的子空间。","text":"使用回溯算法解决N皇后问题 回溯算法也叫试探法，它是一种系统地搜索问题的解的方法。回溯算法的基本思想是：从一条路往前走，能进则进，不能进则退回来，换一条路再试。用回溯算法解决问题的一般步骤为： 定义一个解空间，它包含问题的解。 利用适于搜索的方法组织解空间。 利用深度优先法搜索解空间。 利用限界函数避免移动到不可能产生解的子空间。 问题的解空间通常是在搜索问题的解的过程中动态产生的，这是回溯算法的一个重要特性 要求：N皇后问题：在nn格的棋盘上放置彼此不受攻击的n个皇后。按照国际象棋的规矩，皇后可以攻击与之处在同一行或同一列或同一斜线上的棋子。n后问题等价于在nn格的棋盘上方置n个皇后，任何2个皇后不放在同一行或同一列或同一斜线上。我们需要求的是可放置的总数 例子：如下图 #include &lt;stdio.h&gt; #include &lt;math.h&gt; #include&lt;stdlib.h&gt; // n表示在 n*n 的坐标中进行操作 // 数组x[k]中 下表k表示横轴 x[k]得值表示纵轴 static int n, x[1000]; static long sum; //尝试 判断是否可以 如果不可以则回退到t+1层，再尝试其他的组合 int Place(int k) { int j; for( j = 1;j &lt; k; j++)//循环遍历已经确定位置的坐标(j表示行号) 与当前要选择的坐标进行对比 if((abs(k - j) == abs(x[j] - x[k])) || (x[j] == x[k])) //三个条件 1.任意两个不能在同一个斜边上 2.不能在同一行 3.不能在同一列(即j==k) return 0; return 1; } void Backtrak(int k) //初始1 { if(k &gt; n) sum++;//如果超过最后一行就算成功一个 else{ int i; for( i=1; i &lt;= n; i++){ // 循环一行的每个每一个空位,从1到n x[k] = i; // 表示第k行第i列 if(Place(k)) // 判断 Backtrak(k+1); // 操作完成 进行下一行 } } } int main() { int nn; printf(&quot;请输入2的整数次幂的数: &quot;); while(scanf(&quot;%d&quot;,&amp;nn)!=EOF){ n=nn; sum=0; int i; for(i=0;i&lt;=n;i++) x[i]=0; Backtrak(1); printf(&quot;%l\\n&quot;,sum); } }","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"分治法 (实例)","slug":"20170807_fzf","date":"2020-01-15T05:50:39.617Z","updated":"2021-03-10T15:20:21.729Z","comments":true,"path":"2020/01/15/20170807_fzf/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170807_fzf/","excerpt":"使用分治法解决循环日程表问题 要求: 安排比赛日程 每个选手与其他每个选手进行一对一比赛， 一天只与一个选手比赛，不重复比赛，不漏掉;","text":"使用分治法解决循环日程表问题 要求: 安排比赛日程 每个选手与其他每个选手进行一对一比赛， 一天只与一个选手比赛，不重复比赛，不漏掉; 例子: 如下图 分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题， 这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。 即一种分目标完成程序算法，简单问题可用二分法完成。 分解复杂问题为简单的组合， 如图 #include &lt;stdio.h&gt; #include&lt;conio.h&gt; #define MAXN 64 int a[MAXN + 1][MAXN + 1] = {0}; //从1开始 // 分治算法 void gamecal(int k, int n) {//k表示开始的选手编号， n表示选手个数 int i, j; if(n == 2){ a[k][1] = k; // 参赛选手编号为k a[k][2] = k + 1; // 对阵选手编号为k+1 a[k + 1][1] = k + 1; // 参赛选手编号为k a[k + 1][2] = k; // 对阵选手编号为k+1 }else { gamecal(k, n/2);//递归完成左上角 gamecal(k + n/2, n/2);//递归完成左下角 //右上角，右下角 通过观察发现与左下角和左上角完全一样。可以通过循环求得 for(i = k; i&lt; k + n/2; i++){//右上角 for(j = n/2 + 1; j &lt;= n; j++){ a[i][j] = a[i + n/2][j - n/2]; } } for(i = k + n/2; i &lt; k + n; i++){//右下角 for(j = n/2 + 1; j &lt;= n; j++){ a[i][j] = a[i - n/2][j - n/2]; } } } } int main(){ int m,i,j; printf(&quot;输入参赛选手人数: &quot;); scanf(&quot;%d&quot;, &amp;m); j = 2; for(i = 2; i &lt; 8; i++){//判断是否整数次幂 j = j * 2; if(j == m) break; } if(i &gt;= 8){ printf(&quot;参赛选手人数必须为2的整数次幂， 且不超过64个 \\n&quot;); getch(); return 0; } gamecal(1, m); printf(&quot;\\n编号 &quot;); for(i = 2; i &lt;= m; i++){ printf(&quot;%2d天&quot;, i - 1); } printf(&quot;\\n&quot;); for(i = 1; i &lt;= m; i++){ for(j = 1; j &lt;= m; j++){ printf(&quot;%4d&quot;, a[i][j]); } printf(&quot;\\n&quot;); } getch(); return 0; }","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"枚举法 (实例)","slug":"20170713_qjf","date":"2020-01-15T05:50:39.616Z","updated":"2018-01-13T02:29:22.168Z","comments":true,"path":"2020/01/15/20170713_qjf/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170713_qjf/","excerpt":"使用枚举法(穷举法)实现填运算符游戏 要求: 输入5个数字和1个结果 其中有4个位置选择4种运算符, 实现5个数字通过使用运算符计算,得到填入的结果; 例子: 填入 5 5 5 5 5 = 5 得到 5 + 5 - 5 * 5 / 5 = 5 (实际情况中可能有多种解)","text":"使用枚举法(穷举法)实现填运算符游戏 要求: 输入5个数字和1个结果 其中有4个位置选择4种运算符, 实现5个数字通过使用运算符计算,得到填入的结果; 例子: 填入 5 5 5 5 5 = 5 得到 5 + 5 - 5 * 5 / 5 = 5 (实际情况中可能有多种解) #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; int main() { //下面的所有的数组中第一个位置都不使用(下标为0) int j, i[5];//这里i的4个属性表示4个位置的运算符(什么运算符并不知) int sign;//累加运算事时的符号(需要把所有的加减法转化为乘除已杜绝运算符优先级的问题) int result;//保存运算式的结果值 int count=0;//计数器 int num[6];//操作数, 存放5个要进行计算的数字 float left, right; // 要把多个数的运算转换为多次的二元运算 left每次存放上次两个数的计算结果 char oper[5] = {&apos; &apos;, &apos;+&apos;, &apos;-&apos;, &apos;*&apos;, &apos;/&apos;}; //下标为1 2 3 4位置分别表示 + - * / (由oper数组中属性位置而定, 例如 ) printf(&quot;请输入5个数\\n&quot;); for(j=1; j&lt;=5; j++){ scanf(&quot;%d&quot;, &amp;num[j]); } printf(&quot;请输入结果\\n&quot;); scanf(&quot;%d&quot;, &amp;result); for(i[1] = 1;i[1] &lt;= 4;i[1]++){//循环第一个位置的运算符 // 只有两种情况可以进行下一步: 1,不是i[n]&lt;4(即不是除法) 2,是i[n]==4而且下一个数字不是0(因为除数不能是0) if((i[1] &lt; 4) || (num[2] != 0)){ for(i[2] = 1;i[2] &lt; 4;i[2]++){//循环第二个位置的运算符 if((i[2] &lt; 4) || (num[3] !=0)){ for(i[3] = 1; i[3] &lt;= 4; i[3]++){//循环第三个位置的运算符 if((i[3] &lt; 4) || num[4] != 0){ for(i[4] = 0; i[4] &lt;= 4; i[4]++){//循环第四个位置的运算符 if((i[4] &lt; 4) || (num[5] != 0)){ //四重循环以后 就得到所有的4个位置的运算符的所有的组合情况 left = 0;//设置初始 right = num[1];//设置初始 sign = 1; // 1正数 -1负数 //printf(&quot;[%d %d %d %d]\\t&quot;, i[1], i[2], i[3], i[4]); for(j=1;j&lt;=4;j++){//开始组合4个运算符并完成计算 //下次进入循环的时候才计算这次的结果, 所以需要在循环外面加上最后一次的right //如果是+-,会把以前的结果(left和right)存放到left中,把要+-的对象存放到right,等待以后循环时候执行+-操作 //如果是*/,会把本次的*/的双方直接进行操作, 把结果存放到right中,等待以后循环的时候把right在加入到left中 //通过以上两种处理结果, 在最终循环外部把left和right相加(或相减,取决于sign) switch(oper[i[j]]) { case &apos;+&apos;: left = left + sign * right; sign = 1; right = num[j+1]; break; case &apos;-&apos;: left = left + sign * right; sign = -1; right = num[j+1]; break; case &apos;*&apos;: right = right * num[j+1]; break; case &apos;/&apos;: right = right / num[j+1]; break; } } if(left + sign * right == result){//对比得到结果和设置的结果 count++; printf(&quot;%3d\\t&quot;, count); for(j = 1; j &lt;= 4; j++){ printf(&quot;%d%c&quot;, num[j], oper[i[j]]); } printf(&quot;%d=%d\\n&quot;, num[5], result); } } } } } } } } } if(count == 0){ printf(&quot;没有符合要求的方法!&quot;); } getch(); return 0; }","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"Junit运行报错","slug":"20170615_junit","date":"2020-01-15T05:50:39.611Z","updated":"2021-03-10T15:20:21.821Z","comments":true,"path":"2020/01/15/20170615_junit/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170615_junit/","excerpt":"","text":"maven项目运行测试程序报错 Exception in thread “main” java.lang.NoSuchMethodError: org.junit.platform.commons.util.AnnotationUt 问题所在: 写测试的注解 @Test 时候 idea提示导包, 导入了两个包, 其中第一个包并不是需要的 删除即可","categories":[{"name":"BUG解决","slug":"BUG解决","permalink":"http://zj2626.github.io/categories/BUG解决/"}],"tags":[{"name":"junit","slug":"junit","permalink":"http://zj2626.github.io/tags/junit/"}]},{"title":"重新学习c语言,零碎的知识点","slug":"20170507_c_note","date":"2020-01-15T05:50:39.610Z","updated":"2018-01-13T02:29:22.161Z","comments":true,"path":"2020/01/15/20170507_c_note/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170507_c_note/","excerpt":"编译过程4步骤: 前提: 一个helloworld.c文件 执行 gcc helloworld.c命令进行编译; 过程: .c文件 –&gt; . i文件 :预处理 预处理之一: (.i文件也是c语法)把头文件展开 预处理之二: 宏替换(#define),即把代码中的宏定义替换为定义的字符串(单纯的字符串替换,不识别类型)) ps:宏定义内容可以是任意字符串, 只要替换以后符合c语法即可(可以是表达式) ps:宏定义#define和typedef不同,typedef(关键字)是为变量类型起别名,而#define可以为任意字符串任意字符串的&quot;别名&quot;,而且typedef在预处理时候不会被替换 .i文件 –&gt; .s文件 :编译 .s文件 –&gt; .o文件 :汇编 .o文件 –&gt; 可执行文件 :链接","text":"编译过程4步骤: 前提: 一个helloworld.c文件 执行 gcc helloworld.c命令进行编译; 过程: .c文件 –&gt; . i文件 :预处理 预处理之一: (.i文件也是c语法)把头文件展开 预处理之二: 宏替换(#define),即把代码中的宏定义替换为定义的字符串(单纯的字符串替换,不识别类型)) ps:宏定义内容可以是任意字符串, 只要替换以后符合c语法即可(可以是表达式) ps:宏定义#define和typedef不同,typedef(关键字)是为变量类型起别名,而#define可以为任意字符串任意字符串的&quot;别名&quot;,而且typedef在预处理时候不会被替换 .i文件 –&gt; .s文件 :编译 .s文件 –&gt; .o文件 :汇编 .o文件 –&gt; 可执行文件 :链接 结构体定义: 123456789101112131415161718192021222324struct student &#123; char name[20]; int age; int price;&#125; stu; //这里是定义一个结构体 名为stu 类型为 struct studentstruct &#123; char name[20]; int age; int price;&#125; stuO; //这里是定义一个结构体 名为stu 并且不能再定义其他的相同的结构体变量typedef struct student2 &#123; char name[20]; int age; int price;&#125; stu2; //这里是定义一个结构体的别名 名为stu2int main() &#123; struct student2 ss = &#123;\"aaaaaa\", 20, 31&#125;; //定义一个结构体 ss是结构体的引用 struct student2 ss2[2] = &#123;&#123;\"aaaaaa\", 20, 31&#125;, &#123;\"bbbb\", 21, 32&#125;&#125;; //定义一个结构体数组 printf(\"______________ %s\", ss.name); printf(\"______________ %d\", ss.age);&#125; 结构体指针: 12345678struct student2 *sNode;struct student2 *sNode2;sNode = &amp;ss;sNode2 = &amp;ss2;//指向结构体数组的第一个元素的地址 可以进行 sNode2++ 就指向第二个元素printf(\"______________ %d\", (*sNode).age);printf(\"______________ %d\", sNode-&gt;age); // -&gt;是 指向运算符printf(\"______________ %d\", sNode2-&gt;age); 共用体: 12345678910111213141516171819union data &#123; int a; char b; char c[5]; //此处共用体占用的空间大小是8 (结构体对象大小=最后一个成员的偏移量+最后一个成员的大小+末尾填充字节数), 见 内存对齐机制 http://blog.csdn.net/fb2058/article/details/15502071 int d;&#125;;//偏移量: 某个成员的实际地址和结构体首地址之间的距离int main() &#123; union data dd = &#123;10&#125;; //共用体成员共享一块空间(是成员之间 so一个成员被赋值,其他的成员跟着变) dd.b = 'a'; printf(\"___SIZE____ %lu\\n\", sizeof(dd)); printf(\"________ %d\", dd.a); printf(\"________ %c\", dd.b); printf(\"________ %s\", dd.c); printf(\"________ %d\", dd.d);&#125;","categories":[],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"数据结构随笔","slug":"20170505_line","date":"2020-01-15T05:50:39.609Z","updated":"2021-03-10T15:20:21.812Z","comments":true,"path":"2020/01/15/20170505_line/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170505_line/","excerpt":"","text":"线性表 顺序存储 链式存储 分配方式 连续的存储单元 依次存储 链式存储结构 查找时间复杂度 O(1) O(n) 更新时间复杂度 O(n) O(1) 空间 固定 可扩展 顺序存储1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 封装顺序存储结构 三个条件 1.起始位置 2.最大容量 3.当前长度 优点: 1.无需为表中逻辑关系增加额外的存储空间(空间是紧挨着的) 2.读取元素速度快 缺点: 1.插入,删除操作复杂速度慢 2.易造成空间碎片化 EG: *********************************** #define MAXSIZE 20 typedef int ElemType; typedef struct &#123; ElemType data[MAXSIZE];//内存中的存储位置页数连续的 下标从0开始 int length; //当前长度 &#125; SqList; *********************************** ``` &lt;!--more--&gt;&gt; 顺序存储元素操作```cpp// 1. 获取list中的某个元素#define OK 1#define ERROR 0#define TRUE 1#define FALSE 0typedef int Status; //返回值类型 状态码// i是取第几个位置的值 则其位置下标为 i-1; *e即为获取的元素Status GetElem(SqList L, int i, ElemType *e)&#123; if(L.length==0 || i&gt;L.length) &#123; return ERROR; &#125; *e = L.data[i-1]; return OK;&#125; 测试结果: 123456789101112131415161718192021222324252627282930// 2. 插入元素到list的指定的位置Status ListInsert(SqList *L, int i, ElemType e) //i插入的位置 e插入的数据&#123; int k; if(L -&gt; length == MAXSIZE)//判断List顺序表的实际长度是否已经达到最大长度,即是否已经满了 ( -&gt; 用来取子数据) &#123; return ERROR; &#125; if(i&lt;1 || i&gt;L-&gt;length+1) //判断i在不在已有数据组成的表范围之内 &#123; return ERROR; &#125; if(i&lt;=L-&gt;length) //在合理的范围内 &#123; for(k=L-&gt;length-1; k&gt;= i-1; k--)//从后往前一个一个向后移动一位 (eg: a[1]是第二个元素) &#123; L-&gt;data[k+1] = L-&gt;data[k]; &#125; &#125; L-&gt;data[i-1] = e; //把数据插入到该位置 L-&gt;length++; //表长度增加 return OK;&#125; 测试结果: 12345678910111213141516171819202122232425262728293031// 3. 删除元素从list的指定的位置Status ListDelete(SqList *L, int i, ElemType *e)// i是删除的位置 *e是删除的元素&#123; int k; if(L-&gt;length == 0) &#123; return ERROR; &#125; if(i&lt;1 || i &gt; L-&gt;length) &#123; return ERROR; &#125; *e = L-&gt;data[i-1]; //被删除的元素 if(i &gt;= 1) //在合理的范围内 &#123; for(k=i; k&lt;= L-&gt;length-1; k++)//从前往后一个一个向前移动一位 (eg: a[1]是第二个元素) &#123; L-&gt;data[k-1] = L-&gt;data[k]; &#125; &#125; L-&gt;length--; //表长度减少 return OK;&#125; 测试结果: 链式存储特色: 用一组任意的存储单元存储线性表的数据元素, 每个地址叫结点, 需要存储元素(数据域)和其后继元素的地址(指针域, 内部数据叫指针或链) *只有一个指针域 --&gt; 单链表 *头指针 -- &gt; 指向头结点的指针(永不为空,即使链表为空); *头结点 --&gt; 第一个结点 (不存储数据,数据域可以存放链表长度) ; *最后一个结点指向空(NULL); *空链表 -- &gt; 有头结点和头指针, 没有其他结点, 直接指向NULL EG: *********************************** typedef struct Node { ElemType data; //数据域 struct Node* next; //指针域 } Node; typedef struct Node* LinkList; //取Node*的别名为LinkList //LinkList p; p-&gt;data p-&gt;next *********************************** 链式存储元素操作 12345678910111213141516171819202122232425// 1. 获取list中的某个元素Status GetElemL(LinkList L, int i, ElemType *e)&#123; int j; LinkList p; //p即为一个指针 指向链表 p = L-&gt;next;//使p指向当前链表的第一个结点 j = 1; while( p &amp;&amp; j &lt; i)//判断p不为空 且没到要查询的结点 查到或者到头了就退出循环 &#123; p = p-&gt;next; ++j; &#125; if(!p || j &gt; i) //没找到 &#123; return ERROR; &#125; *e = p-&gt;data; return OK;&#125; 测试结果: 123456789101112131415161718192021222324252627282930// 2. 插入元素到list的指定的位置Status ListInsertL(LinkList L, int i, ElemType e) //i插入的位置 e插入的数据&#123; int j; LinkList p, s; p = L; j = 1; while(p &amp;&amp; j&lt;i)//循环遍历链表 使p指向一个一个结点直到最后(p结点为null)或者到达要插入的地方 &#123; p = p-&gt;next; j++; &#125; if(!p || j&gt;i) // 判断要插入的位置存在 &#123; return ERROR; &#125; s = (LinkList)malloc(sizeof(Node)); //生成新的结点 结点大小=sizeof(Node) 然后强转 s-&gt;data = e; //设置结点数据域 s-&gt;next = p-&gt;next; //把插入结点的上一个结点的指针赋给要插入的结点的指针域 p-&gt;next = s; //把插入结点的上一个结点的指针指向插入的结点 return OK;&#125; 测试结果: 1234567891011121314151617181920212223242526272829// 3. 删除元素从list的指定的位置Status ListRemove(LinkList L, int i, ElemType *e)// i是删除的位置 *e是删除的元素&#123; int j; LinkList p, q; p = L; //先指向头结点, 要删除的结点从头结点指向的结点开始算起;即到最后要删除结点是p-&gt;next j = 1; while(p-&gt;next &amp;&amp; j&lt;i)//循环遍历链表 使p指向一个一个结点直到最后(p结点指针指向null)或者到达要插入的地方 &#123; p = p-&gt;next; j++; &#125; if(!(p-&gt;next) || j&gt;i) // 判断要删除的结点存在 &#123; return ERROR; &#125; q = p-&gt;next; //q结点是要删除的结点 p-&gt;next = q-&gt;next; //q结点指针域可能指向null(q是最后一个结点时候) free(q); //释放空间 return OK;&#125; 测试结果: 链式存储整表创建(建立单链表) (顺序存储 == 数组) 头插法1234567891011121314151617181920212223// 1. 头插法建立单链表: // 把新加入的结点插入到链表头部, 把头结点指向新插入的结点(会使插入的结点顺序与原先设定的顺序颠倒)void CreateListHead(LinkList *L, int n)&#123; LinkList p; int i;// srand(time(0)); //初始化随机数 //这里L是指针 *L表示链表头结点 *L = (LinkList)malloc(sizeof(Node)); //初始化一个链表的头结点(可以放在函数外面) (*L)-&gt;next = NULL; //设置头结点默认指向null for(i=0; i&lt;n; i++) &#123; p = (LinkList)malloc(sizeof(Node)); //新建结点 p-&gt;data = rand() % 100 + 1; //随机数赋值到每个结点的数据域 p-&gt;next = (*L)-&gt;next; //把原来的头结点指针指向的地址赋值给新建的结点(因为要插入到头部) (*L)-&gt;next = p; //更新头结点指针域 &#125;&#125; 测试结果: 尾插法123456789101112131415161718192021// 1. 尾插法建立单链表: void CreateListTail(LinkList *L, int n)&#123; LinkList p, r; int i;// srand(time(0)); *L = (LinkList)malloc(sizeof(Node)); //初始化一个链表的头结点 r = *L; //使r指向生成的链表(当前只有头结点 所以r指向头结点) /*定义一个临时指针变量指向表头*/ for(i=0; i&lt;n; i++) &#123; p = (Node *)malloc(sizeof(Node)); //新建结点 p-&gt;data = rand() % 100 + 1; //随机数赋值到每个结点的数据域 r-&gt;next = p; //使r的指针域指向新的结点 r = p; //把新结点赋给r r指向链表的最后一个结点 &#125; r-&gt;next = NULL; //当全部插入的之后 要把最后一个节点的指针域指向NULL&#125; 测试结果: 链式存储整表删除 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758Status ClearList(LinkList L)&#123; LinkList p, q; p = L-&gt;next; while(p) &#123; q = p-&gt;next; free(p); //p指向每次都释放的地址 p = q; &#125; L-&gt;next = NULL; return OK;&#125; ## 静态链表: 用数组实现链表#### 定义 #define MAXSIZE 1000 typedef struct &#123; ElemType data; //数据 int cur; //游标(Cursor) &#125; Component, StaticLinkList[MAXSIZE]; #### 初始化//初始化void InitList(StaticLinkList space)&#123; int i; for(i=0; i &lt; MAXSIZE-1; i++) &#123; space[i].cur = i + 1; &#125; space[MAXSIZE-1].cur = 1; //最后一个结点存放有数据的第一个节点下标&#125;//返回链表长度int ListLength(StaticLinkList L) &#123; int i, j = 0; i = L[0].cur; //i指向第一个结点 while (i) //最后一个结点的指针域为0，结束循环 &#123; ++j; i = L[i].cur; &#125; return j;&#125; 插入新元素到静态链表 需要先获取一个空闲的链表位置, 插入数据,再把该位置插入到指定位置(其实就是更改cur, 使其链接起来) 123456789101112131415161718192021222324252627282930//申请分配一个空闲节点int malloc_sl(StaticLinkList space) &#123;//分配空闲节点 int i = space[0].cur;//总是取头结点之后的第一个空闲结点做分配，同时空闲链表非空，头结点做调整 if (space[0].cur) &#123; space[0].cur = space[i].cur;//空闲链表头结点调整指针域(把分配结点的cur存放在头结点) &#125; return i;//返回申请到的空闲节点的数组下标&#125;//插入数据到指定节点之前 i的前一个节点void ListInsert(StaticLinkList L, int i, ElemType e) &#123;//e是新插入的元素 i是要插入的位置(插入到第i个元素之前) int j, k, l; k = MAXSIZE - 1; //数组最后一个元素 if (i &lt; 1 || i &gt; ListLength(L)) &#123; return; &#125; j = malloc_sl(L); //申请一个节点, j是下标 if (j) &#123; // C里面非零就是真 L[j].data = e;//赋值到静态链表指定位置 for (l = 1; l &lt;= i - 1; l++) &#123; k = L[k].cur; //目的是 通过循环获取到第(i-1)个元素的下标,其下标为k,其cur为i &#125; L[j].cur = L[k].cur; //把下标为(i-1)的元素的cur赋值给第下标为j的元素的cur: 即把插入节点的\"指针\"指向要插入的节点之前(i) L[k].cur = j; //把下标为(i-1)的元素的cur设置为新插入的节点; 原理和动态链表很相似 &#125;&#125; 静态链表删除元素 要先修改游标(把该节点的游标赋值到其上一个节点的游标) 然后在删除节点数据, 再把该节点接到后面的空闲节点上 123456789101112131415161718192021222324void free_sll(StaticLinkList L, int i) &#123; L[i].cur = L[0].cur; // 头结点中存放的是第一个空闲节点下标 把该下标赋值给删除的节点 L[0].cur = i; //把要删除的节点的下标赋值给头结点; L[i].data = 0; &#125;// 删除指定节点数据(下标减1的节点) L[i-1]void ListDelete(StaticLinkList L, int i) &#123; int j, k; k = MAXSIZE - 1; if (i &lt; 1 || i &gt; ListLength(L)) &#123; return; &#125; for (j = 1; j &lt;= i - 1; j++) &#123; k = L[k].cur; //循环得到要删除的结点的前一个节点(不是物理的前一个,而是cur是i-1的节点) &#125; j = L[k].cur; //获取要删除的结点的cur赋值到j L[k].cur = L[j].cur;//把j赋值给该节点 free_sll(L, j);//\"释放\"节点数据&#125; 循环链表定义: 最后一个结点的指针域指向头结点，整个链表形成一个环 判断空链表的条件是 head == head-&gt;next;","categories":[{"name":"数据结构和算法","slug":"数据结构和算法","permalink":"http://zj2626.github.io/categories/数据结构和算法/"}],"tags":[{"name":"C语言","slug":"C语言","permalink":"http://zj2626.github.io/tags/C语言/"}]},{"title":"linux(centos)下使用jenkins + maven + git码云(或github) 实现自动化构建项目","slug":"20170504_jenkins","date":"2020-01-15T05:50:39.608Z","updated":"2021-03-10T15:33:38.698Z","comments":true,"path":"2020/01/15/20170504_jenkins/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170504_jenkins/","excerpt":"###1.下载jenkins 官网下载地址,自己选取对应系统 https://jenkins.io/download/ 下载rpm或者直接下载war包 https://pkg.jenkins.io/redhat/jenkins-2.9-1.1.noarch.rpm 系统环境要求: jdk, tomcat, git, maven (没有就安装先) rpm -ivh jenkins-2.9-1.1.noarch.rpm 我的安装到 /usr/lib/jenkins目录 Jenkins主目录是用户目录下的.jenkins目录 /root/.jenkins","text":"###1.下载jenkins 官网下载地址,自己选取对应系统 https://jenkins.io/download/ 下载rpm或者直接下载war包 https://pkg.jenkins.io/redhat/jenkins-2.9-1.1.noarch.rpm 系统环境要求: jdk, tomcat, git, maven (没有就安装先) rpm -ivh jenkins-2.9-1.1.noarch.rpm 我的安装到 /usr/lib/jenkins目录 Jenkins主目录是用户目录下的.jenkins目录 /root/.jenkins 复制文件夹内的jenkins.war到tomcat目录下的webapps目录下 并启动tomcat (./startup.sh) 进入: cd ~/.jenkins/ 目录介绍: jobs: 项目配置目录(新建的job,即一个个项目 的配置存放在这里) logs: 日志目录 workspaces: 默认的工作空间(每个项目会存放在这里) users: 创建的用户目录 secrets: 初始的设置(包括初始化的密码, 在创建了用户以后会自动删除里面的初始化密码文件) tomcat启动以后 访问网页 http://127.0.0.1/jenkins 提示输入初始化密码, 密码在secrets目录下的initialAdminPassword文件内进入后先创建一个用户(以后就用这个用户登录), 然后提示下载插件(可以下载推荐的也可以自定义) ##按照提示新建一个项目 如图:这里测试从码云获取项目,so选择第一个, 设置完后 保存 (如果是maven项目 需要下载个maven插件-&gt; Maven Integration plugin 在设置里下载 安装重启 下面介绍) 填写内容: 项目名称: 最好和真正的项目名相同 描述: 随意 源码管理: 选择 git (当遇到 401, 没权限, 读取远程key失败请看下面错误解决) 构建触发器: 设置什么时候触发构建功能(可以用脚本,或者有人提交代码到码云时候构建,或者定时构建都可以) (jenkins有各种提示, 都介绍的很详细了) 如果项目是私有的项目(如码云中的), 则需要设置用户名密码–在 Credentials 中配置 Add 一个 点击左侧 立即构建到主面板查看项目构建情况: 红色代表失败, 蓝色表示成功 可以再面板的 系统管理/系统设置 中修改设置 系统设置: 1.点击高级设置: 可以修改 工作空间根目录,构建记录根目录 2.可以修改时间格式 3.可以修改ssh端口,管理员邮件地址,Jenkins URL等等 Global Tool Configuration: 1.设置maven路径 2.设置jdk路径 3.设置git文件路径 ##对于maven项目 配置如图一,可自行更改 下图是点击构建以后打印的日志信息(正在下载依赖) (but有个问题 下载的jar包并没有按照我maven中配置的仓库地址,而是下载到了.jenkins目录下) ##发布war到tomcat: 由于这里编译就和自己电脑打包项目一样,会把war包放在target目录下, 我们需要一个插件把其发送到tomcat的webapps中 (下载插件 Deploy to container Plugin) 安装插件以后进入项目的配置界面 设置”构建后操作”,里面就会多一个 “Deploy war/ear to a container” 选项 配置: WAR/EAR files: target/*.war (war包的相对路径,相对工作空间) Context path: MeetCode (发布到tomcat的路径,这里我用项目名,到时候访问就用http://127.0.0.1:80/MeetCode) Containers: 配置一个tomcat容器(我用的tomcat8,但是我的版本没有 只能用7x) Manager user name: (tomcat用户名: 进入tomcat/conf/tomcat-users.xml设置) Manager password: 密码 Tomcat URL: http://127.0.0.1:80 (设置远程tomcat访问路径) 设置完毕 保存 构建 可看日志观察构建过程 (进入tomcat/webapps下 发现war包正在传入), success之后访问网页可用 其实也可以不发送war包, 可以在Post Steps中配置maven运行命令* 要求: 1. 在pom文件中加入tomcat插件 2. 如下图配置,则构建最后会直接通过maven运行启动项目 其他问题: 运行其实依然处于正在构建状态(可以自己查看项目构建状态), 所以需要在项目配置中勾选&quot;丢弃旧的构建&quot;,保持构建的最大个数填写&quot;1&quot;,(也可以设置构建最大时间); ##设置邮件消息 1.进入 系统管理 / 系统设置 / 邮件通知 设置选项: (这里用qq邮箱测试) SMTP服务器: smtp.qq.com 用户默认邮件后缀: @qq.com 使用SMTP认证: true 用户名: (作为发件箱的qq邮箱,可以带或不带后缀) 密码: (一般是邮箱密码,qq邮箱特殊,需要进入qq邮箱/设置/账户设置, 发送短信生成一个smtp密码) 使用SSL协议: false SMTP端口: 587 Reply-To Address: 我没写 字符集: UTF-8 测试: 写另一个邮箱地址进行测试 注意: 如果失败, 提示com.sun.mail.smtp.SMTPSendFailedException: 501 mail from address must be sam 需要设置 系统管理员邮件地址, 在本页面上面,必须与发件箱一致 错误解决: 问题: 设置git地址时候 遇到401错误 或者 fatal: Could not read from remote repository 原因: 本地git没有配置SSH公钥 这个配置在github中在右上角 Settings/SSH keys and GPG keys 中 在码云中在右上角 修改资料/SSH公钥 中(二者命令不同) github生成公钥 命令: git config --global user.name &quot;XXXXX&quot; git config --global user.email &quot;XXXXXXX@gmail.com&quot; 1.查看是否已经有了ssh密钥：cd ~/.ssh 如果没有密钥则不会有此文件夹，有则备份删除 2.生存密钥： ssh-keygen -t rsa -C &quot;XXXXXXX@gmail.com&quot; 按3个回车，密码为空。 此时生成两个文件:id_rsa和id_rsa.pub 公钥在id_rsa.pub中,查看并复制粘贴到上面github的配公钥的地方,添加一个公钥 并且在本地也添加公钥 ssh-add id_rsa.pub 码云生成公钥 命令: 见 http://git.mydoc.io/?t=154712","categories":[{"name":"Git","slug":"Git","permalink":"http://zj2626.github.io/categories/Git/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"http://zj2626.github.io/tags/jenkins/"},{"name":"Git","slug":"Git","permalink":"http://zj2626.github.io/tags/Git/"},{"name":"maven","slug":"maven","permalink":"http://zj2626.github.io/tags/maven/"}]},{"title":"Shiro的学习Helloworld","slug":"20170326_shiro","date":"2020-01-15T05:50:39.606Z","updated":"2021-05-31T14:57:02.766Z","comments":true,"path":"2020/01/15/20170326_shiro/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170326_shiro/","excerpt":"Apache Shiro是Java的一个安全框架Shiro可以帮助我们完成：认证、授权、加密、会话管理、与Web集成、缓存等 Shiro基本功能 Authentication：身份认证/登录，验证用户是不是拥有相应的身份； Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限； Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE环境的，也可以是如Web环境的； Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储； Web Support：Web支持，可以非常容易的集成到Web环境； Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率； Concurrency：shiro支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去； Testing：提供测试支持； Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问； Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。","text":"Apache Shiro是Java的一个安全框架Shiro可以帮助我们完成：认证、授权、加密、会话管理、与Web集成、缓存等 Shiro基本功能 Authentication：身份认证/登录，验证用户是不是拥有相应的身份； Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限； Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE环境的，也可以是如Web环境的； Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储； Web Support：Web支持，可以非常容易的集成到Web环境； Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率； Concurrency：shiro支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去； Testing：提供测试支持； Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问； Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。 1.身份认证配置文件： ******************************** [users] zj2626=123456 ay2626=456789 ******************************** package com.em; import org.apache.shiro.SecurityUtils; import org.apache.shiro.authc.UsernamePasswordToken; import org.apache.shiro.config.IniSecurityManagerFactory; import org.apache.shiro.mgt.SecurityManager; import org.apache.shiro.subject.Subject; import org.apache.shiro.util.Factory; public class Hello { public static void main(String args[]) { //初始化SecurityManager工厂 读取配置文件中的用户名密码 Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory(&quot;classpath:shiro.ini&quot;); //获取SecurityManager实例 SecurityManager manager = factory.getInstance(); //把SecurityManager实例绑定到SecurityUtils SecurityUtils.setSecurityManager(manager); //得到当前执行的用户 Subject subject = SecurityUtils.getSubject(); //创建token令牌, 用户/密码 UsernamePasswordToken token = new UsernamePasswordToken(&quot;zj2626&quot;, &quot;123456&quot;); try { //身份认证 登录 subject.login(token); System.out.println(&quot;登录成功&quot;); } catch (Exception e) { System.out.println(&quot;登录失败&quot;); e.printStackTrace(); } subject.logout(); } /* Subject: 认证主体 Principals: 身份: 用户名 Credentials: 凭证: 密码 Realm: 域 1.jdbc realm | 2.jndi realm | 3.text realm */ } 从数据库中读取用户名密码 实现登录 1.配置文件: jdbc_realm.ini （代码只需把读取的文件改成此文件即可测试使用） [main] jdbcRealm=org.apache.shiro.realm.jdbc.JdbcRealm dataSource=com.mchange.v2.c3p0.ComboPooledDataSource dataSource.driverClass=com.mysql.jdbc.Driver dataSource.jdbcUrl=jdbc:mysql://127.0.0.1:3306/test dataSource.user=root dataSource.password=123456 jdbcRealm.dataSource=$dataSource securityManager.realms=$jdbcRealm 2.权限认证核心要素：（资源，）权限，角色，用户用户–（分配）–&gt;角色–（拥有）–&gt;权限–（控制）—-&gt;资源 用户代表访问系统的用户，即subject。 三种授权方式 1. 编程式授权 1.1. 基于角色的访问控制 1.2. 基于权限的访问控制 2. 注解式授权 3.JSP标签授权 ####步骤1: 封装一个工具类 public class ShiroUtils { public static Subject login(String conf, String username, String passowrd) { //初始化SecurityManager工厂 conf是配置文件名称 Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory(&quot;classpath:&quot; + conf + &quot;.ini&quot;); //获取SecurityManager实例 SecurityManager manager = factory.getInstance(); //把SecurityManager实例绑定到SecurityUtils SecurityUtils.setSecurityManager(manager); //得到当前执行的用户 Subject subject = SecurityUtils.getSubject(); //创建token令牌, 用户/密码 UsernamePasswordToken token = new UsernamePasswordToken(username, passowrd); try { //身份认证 登录 subject.login(token); } catch (Exception e) { e.printStackTrace(); } return subject; } } ####步骤2: 测试多种访问控制 /* 基于角色的访问控制方式1 配置文件：shiro_role.ini ****************************** [users] zj2626=123456,role1,role2 py2626=123456,role1 ay2626=456789,role3 ****************************** */ @Test public void testHas() { Subject sub = ShiroUtils.login(&quot;shiro_config/shiro_role&quot;, &quot;zj2626&quot;, &quot;123456&quot;); //判断有没有权限 返回布尔 表示验证的成功与否 boolean bool = sub.hasRole(&quot;role1&quot;); if (bool) { System.out.println(&quot;HAS&quot;); } //判断有没有权限,一次多个分别判断 返回布尔数组 boolean[] booleans = sub.hasRoles(Arrays.asList(&quot;role1&quot;, &quot;role2&quot;, &quot;role3&quot;)); int i = 0; while (booleans[i]) { i++; if (booleans.length &lt;= i) { break; } } //所有的角色都有才返回true System.out.println(sub.hasAllRoles(Arrays.asList(&quot;role1&quot;, &quot;role2&quot;, &quot;role3&quot;))); //判断有没有权限 没有则抛异常 sub.checkRole(&quot;role1&quot;); sub.checkRole(&quot;role3&quot;); //判断多个权限 有一个没有就抛异常 (2种参数形式) sub.checkRoles(Arrays.asList(&quot;role1&quot;, &quot;role2&quot;, &quot;role3&quot;)); sub.checkRoles(&quot;role1&quot;, &quot;role2&quot;, &quot;role3&quot;); //退出登陆 sub.logout(); } /* 基于权限的访问控制方式(过程同上) 配置文件：shiro_permision.ini ****************************** [users] zj2626=123456,role1,role2 py2626=123456,role1 ay2626=456789,role3 [roles] role1=user:select role2=user:add,user:update,user:delete ****************************** */ @Test public void testPermition() { Subject sub = ShiroUtils.login(&quot;shiro_config/shiro_permision&quot;, &quot;py2626&quot;, &quot;123456&quot;); System.out.println(&quot;用户是否有权限 user:select:&quot; + sub.isPermitted(&quot;user:select&quot;)); //true System.out.println(&quot;用户是否有权限 user:update:&quot; + sub.isPermitted(&quot;user:update&quot;)); //false boolean[] booleans = sub.isPermitted(&quot;user:add&quot;, &quot;user:select&quot;); System.out.println(booleans[0] + &quot;____&quot; + booleans[1]); System.out.println(sub.isPermittedAll(&quot;user:add&quot;, &quot;user:select&quot;)); //没有会抛出异常 sub.checkPermission(&quot;user:select&quot;); sub.checkPermissions(&quot;user:select&quot;, &quot;user:update&quot;); sub.logout(); } 3.集成web进行测试1.新建一个maven的web项目 web.xml 配置shiro的必须的配置: 监听器,过滤器 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;!--三个servlet配置 /login跳转到登陆页面 /home跳转到主页,即登陆成功页面 /admin用来测试角色和权限--&gt; &lt;servlet&gt; &lt;servlet-name&gt;loginServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.servlet.LoginServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;loginServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/login&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;homeServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.servlet.HomeServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;homeServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/home&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;adminServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.servlet.AdminServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;adminServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/admin&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--shiro监听--&gt; &lt;listener&gt; &lt;listener-class&gt;org.apache.shiro.web.env.EnvironmentLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--shiro过滤器 这里过滤所有的地址 并且指定权限配置文件(一般项目中权限的配置存放在数据库中)--&gt; &lt;filter&gt; &lt;filter-name&gt;ShiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.shiro.web.servlet.ShiroFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;config&lt;/param-name&gt; &lt;param-value&gt;classpath:shiro.ini&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;ShiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;/web-app&gt; pom.xml :所需依赖 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-web&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-servlet-api&lt;/artifactId&gt; &lt;version&gt;8.5.4&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-beanutils&lt;/groupId&gt; &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt; &lt;version&gt;1.9.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-collections&lt;/groupId&gt; &lt;artifactId&gt;commons-collections&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; shiro.ini: 权限配置文件,配置什么用户有什么角色,什么角色有什么权限 [main] authc.loginUrl=/login perms.unauthorizedUrl=/noAuth.jsp roles.unauthorizedUrl=/noAuth.jsp [users] zj2626=123456,admin ay2626=456789,student [roles] admin=user:*,student:select student:student:* [urls] /login=anon /home=authc /admin=roles[admin] 1.authc.loginUrl配置身份认证不通过(未登录时)跳转的地址…(loginUrl是authc的一个属性)2.roles.unauthorizeUrl配置角色认证不通过跳转的地址…(noAuth.jsp页面目前只有一行字)3.perms.unauthorizeUrl配置权限认证不通过跳转的地址4.[users]下配置用户身份信息以及用户角色5.[roles]下配置角色以及角色的控制权限6.[urls]下配置访问地址所需的权限, 其中值为”anon过滤器”表示地址不需要登录即可访问; “authc过滤器”表示地址登录才能访问7.值为 roles[admin] 表示 必须有角色为admin的用户才能范围8.值为 perms[“student:create”] 表示 必须有权限为”student:create”的用户才能范围9.多个过滤器用”,”隔开 而且相互为”且”的关系(必须同时满足才能访问)10.地址可以使用?表示匹配单个任意字符(eg: /home?=authc 表示可过滤 /home1; /homef…..)11.地址可以使用表示匹配任意个任意字符(eg: /home=authc 表示可过滤 /home123; /homeef…..)12.地址可以使用表示匹配多路径(eg: /home/=authc 表示可过滤 /home/abc; /home/aaa/bbb…..)2.编写sevlet代码 LoginServlet.java :身份验证地址 package com.servlet; import org.apache.shiro.SecurityUtils; import org.apache.shiro.authc.UsernamePasswordToken; import org.apache.shiro.subject.Subject; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * Created by zj on 2017/4/10. */ public class LoginServlet extends HttpServlet { /** * 跳转登录界面 * * @param req * @param resp * @throws ServletException * @throws IOException */ @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(&quot;user no login&quot;); resp.sendRedirect(&quot;login.jsp&quot;); } /** * 进行登录 * * @param req * @param resp * @throws ServletException * @throws IOException */ @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(&quot;登录&quot;); String userName = req.getParameter(&quot;userName&quot;); String password = req.getParameter(&quot;password&quot;); Subject subject = SecurityUtils.getSubject(); //创建token令牌, 用户/密码 UsernamePasswordToken token = new UsernamePasswordToken(userName, password); try { //身份认证 登录 subject.login(token); System.out.println(&quot;登录成功&quot;); resp.sendRedirect(&quot;success.jsp&quot;); } catch (Exception e) { System.out.println(&quot;账号密码不对&quot;); e.printStackTrace(); resp.sendRedirect(&quot;login.jsp&quot;); } } } //****************************************************************** login.jsp &lt;%@ page language=&quot;java&quot; pageEncoding=&quot;UTF-8&quot; %&gt; &lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot; %&gt; &lt;!DOCTYPE HTML&gt; &lt;html&gt; &lt;body&gt; &lt;h2&gt;Hello World&lt;/h2&gt; 登录: &lt;form action=&quot;/login&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;text&quot; value=&quot;&quot; name=&quot;userName&quot;&gt; &lt;input type=&quot;password&quot; value=&quot;&quot; name=&quot;password&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;登录&quot;&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; HomeServlet.java :登录成功以及退出登录地址 package com.servlet; import org.apache.shiro.SecurityUtils; import org.apache.shiro.subject.Subject; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * Created by zj on 2017/4/10. */ public class HomeServlet extends HttpServlet { /** * 进入主页(登陆成功界面) * * @param req * @param resp * @throws ServletException * @throws IOException */ @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(&quot;主页 get&quot;); req.getRequestDispatcher(&quot;success.jsp&quot;).forward(req, resp); } /** * 用来退出登陆 * * @param req * @param resp * @throws ServletException * @throws IOException */ @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(&quot;主页 post&quot;); System.out.println(&quot;login out&quot;); //退出登录 Subject subject = SecurityUtils.getSubject(); subject.logout(); resp.sendRedirect(&quot;login.jsp&quot;); } } //****************************************************************** success.jsp &lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt; &lt;html&gt; &lt;body&gt; &lt;h2&gt;Hello World!&lt;/h2&gt; 成功!!! &lt;form action=&quot;/home&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;退出登陆&quot;&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; AdminServlet.java package com.servlet; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * Created by zj on 2017/4/10. */ public class AdminServlet extends HttpServlet { protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { System.out.println(&quot;ADMIN GET&quot;); } protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { System.out.println(&quot;ADMIN POST&quot;); } } 3.启动项目测试身份认证 不登录情况下输入地址 http://localhost:8080/home 跳转到 /login地址转向的jsp页面 输入正确的用户名(ay2626)密码 点击登录 成功; 再次输入地址 http://localhost:8080/home 跳转到成功的jsp 点击退出登录 成功; 再次输入地址 http://localhost:8080/home 跳转到 /login地址转向的jsp页面 测试角色认证 登录 :进行其他认证前先进行身份认证 使用ay2626用户登录(其角色只有student) 登录成功 跳转到success.jsp 输入地址http://localhost:8080/admin 跳转到 http://localhost:8080/noAuth.jsp 表示没有权限访问此地址 退出登录 用zj2626再次登录测试 登录成功 再次输入http://localhost:8080/admin 控制台打印”ADMIN POST” 表示访问成功 测试权限认证 可把配置文件中 /admin的过滤器改为 /admin=perms[“student:create”] 进行测试 测试发现 有权限的ay2626用户可以访问而没有权限的zj2626不能访问 自定义Realm 实际开发中用户权限的配置要存放在数据库,so需要使用自定义realm来读取数据库中权限配置然后为用户赋予权限 测试开发步骤 1.添加数据库依赖 &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.39&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; 2.设计构建测试的数据库表:有三个表:分别存储用户,角色,权限 并其他两个都与角色关联, 然后存入部分数据 ,再根据三个表建立对应实体(简单实体) 3.添加数据库操作类(写的并不完善 仅测试使用) package com.servlet; import java.sql.*; /** * Created by zj on 2017/4/11. */ public class DBUtil { //获取数据库连接 private static Connection getConnection() { try { Class.forName(&quot;com.mysql.jdbc.Driver&quot;); Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://127.0.0.1:3306/test&quot;, &quot;root&quot;, &quot;fangshuoit&quot;); return connection; } catch (ClassNotFoundException | SQLException e) { e.printStackTrace(); } return null; } /** * 通过用户名获取用户信息 * * @param name * @return * @throws SQLException */ public static User getByUserName(String name) throws SQLException { String sql = &quot;select * from ay_user where loginName = ?&quot;; PreparedStatement preparedStatement = getConnection().prepareStatement(sql); preparedStatement.setString(1, name); ResultSet resultSet = preparedStatement.executeQuery(); if (resultSet.next()) { return new User(resultSet.getInt(&quot;id&quot;), resultSet.getString(&quot;loginName&quot;), resultSet.getString(&quot;password&quot;)); } return null; } /** * 通过用户名获取用户角色 * * @param name * @return * @throws SQLException */ public static Role getRolesByUserName(String name) throws SQLException { String sql = &quot;select roleId from ay_user where loginName = ?&quot;; PreparedStatement preparedStatement = getConnection().prepareStatement(sql); preparedStatement.setString(1, name); ResultSet resultSet = preparedStatement.executeQuery(); if (resultSet.next()) { Integer id = resultSet.getInt(&quot;roleId&quot;); sql = &quot;select * from ay_role where id = ?&quot;; preparedStatement = getConnection().prepareStatement(sql); preparedStatement.setInt(1, id); resultSet = preparedStatement.executeQuery(); if (resultSet.next()) { return new Role(resultSet.getInt(&quot;id&quot;), resultSet.getString(&quot;name&quot;)); } } return null; } /** * 通过角色id获取角色权限 * * @param roleId * @return * @throws SQLException */ public static Perms getPermsByRole(Integer roleId) throws SQLException { String sql = &quot;select * from ay_perms where roleId = ?&quot;; PreparedStatement preparedStatement = getConnection().prepareStatement(sql); preparedStatement.setInt(1, roleId); ResultSet resultSet = preparedStatement.executeQuery(); if (resultSet.next()) { return new Perms(resultSet.getInt(&quot;id&quot;), resultSet.getString(&quot;name&quot;), resultSet.getInt(&quot;roleId&quot;)); } return null; } } 3.编写自定义的Realm类 需要AuthorizingRealm类并实现两个方法; 第一个是用来身份验证,第二是用来角色权限验证 public class MyRealm extends AuthorizingRealm { /** * 验证当前登录的用户(身份认证), 不再需要在配置文件中配置用户的信息和其角色信息 * * @param token 封装有用户的信息 * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { String userName = (String) token.getPrincipal(); System.out.println(&quot;要登录的用户 : &quot; + userName); try { User user = DBUtil.getByUserName(userName);//这里只是通过用户名验证并获取用户信息,实际开发中需要用户名以及加密的密码 if (user != null) { return new SimpleAuthenticationInfo(user.getLoginName(), user.getPassword(), &quot;XX&quot;);//返回登录信息 } else return null; } catch (SQLException e) { e.printStackTrace(); } return null; } /**( 身份验证(登录)以后 ) * 为当前用户授予角色和权限(根据登录的用户名,读取数据库中其角色和权限) * * @param principals 封装了身份信息 * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { String userName = (String) principals.getPrimaryPrincipal(); System.out.println(&quot;要权限的用户 : &quot; + userName); SimpleAuthorizationInfo authenticationInfo = new SimpleAuthorizationInfo(); try { Role role = DBUtil.getRolesByUserName(userName); if (null != role) { Set&lt;String&gt; set = new HashSet&lt;&gt;(); System.out.println(&quot;获得的角色: &quot;+ role.getName()); set.add(role.getName()); authenticationInfo.setRoles(set);//赋予角色 Perms perms = DBUtil.getPermsByRole(role.getId()); Set&lt;String&gt; set2 = new HashSet&lt;&gt;(); set2.add(perms.getName()); System.out.println(&quot;获得的权限: &quot;+ perms.getName()); authenticationInfo.setStringPermissions(set2);//赋予权限 return authenticationInfo; } } catch (SQLException e) { } return null; } } 4.修改配置文件shiro.ini ,引入自定义Realms,并去掉原来的 [users]和[roles]下的配置 [main] authc.loginUrl=/login perms.unauthorizedUrl=/noAuth.jsp roles.unauthorizedUrl=/noAuth.jsp myRealm=com.servlet.MyRealm securityManager.realms=$myRealm [urls] /login=anon /home=authc /admin=roles[admin] 1.myRealm指向自定义Realm的位置2.securityManager.realms指向自定义Realm的引用(表明使用自定义Realms进行安全认证),可以指向多个,用”,”隔开 5.启动项目测试 发现:使用zj2626登录可以访问 /admin地址;而ay2626登录不能访问(没有user角色);而且每次请求都会进行认证(控制台打印信息)","categories":[{"name":"框架相关","slug":"框架相关","permalink":"http://zj2626.github.io/categories/框架相关/"},{"name":"权限管理","slug":"框架相关/权限管理","permalink":"http://zj2626.github.io/categories/框架相关/权限管理/"}],"tags":[{"name":"Shiro","slug":"Shiro","permalink":"http://zj2626.github.io/tags/Shiro/"}]},{"title":"Hexo博客插件安装","slug":"20170315_test","date":"2020-01-15T05:50:39.605Z","updated":"2021-03-10T15:33:38.685Z","comments":true,"path":"2020/01/15/20170315_test/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170315_test/","excerpt":"","text":"Hexo添加网易云跟贴（已关闭）: https://www.levey.cn/2017/415.htmlHexo添加七牛插件,自动上传静态文件: https://github.com/gyk001/hexo-qiniu-syncHexo添加静态文件的CDN加速(可配置七牛): https://github.com/zqjimlove/hexo-cdnify主题介绍： https://www.haomwei.com/technology/maupassant-hexo.html1234567891011121314151617181920数学公式要启用数学公式支持，请在Hexo目录的_config.yml中添加： mathjax: true并在相应文章的front-matter中添加mathjax: true，例如： Test Math date: 2016-04-05 14:16:00 categories: math mathjax: true数学公式的默认定界符是$$...$$和\\\\[...\\\\]（对于块级公式），以及$...$和\\\\(...\\\\)（对于行内公式）。但是，如果你的文章内容中经常出现美元符号“$”, 或者说你想将“$”用作美元符号而非行内公式的定界符，请在Hexo目录的_config.yml中添加： mathjax2: true而不是mathjax: true。 相应地，在需要使用数学公式的文章的front-matter中也添加mathjax2: true。","categories":[],"tags":[{"name":"Hexo优化","slug":"Hexo优化","permalink":"http://zj2626.github.io/tags/Hexo优化/"}]},{"title":"使用iframe标签实现局部刷新","slug":"20170315_iframe","date":"2020-01-15T05:50:39.604Z","updated":"2018-01-13T02:29:22.151Z","comments":true,"path":"2020/01/15/20170315_iframe/","link":"","permalink":"http://zj2626.github.io/2020/01/15/20170315_iframe/","excerpt":"Iframe是一种嵌入网页的框架形式，Web页面可以通过更改嵌入的部分，达到部分内容刷新，通过本文和大家一起学习iframe实现局部刷新的几种方法汇总，对iframe局部刷新相关知识感兴趣的朋友一起学习吧Iframe是一种嵌入网页的框架形式，Web页面可以通过更改嵌入的部分，达到部分内容刷新。Iframe的用法与普通的标签元素DIV类似，可以指定在页面中嵌入的位置、颜色、界面布局等 一、iframe实现局部刷新方法一 &lt;script type=&quot;text/javascript&quot;&gt; $(function(){ $(&quot;#a1&quot;).click(function(){ var name= $(this).attr(&quot;name&quot;); $(&quot;#iframe&quot;).attr(&quot;src&quot;,name).ready(); }) $(&quot;#a2&quot;).click(function(){ var name= $(this).attr(&quot;name&quot;); $(&quot;#iframe&quot;).attr(&quot;src&quot;,name).ready(); }) }) &lt;/script&gt; &lt;a href=&quot;#&quot; id=&quot;a1&quot; name=&quot;a1.html&quot;&gt;1&lt;/a&gt; &lt;a href=&quot;#&quot; id=&quot;a2&quot; name=&quot;a2.html&quot;&gt;2&lt;/a&gt; &lt;iframe src=&quot;&quot; id=&quot;iframe&quot;&gt;&lt;/iframe&gt; 当点a1时在iframe里显示a1.html的内容，点a2时在iframe里显示a2.html的内容","text":"Iframe是一种嵌入网页的框架形式，Web页面可以通过更改嵌入的部分，达到部分内容刷新，通过本文和大家一起学习iframe实现局部刷新的几种方法汇总，对iframe局部刷新相关知识感兴趣的朋友一起学习吧Iframe是一种嵌入网页的框架形式，Web页面可以通过更改嵌入的部分，达到部分内容刷新。Iframe的用法与普通的标签元素DIV类似，可以指定在页面中嵌入的位置、颜色、界面布局等 一、iframe实现局部刷新方法一 &lt;script type=&quot;text/javascript&quot;&gt; $(function(){ $(&quot;#a1&quot;).click(function(){ var name= $(this).attr(&quot;name&quot;); $(&quot;#iframe&quot;).attr(&quot;src&quot;,name).ready(); }) $(&quot;#a2&quot;).click(function(){ var name= $(this).attr(&quot;name&quot;); $(&quot;#iframe&quot;).attr(&quot;src&quot;,name).ready(); }) }) &lt;/script&gt; &lt;a href=&quot;#&quot; id=&quot;a1&quot; name=&quot;a1.html&quot;&gt;1&lt;/a&gt; &lt;a href=&quot;#&quot; id=&quot;a2&quot; name=&quot;a2.html&quot;&gt;2&lt;/a&gt; &lt;iframe src=&quot;&quot; id=&quot;iframe&quot;&gt;&lt;/iframe&gt; 当点a1时在iframe里显示a1.html的内容，点a2时在iframe里显示a2.html的内容 二、iframe实现局部刷新的方法二 &lt;a href=&quot;a1.html&quot; id=&quot;a1&quot; name=&quot;a1.html&quot; target=&quot;i&quot;&gt;1&lt;/a&gt; &lt;a href=&quot;a2.html&quot; id=&quot;a2&quot; name=&quot;a2.html&quot; target=&quot;i&quot;&gt;2&lt;/a&gt; &lt;iframe src=&quot;&quot; id=&quot;iframe&quot; name=&quot;i&quot;&gt;&lt;/iframe&gt; 备注： 同样也有target属性，作用和一样 这个方式如果或提交到某个Action中再跳转到a1.html中效果一样，如果在Action中有req.set或session.set，最后在iframe中同样可以显示出来。 可以加入这些属性 去除iframe的默认样式 frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; allowtransparency=&quot;yes&quot; 三：iframe实现局部刷新的方法三: &lt;iframe src=&quot;1.htm&quot; name=&quot;ifrmname&quot; id=&quot;ifrmid&quot;&gt;&lt;/iframe&gt; 方案一:用iframe的name属性定位 &lt;input type=&quot;button&quot; name=&quot;Button&quot; value=&quot;Button&quot; onclick=&quot;document.frames(&apos;ifrmname&apos;).location.reload()&quot;&gt; 或 &lt;input type=&quot;button&quot; name=&quot;Button&quot; value=&quot;Button&quot; onclick=&quot;document.all.ifrmname.document.location.reload()&quot;&gt; 方案二:用iframe的id属性定位 &lt;input type=&quot;button&quot; name=&quot;Button&quot; value=&quot;Button&quot; onclick=&quot;ifrmid.window.location.reload()&quot;&gt; 方案三:当iframe的src为其它网站地址(跨域操作时) &lt;input type=&quot;button&quot; name=&quot;Button&quot; value=&quot;Button&quot; onclick=&quot;window.open(document.all.ifrmname.src,&apos;ifrmname&apos;,&apos;&apos;)&quot;&gt; 方案四:通过和替换iframe的src来实现局部刷新可以用document.getElementById(“iframname”).src=””来进行iframe得重定向；示例代码如下：test.html &lt;!DOCTYPE html&gt; &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt; &lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; function partRefresh() { document.getElementById(&quot;iframe1Id&quot;).src = &quot;a2.html&quot;; // 方法一: 通过和替换iframe的src来实现局部刷新 } &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;table border=&quot;1&quot; width=&quot;90%&quot; align=&quot;center&quot;&gt; &lt;tr style=&quot;background: #F0F0E4&quot;&gt;&lt;td&gt;方格1&lt;/td&gt;&lt;td&gt;方格2&lt;/td&gt; &lt;td&gt;方格3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;iframe src=&quot;a1.html&quot; id=&quot;iframe1Id&quot; name=&quot;iframe1Name&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt; &lt;/td&gt; &lt;td&gt; &lt;iframe src=&quot;a2.html&quot; id=&quot;iframe2Id&quot; name=&quot;iframe2Name&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt; &lt;/td&gt; &lt;td&gt; &lt;iframe src=&quot;a3.html&quot; id=&quot;iframe3Id&quot; name=&quot;iframe3Name&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;br&gt; &lt;br&gt; &lt;input type=&quot;button&quot; value=&quot;IFRAME局部刷新&quot; style=&quot;margin-left: 70px;&quot; onclick=&quot;partRefresh();&quot;&gt; &lt;/body&gt; &lt;/html&gt;","categories":[{"name":"框架相关","slug":"框架相关","permalink":"http://zj2626.github.io/categories/框架相关/"},{"name":"前端技术","slug":"框架相关/前端技术","permalink":"http://zj2626.github.io/categories/框架相关/前端技术/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"http://zj2626.github.io/tags/HTML/"},{"name":"iframe","slug":"iframe","permalink":"http://zj2626.github.io/tags/iframe/"}]},{"title":"maven安装与命令","slug":"201703101526_maven","date":"2020-01-15T05:50:39.603Z","updated":"2021-03-10T15:33:38.691Z","comments":true,"path":"2020/01/15/201703101526_maven/","link":"","permalink":"http://zj2626.github.io/2020/01/15/201703101526_maven/","excerpt":"下载安装1.下载 地址 : http://maven.apache.org/download.cgi 2.解压 3.配置环境变量: 1.添加 M2_HOME : 解压目录 2.修改 path : 添加maven的bin目录 3.测试 命令行窗口输入: mvn -v","text":"下载安装1.下载 地址 : http://maven.apache.org/download.cgi 2.解压 3.配置环境变量: 1.添加 M2_HOME : 解压目录 2.修改 path : 添加maven的bin目录 3.测试 命令行窗口输入: mvn -v 目录结构 12345678910- src : 源代码目录 -main: - java : java源码 - resources: 资源文件目录,配置文件 - webapp : 页面代码 jsp - WEB-INF - web.xml - test:- target 编译输出目录- pom.xml pom文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!--pom文件--&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; maven版本&lt;groupId&gt;org.living&lt;/groupId&gt; 组织名 一般写包名&lt;artifactId&gt;FSCLassCloud&lt;/artifactId&gt; 模块名 一般写项目名&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; 版本号 SNAPSHOT:快照仓库(快照) alpha(内测版) beta(公测版) release发布仓库(稳定版) GA(正式发布)&lt;packaging&gt;war&lt;/packaging&gt; 打包方式 默认jar ,还有war,zip,pom&lt;name&gt;AAA&lt;/name&gt; 项目描述名&lt;url&gt;http://maven.apache.org&lt;/url&gt; 项目地址&lt;description&gt;&lt;/description&gt; 项目描述&lt;dependencies&gt; 加入的依赖(jar包) groupId,artifactId,version三个属性组成依赖的坐标 &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.jdbc.version&#125;&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; 依赖范围 &lt;optional&gt;false&lt;/optional&gt; 设置依赖是否可选(继承) &lt;exclusions&gt; 排除依赖传递列表(里面写依赖的坐标) &lt;exclusion&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; 插件列表 &lt;plugin&gt; 加载的插件 &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;jdk.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;jdk.version&#125;&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;&lt;parent&gt;&lt;/parent&gt; 继承的父模块&lt;modules&gt; 聚合多个模块 &lt;module&gt;&lt;/module&gt;&lt;/modules&gt; 配置文件: maven目录/conf/settings.xml 里面包含了很多maven的仓库的配置,可以进行自定义 仓库: 本地仓库(电脑本地仓库地址) 远程仓库(远程服务器的仓库) 镜像仓库(国外仓库无法访问,国内创建的远程仓库) 123456789101112131415161718192021222324&lt;!--修改settings.xml文件:--&gt;1. &lt;localRepository&gt;E:/MAVEN-3.3.9-bin/repo&lt;/localRepository&gt; 修改本地仓库位置(默认在c盘)2. &lt;mirrors&gt; 修改远程仓库地址为镜像地址(如果中央仓库访问很慢就换把) &lt;mirror&gt; &lt;id&gt;UK&lt;/id&gt; &lt;name&gt;UK Central&lt;/name&gt; &lt;url&gt;http://uk.maven.org/maven2&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt; 3. &lt;profile&gt; 修改jdk版本支持 &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; 命令 mvn -v 查看maven版本信息 mvn compile 编译(第一次编译会下载插件和jar包) mvn test 运行测试 mvn package 打包 mvn clean 清理,删除编译后的文件–target目录 mvn install 安装jar包到本地仓库 mvn archetype:generate 自动构建maven目录 注: 手动下载的jar包安装到本地仓库方式 mvn install:install-file -Dfile=jar包的位置 -DgroupId=jar包项目的groupId -DartifactId=jar包项目的artifactId -Dversion=jar包项目的version -Dpackaging=jar 注:自动构建maven目录写法 mvn archetype:generate -DgroupId=组织名 -DartifactId=项目名 -Dversion=版本 -Dpackaging=包名 classpath 有三种 编译 测试 运行依赖的范围1.compile (默认) 编译测试运行都有效 2.test 只是在测试范围有效 3.provided 编译测试时候有效 运行时(jar)不会被加入进去 4.runtime 测试和运行时有效 5.system 编译测试有效 移植性差 与本地系统有关 6.import 导入的范围 只使用在dependencyManagement中 表示是从其他的pom中继承的依赖 面对依赖冲突的原则 1.短路优先 当依赖了同一个项目的不同版本 则哪个最近就解析哪个 2.路径相同则先声明先优先 先解析谁 聚合: 几个项目(或模块)放到一起运行 继承: 继承父类项目pom中的配置","categories":[{"name":"程序安装与配置","slug":"程序安装与配置","permalink":"http://zj2626.github.io/categories/程序安装与配置/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://zj2626.github.io/tags/Maven/"}]},{"title":"垃圾收集器与内存分配策略","slug":"201703101259_垃圾收集器与内存分配策略","date":"2020-01-15T05:50:39.600Z","updated":"2021-05-31T14:31:05.431Z","comments":true,"path":"2020/01/15/201703101259_垃圾收集器与内存分配策略/","link":"","permalink":"http://zj2626.github.io/2020/01/15/201703101259_垃圾收集器与内存分配策略/","excerpt":"1. 垃圾收集 (Garbage Collection,GC)Java内存 运行时区域的各个部分，其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随 线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个 栈帧中分配多少内存基本上是在类结构确定下来时就已知的（尽管在运行期会由JIT编译器 进行一些优化，但在本章基于概念模型的讨论中，大体上可以认为是编译期可知的），因此 这几个区域的内存分配和回收都具备确定性，在这几个区域内就不需要过多考虑回收的问 题，因为方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一 样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也 可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配 和回收都是动态的，垃圾收集器所关注的是这部分内存 2.判断对象是否存活算法1. 引用计数算法 给对象中添加一个引用计数器，每当有 一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1； 任何时刻计数器为0 的对象就是不可能再被使用的。 优点:实现简单，判定效率很高缺点:很难解决对象 之间相互循环引用的问题。2. 可达性分析算法 (在主流的商用程序语言（Java、C#...中实现) 这个算法的基本思 路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所 走过的路径称为引用链（Reference Chain）， 当一个对象到GC Roots没有任何引用链相连 （用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的 12345在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对","text":"1. 垃圾收集 (Garbage Collection,GC)Java内存 运行时区域的各个部分，其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随 线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个 栈帧中分配多少内存基本上是在类结构确定下来时就已知的（尽管在运行期会由JIT编译器 进行一些优化，但在本章基于概念模型的讨论中，大体上可以认为是编译期可知的），因此 这几个区域的内存分配和回收都具备确定性，在这几个区域内就不需要过多考虑回收的问 题，因为方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一 样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也 可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配 和回收都是动态的，垃圾收集器所关注的是这部分内存 2.判断对象是否存活算法1. 引用计数算法 给对象中添加一个引用计数器，每当有 一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1； 任何时刻计数器为0 的对象就是不可能再被使用的。 优点:实现简单，判定效率很高缺点:很难解决对象 之间相互循环引用的问题。2. 可达性分析算法 (在主流的商用程序语言（Java、C#...中实现) 这个算法的基本思 路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所 走过的路径称为引用链（Reference Chain）， 当一个对象到GC Roots没有任何引用链相连 （用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的 12345在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对 3.关于引用 传统定义:：如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块 内存代表着一个引用。 当前的扩充定义: 引用分为4种123451. 强引用: 通过new出来的, 只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象2. 软引用: 用来描述一些还有用但并非必需的对象 对于软引用关联着的对象，在系统将 要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回 收还没有足够的内存，才会抛出内存溢出异常。 在JDK 1.2之后，提供了SoftReference类来实 现软引用。 3. 弱引用: 用来描述非必需的对象 更弱","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"Java元数据与注解的实现原理","slug":"201703092044_annotation","date":"2020-01-15T05:50:39.599Z","updated":"2018-01-13T02:29:22.145Z","comments":true,"path":"2020/01/15/201703092044_annotation/","link":"","permalink":"http://zj2626.github.io/2020/01/15/201703092044_annotation/","excerpt":"知识来源: http://blog.csdn.net/vebasan/article/details/4794699http://www.cnblogs.com/liuyonglong/p/3567786.htmlhttp://www.oracle.com/technetwork/cn/topics/linux/hunter-meta-097643-zhs.htmlhttp://developer.51cto.com/art/200909/152828.htmhttp://blog.csdn.net/yerenyuan_pku/article/details/52583656http://www.cnblogs.com/lzq2016/p/5169475.html","text":"知识来源: http://blog.csdn.net/vebasan/article/details/4794699http://www.cnblogs.com/liuyonglong/p/3567786.htmlhttp://www.oracle.com/technetwork/cn/topics/linux/hunter-meta-097643-zhs.htmlhttp://developer.51cto.com/art/200909/152828.htmhttp://blog.csdn.net/yerenyuan_pku/article/details/52583656http://www.cnblogs.com/lzq2016/p/5169475.html J2SE 5.0 版本以后新特性 Annotation(注解)定义: 元数据(MetaData)是数据的数据。元数据是添加到程序元素如方法、字段、类和包上的额外信息。或者说是从信息资源中抽取出来的用于说明其特征、内容的结构化的数据&gt;例如：富士苹果有一个属性：它是红色的。假定有一个 FushiApple 类，可以使用 @Color 批注类型的一个批注来指定它的颜色。通过这么做，您就提供了关于苹果的元数据。 作用: 创建文档，跟踪代码中的依赖性，执行编译时检查，代码分析&gt;例如: spring等框架中可以大量运用注解来替代配置文件进行依赖注入(取代了复杂的XML配置文件) &gt; 所以说注解其实就是元数据,本质上也是接口,而且是继承了接口Annotation的接口 &gt;利用元数据来描述资源后，我们就可以用来做很多的事情。比如确定资源，为资源提供检索点，在不同系统之间进行数据交换。 &gt;比如:我们把所有的控制层都打注解@Controller,就表示此类为控制层,为springMVC提供定位,表明这是控制器,然后在springMVC配置文件中加入&lt;context:component-scan base-package=&quot;&quot;/&gt;用来识别就可以 ##元数据的实现 JDK5.0出来后，java语言中就有了四种类型（TYPE），即类(class)、枚举(enum)、接口(interface)和注解(@interface)，它们是处在同一级别的。java就是通过注解来表示元数据的。 java.lang.annotation.Annotation 本身是接口，而不是注解，当使用关键字@interface 定义一个注解时，该注解隐含的继承了java.lang.annotation.Annotation接口； 如果我们定义一个接口，并且让该接口继承自Annotation，并不能作为注解, 定义注解只能依靠@interface实现 JDK提供的基本注解 @SuppressWarnings 压制警告 参数: 1.deprecation ：过时的类或方法警告。 2.unchecked：执行了未检查的转换时警告。 3.fallthrough：当Switch程序块直接通往下一种情况而没有Break时的警告。 4.path：在类路径、源文件路径等中有不存在的路径时的警告。 5.serial：当在可序列化的类上缺少serialVersionUID定义时的警告。 6.finally：任何finally子句不能完成时的警告。 7.all：关于以上所有情况的警告。 @Deprecated 设置过时 @Override 表示复写 元注解(注解的注解) 用于修饰一个Annotation的定义 @Retention 设置注解的生命周期 RetentionPolicy.SOURCE java源文件 只在源代码级别保留,编译时就会被忽略 RetentionPolicy.CLASS class文件 编译器将把注解记录在class文件中，当运行Java程序时，JVM会忽略注解。这是默认值。 RetentionPolicy.RUNTIME 内存的字节码 编译器将把注解记录在class文件中。当运行Java程序时，JVM会保留注解，程序可以通过反射获取该注解 @Target 表示该注解可以用在什么地方 参数:value 类型:ElementType ElementType.METHOD,ElementType.TYPE,ElementType.FIELD,... 分别表示注解的不同的使用地方 @Document 将注解包含在javadoc中 指定被该元Annotation修饰的Annotation类将被javadoc工具提取成文档 @Inherited 被它修饰的Annotation将具有继承性 允许子类继承父类的注解 其子类将自动具有该注解 注解和XML配置文件对比XML配置文件与代码文件分离，不利于一致性维护，缺乏在运行时的反射机制。而Annotation与代码一起被编译器处理，并能够在运行时访问。 通常XML配置文件都很复杂而且冗长。Java注释则不同，它是代码的一部分，不需要额外的引用就可以指明配置信息。 XML配置文件是文本文件，没有显式的类型支持，需要到运行时刻才能发现隐藏的错误。而Annotation是类型安全的，它会被编译器检查。 XML文件可以表达复杂的关系，但是在注释中我们却很难表达复杂的或层次的结构。 XML配置文件是在代码之外被单独处理的，也就是说基于XML的配置信息不是硬编码的，可以部署的时候进行修改。而修改Annotation则需要进行重新编译， 不过我们可以利用AOP提供的机制为已有的代码添加Annotation。通过部署不同的AOP模块，就能使代码具有不同的Annotation，但比起直接修改XML显得复杂。 注释是简单易用的，并且对大多数应用来说已经足够了。而XML文件更复杂，但具有部署的灵活性，因而被用来处理与部署相关的决策。 注释与XML配置文件可以一起使用。由于注释只能保存相当少的配置信息，只有预先集成的框架组件（类似在框架组件中已经完成了大多数预备工作）可以广泛地把注释作为配置选项。 而XML配置文件作为一个可选的重载机制，可以用于改变注释的默认行为。 创建注解1.定义一个注解类 //@Retention(RetentionPolicy.RUNTIME) public @interface MyAnnotation { //公共的final静态属性 默认加上public static final 必须初始化 String user = &quot;root&quot;; String password = &quot;fangshuoit&quot;; //公共的抽象方法 默认加上public abstract 调用时必须初始化 //可以有默认返回值(返回值类型:8种基本类型，String、Class、枚举、注解及这些类型的数组) String driverClass() default &quot;com.mysql.jdbc.Driver&quot;; String jdbcUrl() default &quot;jdbc:mysql://localhost:3306/test&quot;; String password() default &quot;fangshuoit&quot;; int[] arrayAttr() default {3,4,4}; } 2.在另一个类或方法上加上此注解,并且添加一个测试方法测试有没有此注解 @MyAnnotation(jdbcUrl = &quot;jdbc:mysql://localhost:3306/test2&quot;) public class TestAnnotaion { private String name; @Test @MyAnnotation(arrayAttr={2,3,4}, jdbcUrl = &quot;jdbc:mysql://localhost:3306/test3&quot;) public void test() { } @SuppressWarnings(&quot;deprecation&quot;) public static void main(String[] args) { System.runFinalizersOnExit(true); if (TestAnnotaion.class.isAnnotationPresent(MyAnnotation.class)) { // 类上是否有注解，默认情况下返回false MyAnnotation annotation = TestAnnotaion.class.getAnnotation(MyAnnotation.class); System.out.println(annotation.jdbcUrl()); System.out.println(annotation.user); } System.out.println(&quot;运行结束&quot;); } } //上面并没有返回System.out.println(annotation.jdbcUrl())结果, 要设置生命周期,在注解类上加@Retention(RetentionPolicy.RUNTIME) 输出: jdbc:mysql://localhost:3306/test2 root 运行结束 //表示获取到TestAnnotaion类上的注解@MyAnnotation的信息 //可以认定@MyAnnotation(driverClass = &quot;&quot;, jdbcUrl = &quot;jdbc:mysql://localhost:3306/test2&quot;)是MyAnnotation类的实例对象 //这里是通过反射获得MyAnnotation对象 //其实@MyAnnotation()相当于new了一个对象 //如果数组属性中只有一个元素，这时候属性值部分可以省略大括号。 可以加上@Target({ElementType.METHOD,ElementType.TYPE}) 表示只能在方法和类上加此注解 枚举类型注解属性 在注解类中添加 MyEnum season() default MyEnum.Winter; 则被注解类可添加 @MyAnnotation(season = MyEnum.Autumn)","categories":[{"name":"java语言基础","slug":"java语言基础","permalink":"http://zj2626.github.io/categories/java语言基础/"}],"tags":[{"name":"注解","slug":"注解","permalink":"http://zj2626.github.io/tags/注解/"},{"name":"元数据","slug":"元数据","permalink":"http://zj2626.github.io/tags/元数据/"}]},{"title":"对象在HotSpot虚拟机中","slug":"201703092017_对象在HotSpot虚拟机中","date":"2020-01-15T05:50:39.597Z","updated":"2021-03-10T15:33:38.669Z","comments":true,"path":"2020/01/15/201703092017_对象在HotSpot虚拟机中/","link":"","permalink":"http://zj2626.github.io/2020/01/15/201703092017_对象在HotSpot虚拟机中/","excerpt":"对象的建立位置对象在HotSpot虚拟机内存中存储分为三个区域1.对象头(Hearder) 头中包含两部分信息:对象的运行时数据(官方叫Mark Word)以及类型指针; 2.实例数据(Instance Data) 3.对齐填充(Padding) 对象运行时数据有很多,但是对象头信息是与数据无关的额外信息,为了提高空间利用率,其数据结构不固定,会根据对象状态复用自身的存储空间类型指针是对象指向其类元数据的指针,虚拟机通过其确定对象是哪个类的实例(不是每个对象都有)如果是数组,对象头中还有一块区域存放数组长度(一般对象可根据类型获得) 实例数据是真正的对象的有效信息,这些信息的顺序受到虚拟机分配策略参数的影响默认分配策略: longs/doubles,ints,shorts/chars,bytes/booleans/oops(一般对象指针) 父类定义的变量在子类之前 相同宽度的字段总是被分配的一起","text":"对象的建立位置对象在HotSpot虚拟机内存中存储分为三个区域1.对象头(Hearder) 头中包含两部分信息:对象的运行时数据(官方叫Mark Word)以及类型指针; 2.实例数据(Instance Data) 3.对齐填充(Padding) 对象运行时数据有很多,但是对象头信息是与数据无关的额外信息,为了提高空间利用率,其数据结构不固定,会根据对象状态复用自身的存储空间类型指针是对象指向其类元数据的指针,虚拟机通过其确定对象是哪个类的实例(不是每个对象都有)如果是数组,对象头中还有一块区域存放数组长度(一般对象可根据类型获得) 实例数据是真正的对象的有效信息,这些信息的顺序受到虚拟机分配策略参数的影响默认分配策略: longs/doubles,ints,shorts/chars,bytes/booleans/oops(一般对象指针) 父类定义的变量在子类之前 相同宽度的字段总是被分配的一起 对象的访问(方式)1.句柄方式: 虚拟机在java堆中划分出一块叫句柄池,reference中存储对象的句柄地址,句柄中包含了对象实例数据和类型数据的地址信息 优点: 稳定,即使对象被移动,只改变句柄中的实例数据指针,reference不变 2.直接指针方式: reference中存储的就是对象的地址 优点:速度快,节省一次指针定位的开销(HotSpot使用) reference:存在栈中,用来操作堆中的具体对象,存储了对象的引用(句柄地址或直接地址)","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"Mybatis 高级结果映射 ResultMap Association Collection","slug":"20170619_Mybatis","date":"2017-06-18T16:00:00.000Z","updated":"2021-03-10T15:20:21.747Z","comments":true,"path":"2017/06/19/20170619_Mybatis/","link":"","permalink":"http://zj2626.github.io/2017/06/19/20170619_Mybatis/","excerpt":"转自 http://blog.csdn.net/ilovejava_2010/article/details/8180521 高级结果映射 MyBatis的创建基于这样一个思想：数据库并不是您想怎样就怎样的。虽然我们希望所有的数据库遵守第三范式或BCNF（修正的第三范式），但它们不是。如果有一个数据库能够完美映射到所有应用程序，也将是非常棒的，但也没有。结果集映射就是MyBatis为解决这些问题而提供的解决方案。例如，我们如何映射下面这条语句？","text":"转自 http://blog.csdn.net/ilovejava_2010/article/details/8180521 高级结果映射 MyBatis的创建基于这样一个思想：数据库并不是您想怎样就怎样的。虽然我们希望所有的数据库遵守第三范式或BCNF（修正的第三范式），但它们不是。如果有一个数据库能够完美映射到所有应用程序，也将是非常棒的，但也没有。结果集映射就是MyBatis为解决这些问题而提供的解决方案。例如，我们如何映射下面这条语句？ &lt;!-- Very Complex Statement --&gt; &lt;select id=&quot;selectBlogDetails&quot; parameterType=&quot;int&quot; resultMap=&quot;detailedBlogResultMap&quot;&gt; select B.id as blog_id, B.title as blog_title, B.author_id as blog_author_id, A.id as author_id, A.username as author_username, A.password as author_password, A.email as author_email, A.bio as author_bio, A.favourite_section as author_favourite_section, P.id as post_id, P.blog_id as post_blog_id, P.author_id as post_author_id, P.created_on as post_created_on, P.section as post_section, P.subject as post_subject, P.draft as draft, P.body as post_body, C.id as comment_id, C.post_id as comment_post_id, C.name as comment_name, C.comment as comment_text, T.id as tag_id, T.name as tag_name from Blog B left outer join Author A on B.author_id = A.id left outer join Post P on B.id = P.blog_id left outer join Comment C on P.id = C.post_id left outer join Post_Tag PT on PT.post_id = P.id left outer join Tag T on PT.tag_id = T.id where B.id = #{id} &lt;/select&gt; &lt;wbr&gt; 您可能想要把它映射到一个智能的对象模型，包括由一个作者写的一个博客，有许多文章（Post，帖子），每个文章由0个或者多个评论和标签。下面是一个复杂ResultMap 的完整例子（假定作者、博客、文章、评论和标签都是别名）。仔细看看这个例子，但是不用太担心，我们会一步步地来分析，一眼看上去可能让人沮丧，但是实际上非常简单的 &lt;!-- Very Complex Result Map --&gt; &lt;resultMap id=&quot;detailedBlogResultMap&quot; type=&quot;Blog&quot;&gt; &lt;constructor&gt; &lt;idArg column=&quot;blog_id&quot; javaType=&quot;int&quot;/&gt; &lt;/constructor&gt; &lt;result property=&quot;title&quot; column=&quot;blog_title&quot;/&gt; &lt;association property=&quot;author&quot; column=&quot;blog_author_id&quot; javaType=&quot; Author&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;author_id&quot;/&gt; &lt;result property=&quot;username&quot; column=&quot;author_username&quot;/&gt; &lt;result property=&quot;password&quot; column=&quot;author_password&quot;/&gt; &lt;result property=&quot;email&quot; column=&quot;author_email&quot;/&gt; &lt;result property=&quot;bio&quot; column=&quot;author_bio&quot;/&gt; &lt;result property=&quot;favouriteSection&quot; column=&quot;author_favourite_section&quot;/&gt; &lt;/association&gt; &lt;collection property=&quot;posts&quot; ofType=&quot;Post&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;post_id&quot;/&gt; &lt;result property=&quot;subject&quot; column=&quot;post_subject&quot;/&gt; &lt;association property=&quot;author&quot; column=&quot;post_author_id&quot; javaType=&quot;Author&quot;/&gt; &lt;collection property=&quot;comments&quot; column=&quot;post_id&quot; ofType=&quot; Comment&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;comment_id&quot;/&gt; &lt;/collection&gt; &lt;collection property=&quot;tags&quot; column=&quot;post_id&quot; ofType=&quot; Tag&quot; &gt; &lt;id property=&quot;id&quot; column=&quot;tag_id&quot;/&gt; &lt;/collection&gt; &lt;discriminator javaType=&quot;int&quot; column=&quot;draft&quot;&gt; &lt;case value=&quot;1&quot; resultType=&quot;DraftPost&quot;/&gt; &lt;/discriminator&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;wbr&gt; 这个resultMap 的元素的子元素比较多，讨论起来比较宽泛。下面我们从概念上概览一下这个resultMap的元素。 resultMap constructor–实例化的时候通过构造器将结果集注入到类中 oidArg– ID 参数; 将结果集标记为ID，以方便全局调用 oarg–注入构造器的结果集 id–结果集ID，将结果集标记为ID，以方便全局调用 result–注入一个字段或者javabean属性的结果 association–复杂类型联合;许多查询结果合成这个类型 嵌套结果映射– associations能引用自身,或者从其它地方引用 collection–复杂类型集合 嵌套结果映射– collections能引用自身,或者从其它地方引用 discriminator–使用一个结果值以决定使用哪个resultMap ocase–基于不同值的结果映射 §嵌套结果映射–case也能引用它自身, 所以也能包含这些同样的元素。它也可以从外部引用resultMap 最佳实践:逐步地生成resultMap，单元测试对此非常有帮助。如果您尝试一下子就生成像上面这样巨大的resultMap，可能会出错，并且工作起来非常吃力。从简单地开始，再一步步地扩展，并且进行单元测试。使用框架开发有一个缺点，它们有时像是一个黑合。为了确保达到您所预想的行为，最好的方式就是进行单元测试。这对提交bugs 也非常有用。 下一节，我们一步步地查看这些细节。 id, result元素&lt;id property=&quot;id&quot; column=&quot;post_id&quot;/&gt; &lt;result property=&quot;subject&quot; column=&quot;post_subject&quot;/&gt; 这是最基本的结果集映射。id 和result 将列映射到属性或简单的数据类型字段(String, int, double, Date等)。这两者唯一不同的是，在比较对象实例时id 作为结果集的标识属性。这有助于提高总体性能，特别是应用缓存和嵌套结果映射的时候。 Id、result属性如下： Attribute Description property 映射数据库列的字段或属性。如果JavaBean 的属性与给定的名称匹配，就会使用匹配的名字。否则，MyBatis 将搜索给定名称的字段。两种情况下您都可以使用逗点的属性形式。比如，您可以映射到“username”，也可以映射到“address.street.number”。 column 数据库的列名或者列标签别名。与传递给resultSet.getString(columnName)的参数名称相同。 javaType 完整Java类名或别名(参考上面的内置别名列表)。如果映射到一个JavaBean，那MyBatis 通常会自行检测到。然而，如果映射到一个HashMap，那您应该明确指定javaType 来确保所需行为 jdbcType 这张表下面支持的JDBC类型列表列出的JDBC类型。这个属性只在insert，update 或delete 的时候针对允许空的列有用。JDBC 需要这项，但MyBatis 不需要。如果您直接编写JDBC代码，在允许为空值的情况下需要指定这个类型。 typeHandler 我们已经在文档中讨论过默认类型处理器。使用这个属性可以重写默认类型处理器。它的值可以是一个TypeHandler实现的完整类名，也可以是一个类型别名。 支持的JDBC类型 MyBatis支持如下的JDBC类型： Constructor元素 &lt;constructor&gt; &lt;idArg column=&quot;id&quot; javaType=&quot;int&quot;/&gt; &lt;arg column=”username” javaType=”String”/&gt; &lt;/constructor&gt; 当属性与DTO，或者与您自己的域模型一起工作的时候，许多场合要用到不变类。通常，包含引用，或者查找的数据很少或者数据不会改变的的表，适合映射到不变类中。构造器注入允许您在类实例化后给类设值，这不需要通过public方法。MyBatis同样也支持private属性和JavaBeans的私有属性达到这一点，但是一些用户可能更喜欢使用构造器注入。构造器元素可以做到这点。 考虑下面的构造器： public class User { //… public User(int id, String username) { //… } //… } 为了将结果注入构造器，MyBatis需要使用它的参数类型来标记构造器。Java没有办法通过参数名称来反射获得。因此当创建constructor 元素，确保参数是按顺序的并且指定了正确的类型。 &lt;constructor&gt; &lt;idArg column=&quot;id&quot; javaType=&quot;int&quot;/&gt; &lt;arg column=”username” javaType=”String”/&gt; &lt;/constructor&gt; 其它的属性与规则与id、result元素的一样。 Attribute Description column 数据库的列名或者列标签别名。与传递给resultSet.getString(columnName)的参数名称相同。 javaType 完整Java类名或别名(参考上面的内置别名列表)。如果映射到一个JavaBean，那MyBatis 通常会自行检测到。然而，如果映射到一个HashMap，那您应该明确指定javaType 来确保所需行为 jdbcType 这张表下面支持的JDBC类型列表列出的JDBC类型。这个属性只在insert，update 或delete 的时候针对允许空的列有用。JDBC 需要这项，但MyBatis 不需要。如果您直接编写JDBC代码，在允许为空值的情况下需要指定这个类型。 typeHandler 我们已经在文档中讨论过默认类型处理器。使用这个属性可以重写默认类型处理器。它的值可以是一个TypeHandler实现的完整类名，也可以是一个类型别名。 Association元素 &lt;association property=&quot;author&quot; column=&quot;blog_author_id&quot; javaType=&quot; Author&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;author_id&quot;/&gt; &lt;result property=&quot;username&quot; column=&quot;author_username&quot;/&gt; &lt;/association&gt; Association元素处理“has-one”（一对一）这种类型关系。比如在我们的例子中，一个Blog有一个Author。联合映射与其它的结果集映射工作方式差不多，指定property、column、javaType（通常MyBatis会自动识别）、jdbcType（如果需要）、typeHandler。 不同的地方是您需要告诉MyBatis 如何加载一个联合查询。MyBatis使用两种方式来加载： Nested Select:通过执行另一个返回预期复杂类型的映射SQL语句（即引用外部定义好的SQL语句块）。 Nested Results:通过嵌套结果映射（nested result mappings）来处理联接结果集（joined results）的重复子集。 首先，让我们检查一下元素属性。正如您看到的，它不同于普通只有select和resultMap属性的结果映射。 Attribute Description property 映射数据库列的字段或属性。如果JavaBean 的属性与给定的名称匹配，就会使用匹配的名字。否则，MyBatis 将搜索给定名称的字段。两种情况下您都可以使用逗点的属性形式。比如，您可以映射到“username”，也可以映射到“address.street.number”。 column 数据库的列名或者列标签别名。与传递给resultSet.getString(columnName)的参数名称相同。 javaType 完整Java类名或别名(参考上面的内置别名列表)。如果映射到一个JavaBean，那MyBatis 通常会自行检测到。然而，如果映射到一个HashMap，那您应该明确指定javaType 来确保所需行为 jdbcType 这张表下面支持的JDBC类型列表列出的JDBC类型。这个属性只在insert，update 或delete 的时候针对允许空的列有用。 JDBC 需要这项，但MyBatis 不需要。 如果您直接编写JDBC代码，在允许为空值的情况下需要指定这个类型。 typeHandler 我们已经在文档中讨论过默认类型处理器。使用这个属性可以重写默认类型处理器。它的值可以是一个TypeHandler实现的完整类名，也可以是一个类型别名。 select 联合嵌套选择（Nested Select for Association） 通过这个属性，通过ID引用另一个加载复杂类型的映射语句。从指定列属性中返回的值，将作为参数设置给目标select 语句。表格下方将有一个例子。注意：在处理组合键时，您可以使用column=”{prop1=col1,prop2=col2}”这样的语法，设置多个列名传入到嵌套语句。这就会把prop1和prop2设置到目标嵌套语句的参数对象中。 例如: &lt;resultMap id=”blogResult” type=”Blog”&gt; &lt;association property=&quot;author&quot; column=&quot;blog_author_id&quot; javaType=&quot;Author&quot; select=”selectAuthor”/&gt; &lt;/resultMap&gt; &lt;select id=”selectBlog” parameterType=”int” resultMap=”blogResult”&gt; SELECT * FROM BLOG WHERE ID = #{id} &lt;/select&gt; &lt;select id=”selectAuthor” parameterType=”int” resultType=&quot;Author&quot;&gt; SELECT * FROM AUTHOR WHERE ID = #{id} &lt;/select&gt; &lt;wbr&gt; 我们使用两个select语句：一个用来加载Blog，另一个用来加载Author。Blog的resultMap 描述了使用“selectAuthor”语句来加载author的属性。如果列名和属性名称相匹配的话，所有匹配的属性都会自动加载。 译者注： 上面的例子，首先执行&lt;select id=“selectBlog”&gt;，执行结果存放到&lt;resultMap id=“blogResult”&gt;结果映射中。“blogResult”是一个Blog类型，从&lt;select id=“selectBlog”&gt;查出的数据都会自动赋值给”blogResult”的与列名匹配的属性，这时blog_id，title等就被赋值了。同时“blogResult”还有一个关联属性&quot;Author&quot;，执行嵌套查询select=”selectAuthor”后，Author对象的属性id，username，password，email，bio也被赋于数据库匹配的值。 Blog { blog_id; title; Author author { id; username; password; email; bio; } } 虽然这个方法简单，但是对于大数据集或列表查询，就不尽如人意了。这个问题被称为“N+1 选择问题”（N+1 Selects Problem）。概括地说，N+1选择问题是这样产生的： 您执行单条SQL语句去获取一个列表的记录( “+1”)。 对列表中的每一条记录，再执行一个联合select 语句来加载每条记录更加详细的信息(“N”)。这个问题会导致成千上万的SQL语句的执行，因此并非总是可取的。 上面的例子，MyBatis可以使用延迟加载这些查询，因此这些查询立马可节省开销。然而，如果您加载一个列表后立即迭代访问嵌套的数据，这将会调用所有的延迟加载，因此性能会变得非常糟糕。鉴于此，这有另外一种方式。联合嵌套结果集（Nested Results for Association) resultMap一个可以映射联合嵌套结果集到一个适合的对象视图上的ResultMap 。这是一个替代的方式去调用另一个select 语句。它允许您去联合多个表到一个结果集里。这样的结果集可能包括冗余的、重复的需要分解和正确映射到一个嵌套对象视图的数据组。简言之，MyBatis 让您把结果映射‘链接’到一起，用来处理嵌套结果。举个例子会更好理解，例子在表格下方。 您已经在上面看到了一个非常复杂的嵌套联合的例子，接下的演示的例子会更简单一些。我们把Blog和Author表联接起来查询，而不是执行分开的查询语句： &lt;select id=&quot;selectBlog&quot; parameterType=&quot;int&quot; resultMap=&quot;blogResult&quot;&gt; select B.id as blog_id, B.title as blog_title, B.author_id as blog_author_id, A.id as author_id, A.username as author_username, A.password as author_password, A.email as author_email, A.bio as author_bio from Blog B left outer join Author A on B.author_id = A.id where B.id = #{id} &lt;/select&gt; &lt;wbr&gt; 注意到这个连接（join），要确保所有的别名都是唯一且无歧义的。这使映射容易多了，现在我们来映射结果集： &lt;resultMap id=&quot;blogResult&quot; type=&quot;Blog&quot;&gt; &lt;id property=”blog_id” column=&quot;id&quot; /&gt; &lt;result property=&quot;title&quot; column=&quot;blog_title&quot;/&gt; &lt;association property=&quot;author&quot; column=&quot;blog_author_id&quot; javaType=&quot;Author&quot; resultMap=”authorResult”/&gt; &lt;/resultMap&gt; &lt;resultMap id=&quot;authorResult&quot; type=&quot;Author&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;author_id&quot;/&gt; &lt;result property=&quot;username&quot; column=&quot;author_username&quot;/&gt; &lt;result property=&quot;password&quot; column=&quot;author_password&quot;/&gt; &lt;result property=&quot;email&quot; column=&quot;author_email&quot;/&gt; &lt;result property=&quot;bio&quot; column=&quot;author_bio&quot;/&gt; &lt;/resultMap&gt; &lt;wbr&gt; 在上面的例子中，您会看到Blog的作者（“author”）联合一个“authorResult”结果映射来加载Author实例。重点提示 :id元素在嵌套结果映射中扮演了非常重要的角色，您应该总是指定一个或多个属性来唯一标识这个结果集。事实上，如果您没有那样做，MyBatis也会工作，但是会导致严重性能开销。选择尽量少的属性来唯一标识结果，而使用主键是最明显的选择（即使是复合主键）。上面的例子使用一个扩展的resultMap 元素来联合映射。这可使Author结果映射可重复使用。然后，如果您不需要重用它，您可以直接嵌套这个联合结果映射。下面例子就是使用这样的方式： &lt;resultMap id=&quot;blogResult&quot; type=&quot;Blog&quot;&gt; &lt;id property=”blog_id” column=&quot;id&quot; /&gt; &lt;result property=&quot;title&quot; column=&quot;blog_title&quot;/&gt; &lt;association property=&quot;author&quot; column=&quot;blog_author_id&quot; javaType=&quot;Author&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;author_id&quot;/&gt; &lt;result property=&quot;username&quot; column=&quot;author_username&quot;/&gt; &lt;result property=&quot;password&quot; column=&quot;author_password&quot;/&gt; &lt;result property=&quot;email&quot; column=&quot;author_email&quot;/&gt; &lt;result property=&quot;bio&quot; column=&quot;author_bio&quot;/&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;wbr&gt; 在上面的例子中您已经看到如果处理“一对一”（“has one”）类型的联合查询。但是对于“一对多”（“has many”）的情况如果处理呢？这个问题在下一节讨论。 Collection元素&lt;collection property=&quot;posts&quot; ofType=&quot;domain.blog.Post&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;post_id&quot;/&gt; &lt;result property=&quot;subject&quot; column=&quot;post_subject&quot;/&gt; &lt;result property=&quot;body&quot; column=&quot;post_body&quot;/&gt; &lt;/collection&gt; &lt;wbr&gt; collection元素的作用差不多和association元素的作用一样。事实上，它们非常相似，以至于再对相似点进行描述会显得冗余，因此我们只关注它们的不同点。 继续我们上面的例子，一个Blog只有一个Author。但一个Blog有许多帖子（文章）。在Blog类中，会像下面这样定义相应属性： private List&lt;Post&gt; posts; 映射一个嵌套结果集到一个列表，我们使用collection元素。就像association 元素那样，我们使用嵌套查询，或者从连接中嵌套结果集。集合嵌套选择（Nested Select for Collection） 首先我们使用嵌套选择来加载Blog的文章。 &lt;resultMap id=”blogResult” type=”Blog”&gt; &lt;collection property=&quot;posts&quot; javaType=”ArrayList” column=&quot;blog_id&quot; ofType=&quot;Post&quot; select=”selectPostsForBlog”/&gt; &lt;/resultMap&gt; &lt;select id=”selectBlog” parameterType=”int” resultMap=”blogResult”&gt; SELECT * FROM BLOG WHERE ID = #{id} &lt;/select&gt; &lt;select id=”selectPostsForBlog” parameterType=”int” resultType=&quot;Author&quot;&gt; SELECT * FROM POST WHERE BLOG_ID = #{id} &lt;/select&gt; &lt;wbr&gt; 一看上去这有许多东西需要注意，但大部分看起与我们在association元素中学过的相似。首先，您会注意到我们使用了collection元素，然后会注意到一个新的属性“ofType”。这个元素是用来区别JavaBean属性（或者字段）类型和集合所包括的类型。因此您会读到下面这段代码。 &lt;collection property=&quot;posts&quot; javaType=”ArrayList” column=&quot;blog_id&quot; ofType=&quot;Post&quot; select=”selectPostsForBlog”/&gt; 理解为:“一个名为posts，类型为Post的ArrayList集合（A collection of posts in an ArrayList of type Post）” 。 javaType属性不是必须的，通常MyBatis 会自动识别，所以您通常可以简略地写成： &lt;collection property=&quot;posts&quot; column=&quot;blog_id&quot; ofType=&quot;Post&quot; select=”selectPostsForBlog”/&gt; 集合的嵌套结果集（Nested Results for Collection）这时候，您可能已经猜出嵌套结果集是怎样工作的了，因为它与association非常相似，只不过多了一个属性“ofType”。 让我们看下这个SQL： &lt;select id=&quot;selectBlog&quot; parameterType=&quot;int&quot; resultMap=&quot;blogResult&quot;&gt; select B.id as blog_id, B.title as blog_title, B.author_id as blog_author_id, P.id as post_id, P.subject as post_subject, P.body as post_body, from Blog B left outer join Post P on B.id = P.blog_id where B.id = #{id} &lt;/select&gt; &lt;wbr&gt; 同样，我们把Blog和Post两张表连接在一起，并且也保证列标签名在映射的时候是唯一且无歧义的。现在将Blog和Post的集合映射在一起是多么简单： &lt;resultMap id=&quot;blogResult&quot; type=&quot;Blog&quot;&gt; &lt;id property=”id” column=&quot;blog_id&quot; /&gt; &lt;result property=&quot;title&quot; column=&quot;blog_title&quot;/&gt; &lt;collection property=&quot;posts&quot; ofType=&quot;Post&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;post_id&quot;/&gt; &lt;result property=&quot;subject&quot; column=&quot;post_subject&quot;/&gt; &lt;result property=&quot;body&quot; column=&quot;post_body&quot;/&gt; &lt;/collection&gt; &lt;/resultMap&gt; 再次强调一下，id 元素是非常重要的。如果您忘了或者不知道id 元素的作用，请先读一下上面association 一节。 如果希望结果映射有更好的可重用性，您可以使用下面的方式： &lt;resultMap id=&quot;blogResult&quot; type=&quot;Blog&quot;&gt; &lt;id property=”id” column=&quot;blog_id&quot; /&gt; &lt;result property=&quot;title&quot; column=&quot;blog_title&quot;/&gt; &lt;collection property=&quot;posts&quot; ofType=&quot;Post&quot; resultMap=”blogPostResult”/&gt; &lt;/resultMap&gt; &lt;resultMap id=&quot;blogPostResult&quot; type=&quot;Post&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;post_id&quot;/&gt; &lt;result property=&quot;subject&quot; column=&quot;post_subject&quot;/&gt; &lt;result property=&quot;body&quot; column=&quot;post_body&quot;/&gt; &lt;/resultMap&gt; Note:在您的映射中没有深度、宽度、联合和集合数目的限制。但应该谨记，在进行映射的时候也要考虑性能的因素。应用程序的单元测试和性能测试帮助您发现最好的方式可能要花很长时间。但幸运的是，MyBatis允许您以后可以修改您的想法，这时只需要修改少量代码就行了。 关于高级联合和集合映射是一个比较深入的课题，文档只能帮您了解到这里，多做一些实践，一切将很快变得容易理解。 Discriminator元素&lt;discriminator javaType=&quot;int&quot; column=&quot;draft&quot;&gt; &lt;case value=&quot;1&quot; resultType=&quot;DraftPost&quot;/&gt; &lt;/discriminator&gt; 有时候一条数据库查询可能会返回包括各种不同的数据类型的结果集。Discriminator（识别器）元素被设计来处理这种情况，以及其它像类继承层次情况。识别器非常好理解，它就像java里的switch语句。 Discriminator定义要指定column和javaType属性。列是MyBatis将要取出进行比较的值，javaType用来确定适当的测试是否正确运行（虽然String在大部分情况下都可以工作），例： &lt;resultMap id=&quot;vehicleResult&quot; type=&quot;Vehicle&quot;&gt; &lt;id property=”id” column=&quot;id&quot; /&gt; &lt;result property=&quot;vin&quot; column=&quot;vin&quot;/&gt; &lt;result property=&quot;year&quot; column=&quot;year&quot;/&gt; &lt;result property=&quot;make&quot; column=&quot;make&quot;/&gt; &lt;result property=&quot;model&quot; column=&quot;model&quot;/&gt; &lt;result property=&quot;color&quot; column=&quot;color&quot;/&gt; &lt;discriminator javaType=&quot;int&quot; column=&quot;vehicle_type&quot;&gt; &lt;case value=&quot;1&quot; resultMap=&quot;carResult&quot;/&gt; &lt;case value=&quot;2&quot; resultMap=&quot;truckResult&quot;/&gt; &lt;case value=&quot;3&quot; resultMap=&quot;vanResult&quot;/&gt; &lt;case value=&quot;4&quot; resultMap=&quot;suvResult&quot;/&gt; &lt;/discriminator&gt; &lt;/resultMap&gt; &lt;wbr&gt; 在这个例子中，MyBatis将会从结果集中取出每条记录，然后比较它的vehicle type的值。如果匹配任何discriminator中的case，它将使用由case指定的resultMap。这是排它性的，换句话说，其它的case的resultMap将会被忽略（除非使用我们下面说到的extended）。如果没有匹配到任何case，MyBatis只是简单的使用定义在discriminator块外面的resultMap。所以，如果carResult像下面这样定义： &lt;resultMap id=&quot;carResult&quot; type=&quot;Car&quot;&gt; &lt;result property=”doorCount” column=&quot;door_count&quot; /&gt; &lt;/resultMap&gt; 那么，只有doorCount属性会被加载。这样做是为了与识别器cases群组完全独立开来，哪怕它与上一层的resultMap 一点关系都没有。在刚才的例子里我们当然知道cars和vehicles的关系，a Car is-a Vehicle。因此，我们也要把其它属性加载进来。我们要稍稍改动一下resultMap： &lt;resultMap id=&quot;carResult&quot; type=&quot;Car&quot;extends=”vehicleResult”&gt; &lt;result property=”doorCount” column=&quot;door_count&quot; /&gt; &lt;/resultMap&gt; 现在，vehicleResult和carResult的所有属性都会被加载。可能有人会认为这样扩展映射定义有一点单调了，所以还有一种可选的更加简单明了的映射风格语法。例如： &lt;resultMap id=&quot;vehicleResult&quot; type=&quot;Vehicle&quot;&gt; &lt;id property=”id” column=&quot;id&quot; /&gt; &lt;result property=&quot;vin&quot; column=&quot;vin&quot;/&gt; &lt;result property=&quot;year&quot; column=&quot;year&quot;/&gt; &lt;result property=&quot;make&quot; column=&quot;make&quot;/&gt; &lt;result property=&quot;model&quot; column=&quot;model&quot;/&gt; &lt;result property=&quot;color&quot; column=&quot;color&quot;/&gt; &lt;discriminator javaType=&quot;int&quot; column=&quot;vehicle_type&quot;&gt; &lt;case value=&quot;1&quot; resultType=&quot;carResult&quot;&gt; &lt;result property=”doorCount” column=&quot;door_count&quot; /&gt; &lt;/case&gt; &lt;case value=&quot;2&quot; resultType=&quot;truckResult&quot;&gt; &lt;result property=”boxSize” column=&quot;box_size&quot; /&gt; &lt;result property=”extendedCab” column=&quot;extended_cab&quot; /&gt; &lt;/case&gt; &lt;case value=&quot;3&quot; resultType=&quot;vanResult&quot;&gt; &lt;result property=”powerSlidingDoor” column=&quot;power_sliding_door&quot; /&gt; &lt;/case&gt; &lt;case value=&quot;4&quot; resultType=&quot;suvResult&quot;&gt; &lt;result property=”allWheelDrive” column=&quot;all_wheel_drive&quot; /&gt; &lt;/case&gt; &lt;/discriminator&gt; &lt;/resultMap&gt; &lt;wbr&gt; 记住：对于这么多的结果映射，如果您不指定任何的结果集，那么MyBatis 会自动地将列名与属性相匹配。所以上面所举的例子比实际中需要的要详细。尽管如此，大部分数据库有点复杂，并且它并不是所有情况都是完全可以适用的。 Cache元素 MyBatis包含一个强大的、可配置、可定制的查询缓存机制。MyBatis 3 的缓存实现有了许多改进，使它更强大更容易配置。默认的情况，缓存是没有开启，除了会话缓存以外，它可以提高性能，且能解决循环依赖。开启二级缓存，您只需要在SQL映射文件中加入简单的一行： &lt;cache/&gt; 这句简单的语句作用如下： 所有映射文件里的select语句的结果都会被缓存。 所有映射文件里的insert、update和delete语句执行都会清空缓存。 缓存使用最近最少使用算法(LRU)来回收。 缓存不会被设定的时间所清空。 每个缓存可以存储1024 个列表或对象的引用（不管查询方法返回的是什么）。 缓存将作为“读/写”缓存，意味着检索的对象不是共享的且可以被调用者安全地修改，而不会被其它调用者或者线程干扰。 所有这些特性都可以通过cache元素进行修改。例如： &lt;cache eviction=&quot;FIFO&quot; flushInterval=&quot;60000&quot; size=&quot;512&quot; readOnly=&quot;true&quot;/&gt; 这种高级的配置创建一个每60秒刷新一次的FIFO 缓存，存储512个结果对象或列表的引用，并且返回的对象是只读的。因此在不用的线程里的调用者修改它们可能会引用冲突。 可用的回收算法如下： LRU–最近最少使用：移出最近最长时间内都没有被使用的对象。 FIFO–先进先出：移除最先进入缓存的对象。 SOFT–软引用: 基于垃圾回收机制和软引用规则来移除对象（空间内存不足时才进行回收）。 WEAK–弱引用:基于垃圾回收机制和弱引用规则（垃圾回收器扫描到时即进行回收）。 默认使用LRU。 flushInterval：设置任何正整数，代表一个以毫秒为单位的合理时间。默认是没有设置，因此没有刷新间隔时间被使用，在语句每次调用时才进行刷新。 Size：属性可以设置为一个正整数，您需要留意您要缓存对象的大小和环境中可用的内存空间。默认是1024。 readOnly：属性可以被设置为true 或false。只读缓存将对所有调用者返回同一个实例。因此这些对象都不能被修改，这可以极大的提高性能。可写的缓存将通过序列化来返回一个缓存对象的拷贝。这会比较慢，但是比较安全。所以默认值是false。 使用自定义缓存 除了上面已经定义好的缓存方式，您能够通过您自己的缓存实现来完全重写缓存行为，或者通过创建第三方缓存解决方案的适配器。 &lt;cache type=”com.domain.something.MyCustomCache”/&gt; 这个例子演示了如果自定义缓存实现。由type指定的类必须实现org.mybatis.cache.Cache接口。这个接口是MyBatis框架比较复杂的接口之一，先给个示例： public interface Cache { String getId(); int getSize(); void putObject(Object key, Object value); Object getObject(Object key); boolean hasKey(Object key); Object removeObject(Object key); void clear(); ReadWriteLock getReadWriteLock(); } 要配置您的缓存，简单地添加一个公共的JavaBeans 属性到您的缓存实现中，然后通过cache 元素设置属性进行传递，下面示例，将在您的缓存实现上调用一个setCacheFile(String file)方法。 &lt;cache type=”com.domain.something.MyCustomCache”&gt; &lt;property name=”cacheFile” value=”/tmp/my-custom-cache.tmp”/&gt; &lt;/cache&gt; 您可以使用所有简单的JavaBeans属性，MyBatis会自动进行转换。 需要牢记的是一个缓存配置和缓存实例都绑定到一个SQL Map 文件命名空间。因此，所有的这个相同命名空间的语句也都和这个缓存绑定。语句可以修改如何与这个缓存相匹配，或者使用两个简单的属性来完全排除它们自己。默认情况下，语句像下面这样来配置： &lt;select ... flushCache=”false” useCache=”true”/&gt; &lt;insert ... flushCache=”true”/&gt; &lt;update ... flushCache=”true”/&gt; &lt;delete ... flushCache=”true”/&gt; 因为有默认值，所以您不需要使用这种方式明确地配置这些语句。如果您想改变默认的动作，只需要设置flushCache和useCache 属性即可。举个例子来说，在许多的场合下您可能排除缓存中某些特定的select语句。或者您想用select语句清空缓存。同样的，您也可能有一些update 语句在执行的时候不需要清空缓存。 cache-ref元素回想上一节，我们仅仅只是讨论在某一个命名空间里使用或者刷新缓存。但有可能您想要在不同的命名空间里共享同一个缓存配置或者实例。在这种情况下，您就可以使用cache-ref 元素来引用另外一个缓存。 &lt;cache-ref namespace=”com.someone.application.data.SomeMapper”/&gt;","categories":[{"name":"框架相关","slug":"框架相关","permalink":"http://zj2626.github.io/categories/框架相关/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://zj2626.github.io/tags/Mybatis/"}]},{"title":"Mybatis入门学习","slug":"20170616_Mybatis","date":"2017-06-15T16:00:00.000Z","updated":"2021-03-10T13:50:15.236Z","comments":true,"path":"2017/06/16/20170616_Mybatis/","link":"","permalink":"http://zj2626.github.io/2017/06/16/20170616_Mybatis/","excerpt":"什么是 MyBatis ？ 官方文档: http://www.mybatis.org/mybatis-3/zh/index.html MyBatis 一个基于Java的持久层框架; 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将代理接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 与hibernate不同的是: mybatis是通过xml映射文件实现代理接口来实现操作数据库的功能","text":"什么是 MyBatis ？ 官方文档: http://www.mybatis.org/mybatis-3/zh/index.html MyBatis 一个基于Java的持久层框架; 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将代理接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 与hibernate不同的是: mybatis是通过xml映射文件实现代理接口来实现操作数据库的功能 基本的步骤:1. 引入dependency&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; 2. mybatis核心配置文件 #在resources目录下的 mybatis/conf.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt; &lt;configuration&gt; &lt;!--可以读取数据库配置文件 用EL表达式获取参数--&gt; &lt;!--&lt;properties resource=&quot;classpath:mybatis/db.properties&quot;/&gt;--&gt; &lt;!-- development : 开发模式 work : 工作模式 --&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/test?zeroDateTimeBehavior=convertToNull&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;fangshuoit&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--映射文件所在位置 不能使用通配符(和spring整合时候可以使用)--&gt; &lt;mappers&gt; &lt;mapper resource=&quot;com/mybatis/test1/pojo/MyUserMapper.xml&quot;/&gt; &lt;/mappers&gt; &lt;/configuration&gt; 如果需要(或者测试没日志)可以引入log4j的包和配置文件 方便测试3. 新建实体类–MyUser.java 对应数据库中表my_user//三个属性 private int id; private String name; private int age; 4. 新建Mapper映射文件–MyUserMapper.xml(要和实体放到一个目录下)&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;mapper namespace=&quot;com.mybatis.test1.pojo.MyUserMapper&quot;&gt; &lt;!-- 根据id查询得到一个user对象 其中sql语句中的表名,查询参数名,where语句中 键都是数据库中表的写法, 要传入的参数占位符是书体属性名 --&gt; &lt;select id=&quot;getUser&quot; parameterType=&quot;int&quot; resultType=&quot;com.mybatis.test1.pojo.MyUser&quot;&gt; SELECT * FROM my_user WHERE id = #{id} &lt;/select&gt; &lt;/mapper&gt; maven项目运行时找不到映射文件:Could not find resource;(原因是maven在构建的时候不会识别src下的配置文件,见生成的class目录)所以有两种方法解决 1.在resources下新建目录,目录结构和java下的一致(因为需要保证映射文件和实体在同一个目录下),到时候生成的.class就会和配置文件放到一起,就可以找到了 2.(推荐), 添加设置资源目录: 在pom的build下加入: &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; 5.可以测试啦: 添加测试类–MainTest.java private SqlSession util(){ //配置文件 String resource = &quot;mybatis/conf.xml&quot;; //加载配置mybatis文件 InputStream input = MainTest.class.getClassLoader().getResourceAsStream(resource); // Reader reader = Resources.getResourceAsReader(resource); //也可以使用这个加载配置 //构建sqlSession工厂 SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(input); //得到能执行映射文件中sql语句的sqlSession(等同于jdbc中的PreparedStatement) SqlSession session = sqlSessionFactory.openSession(true);//设置自动提交事务 return session; } @Test public void testSelect() { SqlSession session = util(); //映射sql的标识符字符串(映射文件全类名 + 映射节点id) String statement = &quot;com.mybatis.test1.pojo.MyUserMapper.getUser&quot;; //执行sql语句返回结果 MyUser user = session.selectOne(statement, 12);//两个参数 statement和占位符要填写的参数 System.out.println(user); } 6. 大功告成 ! 7. 其他操作 : CURD 增删改查实现方法, 1. 增加映射文件内容; &lt;!-- 插入一个用户 --&gt; &lt;insert id=&quot;addUser&quot; parameterType=&quot;com.mybatis.test1.pojo.MyUser&quot;&gt; INSERT INTO my_user (id, name, age) VALUES (#{id}, #{name}, #{age}) &lt;/insert&gt; &lt;!-- 根据id删除一个用户 --&gt; &lt;delete id=&quot;delUser&quot; parameterType=&quot;int&quot;&gt; DELETE FROM my_user WHERE id = #{id} &lt;/delete&gt; &lt;!-- 更新用户信息 --&gt; &lt;update id=&quot;editUser&quot; parameterType=&quot;com.mybatis.test1.pojo.MyUser&quot;&gt; UPDATE my_user SET name = #{name}, age = #{age} WHERE id = #{id} &lt;/update&gt; &lt;!-- 根据id查询得到一个user对象 --&gt; &lt;select id=&quot;getUser&quot; parameterType=&quot;int&quot; resultType=&quot;com.mybatis.test1.pojo.MyUser&quot;&gt; SELECT * FROM my_user WHERE id = #{id} &lt;/select&gt; &lt;select id=&quot;getAllUser&quot; resultType=&quot;com.mybatis.test1.pojo.MyUser&quot;&gt; SELECT * FROM my_user &lt;/select&gt; 2.调用sqlSession的各种方法(方法名基本上是个人都能看出来干嘛的,你就直接试); 比如 int result = session.delete(statement, 1); List&lt;MyUser&gt; users = session.selectList(statement); .... 8. 基于接口的写法: 基于接口有两种具体实现 1.基于注解:不需要自己写实现类,实现类自己”生成”; 2:基于xml文件,需要把xml文件和接口放在同一个目录下 基于注解1.新建一个代理接口–MyUserMapper.java public interface MyUserMapper { @Insert(&quot;INSERT INTO my_user (id, name, age) VALUES (#{id}, #{name}, #{age})&quot;) public int add(MyUser user); @Delete(&quot;DELETE FROM my_user WHERE id = #{id}&quot;) public int del(int id); @Update(&quot;UPDATE my_user SET name = #{name}, age = #{age} WHERE id = #{id}&quot;) public int edit(MyUser user); @Select(&quot;SELECT * FROM my_user WHERE id = #{id}&quot;) public MyUser find(int id); @Select(&quot;SELECT * FROM my_user&quot;) public List&lt;MyUser&gt; getAll(); } 2.”注册”到mybatis配置文件–在conf.xml中mappers节点下添加 &lt;mapper class=&quot;com.mybatis.test2.pojo.MyUserMapper&quot;/&gt; 3.测试 String resource = &quot;mybatis/conf.xml&quot;; InputStream input = MainTest.class.getClassLoader().getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(input); SqlSession session = sqlSessionFactory.openSession(true); //获取接口动态产生的实现类 再调用方法 MyUserMapper myUserMapper = session.getMapper(MyUserMapper.class); MyUser user = myUserMapper.find(12); System.out.println(user); 基于配置文件 和实现xml文件–MyUserMapper.java &amp; MyUserMapper.xml public interface MyUserMapper { //方法要求 类名必须与.xml名相同; 方法名必须与MyUserMapper.xml中对应的id相同; 并且参数要一一对应 public List&lt;MyUser&gt; getAll(); } &lt;select id=&quot;getAllUser&quot; resultType=&quot;com.mybatis.test2.pojo.MyUser&quot;&gt; SELECT * FROM my_user &lt;/select&gt; “注册”到mybatis配置文件–在conf.xml中mappers节点下添加(二选一, 只要有一个就可定位Mapper) &lt;mapper class=&quot;com.mybatis.test2.pojo.MyUserMapper&quot;/&gt; &lt;mapper resource=&quot;com/mybatis/test2/pojo/MyUserMapper.xml&quot;/&gt; 测试(方法不变 只需改方法) 9.优化 1.数据库文件: 把数据库信息配置到一个文件: db.properties,然后在conf.xml中引入,调用使用EL表达式 &lt;properties resource=&quot;classpath:mybatis/db.properties&quot;/&gt; 2.配置别名: 在映射文件中写全类名很长很麻烦,可以在conf.xml中配置别名 alias为别名; 则可以在映射xml文件中写别名表示此类 &lt;typeAliases&gt; &lt;typeAlias type=&quot;com.mybatis.test2.pojo.MyUser&quot; alias=&quot;_MyUser&quot;/&gt; &lt;/typeAliases&gt; 2.配置别名2: 为整个包下类取别名 则别名为此类类名(比如: MyUser) &lt;typeAliases&gt; &lt;package name=&quot;com.mybatis.test2.pojo&quot;/&gt; &lt;/typeAliases&gt; 10.对于数据表字段名和实体属性名不一致的问题 当表字段名和实体属性名不同 就会无法获取数据(区分大小写), 对应的属性即为null(相关类型默认值) 原因是查到的数据无法映射到对应的result实体上,所以只要创建一个映射关系就能解决这个问题 方法一: 指定字段别名(sql语句的方法, 直接指定字段别名为实体属性名) &lt;select id=&quot;getOrder&quot; parameterType=&quot;int&quot; resultType=&quot;Order&quot;&gt; SELECT order_id id, order_no orderNo, order_price orderPrice FROM `order` WHERE order_id = #{id} &lt;/select&gt; 方法二: mybatis提供resultMap用于结果映射; like this &lt;!-- type: 映射实体类型 id主键 property实体属性名 column字段名 --&gt; &lt;resultMap id=&quot;order&quot; type=&quot;Order&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;order_id&quot;/&gt; &lt;result property=&quot;orderNo&quot; column=&quot;order_no&quot;/&gt; &lt;result property=&quot;orderPrice&quot; column=&quot;order_price&quot;/&gt; &lt;/resultMap&gt; &lt;select id=&quot;getOrder&quot; parameterType=&quot;int&quot; resultMap=&quot;order&quot;&gt; SELECT * FROM `order` WHERE order_id = #{id} &lt;/select&gt; 11.一对一和一对多的实现 对于涉及到多表查询, 一般有两种方式: 1.一个表一个表查询,用第一个表查到的数据组成第二个查询语句(也叫嵌套查询); 2.sql关联查询,一条语句,一次查询,语句比较复杂(也叫嵌套结果); 为了尽可能的减少代码量(当然,去掉不必要的”体积”的麻烦),而且效率上 嵌套结果&gt;存储过程&gt;嵌套查询; 嵌套结果示例: 一对一 两个实体类以及一个结果封装类(由于不能仅仅用一个实体接收查询的所有的字段, so其用于封装查询的结果) // 对应数据库中表: order (字段有所不同,参考查询语句) public class Order { private int id; private String orderNo; private float orderPrice; private User user; ... //构造方法, setter, getter, toString等方法 } // 对应数据库中表: user public class User { private int id; private String name; private int age; ... } // 结果封装类 id为user的id, 属性包含其他两个实体类(由于是一对一,则参数也可以把实体的参数复制过来,那查询mapper中resultMap有所不同) public class UserOrder { private String id; private User user; private Order order; ... } 映射文件中查询的编写: &lt;!-使用resultMap封装查询到的所有数据--&gt; &lt;select id=&quot;getOrderInfo&quot; parameterType=&quot;int&quot; resultMap=&quot;uo&quot;&gt; SELECT * FROM user u, `order` o WHERE u.id = #{id} AND u.id = o.user_id &lt;/select&gt; &lt;!-column是查询输出结果的字段名, 如果查询的表之间没有同名字段则column是字段名,如果有字段冲突,则会有所变化(一般是&quot;表别名_字段名&quot;),以防万一要多测试--&gt; &lt;!-property是实体属性名--&gt; &lt;!-association:复杂类型联合,把多个字段映射联合映射为一个对象或其他 需要书写javaType表示要映射的类型 property表示映射类型的属性名--&gt; &lt;resultMap id=&quot;uo&quot; type=&quot;UserOrder&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;id&quot;/&gt; &lt;association property=&quot;user&quot; javaType=&quot;User&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;id&quot;/&gt; &lt;result property=&quot;name&quot; column=&quot;name&quot;/&gt; &lt;result property=&quot;age&quot; column=&quot;age&quot;/&gt; &lt;/association&gt; &lt;association property=&quot;order&quot; javaType=&quot;Order&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;order_id&quot;/&gt; &lt;result property=&quot;orderNo&quot; column=&quot;order_no&quot;/&gt; &lt;result property=&quot;orderPrice&quot; column=&quot;order_price&quot;/&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;!-记得书写代理接口--&gt; 测试类: ... UserOrder order = orderMapper.getOrderInfo(12); System.out.println(order); 一对多 一的一方同上,多的一方就需要一个新的类封装实体对象的集合,并且需要修改mapper写法 // 实体类不变 结果封装类为: public class UserOrder2 { private String id; private User user; private List&lt;Order&gt; orders; } 映射文件: &lt;!-如果你在mysql中输入sql语句,查看结果就会发现:user只有一种但是每条数据的字段数据都有并且相同,order的字段数据每条都不一样--&gt; &lt;!-collection:复杂类型集合,--&gt; &lt;select id=&quot;getOrderInfo2&quot; parameterType=&quot;int&quot; resultMap=&quot;uo2&quot;&gt; SELECT * FROM user u, `order` o WHERE u.id = #{id} AND u.id = o.user_id &lt;/select&gt; &lt;!--collection: 封装字段为集合类型 property: 类中的属性名 内容是集合数据的类型的属性--&gt; &lt;!--oftype: 集合中元素对象类型--&gt; &lt;resultMap id=&quot;uo2&quot; type=&quot;UserOrder2&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;id&quot;/&gt; &lt;association property=&quot;user&quot; javaType=&quot;User&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;id&quot;/&gt; &lt;result property=&quot;name&quot; column=&quot;name&quot;/&gt; &lt;result property=&quot;age&quot; column=&quot;age&quot;/&gt; &lt;/association&gt; &lt;collection property=&quot;orders&quot; ofType=&quot;Order&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;order_id&quot;/&gt; &lt;result property=&quot;orderNo&quot; column=&quot;order_no&quot;/&gt; &lt;result property=&quot;orderPrice&quot; column=&quot;order_price&quot;/&gt; &lt;/collection&gt; &lt;/resultMap&gt; 高级结果映射详细简介见: http://zj2626.github.io/2017/06/19/20170619_Mybatis/ 测试类 UserOrder2 order2 = orderMapper.getOrderInfo2(12); System.out.println(order2); 12.一级缓存与二级缓存 与hibernate相似, mybatis也存在缓存并且默认开启一级缓存,mybatis一级缓存是session级别的,而二级缓存是namespace(statement)级别的(即每个mapper文件就是一个二级缓存范围,需要配置) 配置二级缓存 &lt;cache/&gt; or &lt;cache eviction=&quot;LRU&quot; flushInterval=&quot;60000&quot; size=&quot;512&quot;/&gt; 13.与spring集成 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; 配置mapper 同上 配置spring配置文件: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd&quot;&gt; &lt;!-- 1. 数据源 : DriverManagerDataSource --&gt; &lt;bean id=&quot;datasource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/bean&gt; &lt;!-- 2. mybatis的SqlSession的工厂: SqlSessionFactoryBean dataSource / typeAliasesPackage --&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;datasource&quot;/&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com/mybatis/test3/bean&quot;/&gt; &lt;/bean&gt; &lt;!-- 3. mybatis自动扫描加载Sql映射文件(即接口) : MapperScannerConfigurer sqlSessionFactory / basePackage --&gt; &lt;bean id=&quot;config&quot; class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com/mybatis/test3/mapper&quot;/&gt; &lt;property name=&quot;sqlSessionFactory&quot; ref=&quot;sqlSessionFactory&quot;/&gt; &lt;/bean&gt; &lt;!-- 4. 事务管理 : DataSourceTransactionManager --&gt; &lt;bean id=&quot;manager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;datasource&quot;/&gt; &lt;/bean&gt; &lt;!-- 5. 使用声明式事务 --&gt; &lt;tx:annotation-driven transaction-manager=&quot;manager&quot; /&gt; &lt;/beans&gt; 配置mybatis配置文件 里面没有配置内容(但是必须要) &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt; &lt;configuration&gt; &lt;/configuration&gt; n.分页插件 — PageHelper: 一个分页插件,支持多种数据库,原理大概是在执行sql语句之前(拦截器)进行了操作改写了sql语句,实现分页 导入依赖 &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;/dependency&gt; 配置插件–拦截器(在mybatis的配置文件中), 笔者在spring中集成了mybatis的配置 &lt;plugins&gt; &lt;!--配置PageHelper插件--&gt; &lt;plugin interceptor=&quot;com.github.pagehelper.PageHelper&quot;&gt; &lt;!--配置方言(数据库识别)--&gt; &lt;property name=&quot;dialect&quot; value=&quot;mysql&quot;/&gt; &lt;/plugin&gt; &lt;/plugins&gt; 测试分页 @Test public void testPage() { //初始化Spring容器 ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;classpath:spring/applicationContext-dao.xml&quot;); //获取代理对象 TbItemMapper itemMapper = applicationContext.getBean(TbItemMapper.class); //执行sql语句前设置分页信息使用PageHelper的startPage方法 PageHelper.startPage(1, 10); //查询 TbItemExample example = new TbItemExample(); List&lt;TbItem&gt; list = itemMapper.selectByExample(example); //取分页信息PageInfo 总记录数 总页数 当前页 PageInfo&lt;TbItem&gt; pageInfo = new PageInfo&lt;&gt;(list); System.out.println(pageInfo.getTotal()); System.out.println(pageInfo.getEndRow()); System.out.println(pageInfo.getFirstPage()); System.out.println(pageInfo.getLastPage()); System.out.println(pageInfo.getList()); System.out.println(pageInfo.getNavigatePages()); System.out.println(pageInfo.getNextPage()); System.out.println(pageInfo.getPageNum()); System.out.println(pageInfo.getPages()); System.out.println(pageInfo.getPageSize()); System.out.println(pageInfo.getPrePage()); System.out.println(pageInfo.getSize()); System.out.println(pageInfo.getStartRow()); }","categories":[{"name":"框架相关","slug":"框架相关","permalink":"http://zj2626.github.io/categories/框架相关/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://zj2626.github.io/tags/Mybatis/"}]},{"title":"Vue学习笔记","slug":"2017_e","date":"2017-02-28T16:00:00.000Z","updated":"2018-01-13T02:29:22.234Z","comments":true,"path":"2017/03/01/2017_e/","link":"","permalink":"http://zj2626.github.io/2017/03/01/2017_e/","excerpt":"","text":"Vue.js 是一套构建用户界面的 渐进式框架 JavaScript MVVM库 它是以数据驱动和组件化的思想构建的,无需手动操作DOM.MVVM模式Model-View-ViewModelViewModel是Vue.js的核心，它是一个Vue实例。Vue实例是作用于某一个HTML元素上的，这个元素可以是HTML的body元素，也可以是指定了id的某个元素。 当创建了ViewModel后，双向绑定是如何达成的呢？ 首先，我们将DOM Listeners和Data Bindings看作两个工具，它们是实现双向绑定的关键。从View侧看，ViewModel中的DOM Listeners工具会帮我们监测页面上DOM元素的变化，如果有变化，则更改Model中的数据；从Model侧看，当我们更新Model中的数据时，Data Bindings工具会帮我们更新页面中的DOM元素。&lt;摘自: http://www.cnblogs.com/rik28/p/6024425.html&gt;","categories":[{"name":"框架相关","slug":"框架相关","permalink":"http://zj2626.github.io/categories/框架相关/"},{"name":"前端技术","slug":"框架相关/前端技术","permalink":"http://zj2626.github.io/categories/框架相关/前端技术/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://zj2626.github.io/tags/Vue/"}]},{"title":"Mongodb安装与启动","slug":"2017_Mongodb","date":"2017-02-28T16:00:00.000Z","updated":"2018-01-13T02:29:22.227Z","comments":true,"path":"2017/03/01/2017_Mongodb/","link":"","permalink":"http://zj2626.github.io/2017/03/01/2017_Mongodb/","excerpt":"MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写;是一个介于关系数据库和非关系数据库之间的产品其支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。使用原理 : 面向集合: 数据被分组存储在数据集中，被称为一个集合（Collection),每个集合在数据库中都有一个唯一的标识名，并且可以包含无限数目的文档 (类似于传统数据库中的 表(table)) 模式自由: 意味着对于存储在mongodb数据库中的文件，我们不需要知道它的任何结构定义;存储在集合中的文档， 键-值对的形式:键用于唯一标识一个文档，为字符串类型，而值则可以是各种复杂的文件类型。我们称这种存储形式为BSON（Binary Serialized Document Format）","text":"MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写;是一个介于关系数据库和非关系数据库之间的产品其支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。使用原理 : 面向集合: 数据被分组存储在数据集中，被称为一个集合（Collection),每个集合在数据库中都有一个唯一的标识名，并且可以包含无限数目的文档 (类似于传统数据库中的 表(table)) 模式自由: 意味着对于存储在mongodb数据库中的文件，我们不需要知道它的任何结构定义;存储在集合中的文档， 键-值对的形式:键用于唯一标识一个文档，为字符串类型，而值则可以是各种复杂的文件类型。我们称这种存储形式为BSON（Binary Serialized Document Format） 安装 环境:CentOs6.5 64位 远程工具 xsell 下载:官网下载 https://www.mongodb.com/download-center?jmp=nav#community 或者 输入命令: &gt; curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.0.6.tgz 解压: &gt; tar -zxvf mongodb-linux-x86_64-3.0.6.tgz 移动到目录 mv mongodb-linux-x86_64-3.0.6/ /usr/local/mongodb 把bin目录添加到环境变量PATH中 : vim /etc/profile 添加或修改为: export PATH=”/usr/local/mongodb/bin:$PATH” 配置自己的数据,日志等目录 I. &gt; cd /usr/local/mongodb II. &gt; mkdir data III. &gt; mkdir log IV. &gt; mkdir conf V. &gt; cd conf VI. &gt; touch mongodb.conf VII. &gt; vim mongodb.conf port = 27017 dbpath = data logpath = log/mongod.log fork = true 启动 配置完毕 启动服务 可以使用自己的配置文件中的配置 /usr/local/mongodb/bin/mongod -f /usr/local/mongodb/conf/mongodb.conf 也可以输入配置目录启动 /usr/local/mongodb/bin/mongod –dbpath=/usr/local/mongodb/data/ –port=12345 –fork –logpath=/usr/local/mongodb/log/mongodb.log 启动之后 输入 &gt; mongo 127.0.0.1:12345/admin 连接mongodb服务 目前没有设置用户名密码 所以需要无认证启动, so先设置用户名密码 mongodb中用户是归属于数据库的 ,可以说是为数据库设置自己的用户,并设置权限,一般一个用户只是管理一个数据库 (当然,可以设置一个超级管理员用来管理所有的数据库) 下面的意思是为admin数据库设置一个用户名为”root”,密码为”root”的用户,用户权限(角色) 是root(超级管理员) &gt; use admin &gt; db.createUser( ... { ... user: &quot;root&quot;, ... pwd: &quot;root&quot;, ... roles: [ { role: &quot;root&quot;, db: &quot;admin&quot; } ] ... } ... ) 上面是mongodb3.0的新建用户方式, 2.x的方式有所不同,自行查阅 下面是mongodb内置的角色 1. 数据库用户角色：read、readWrite; 2. 数据库管理角色：dbAdmin、dbOwner、userAdmin； 3. 集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManager； 4. 备份恢复角色：backup、restore； 5. 所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、dbAdminAnyDatabase 6. 超级用户角色：root // 这里还有几个角色间接或直接提供了系统超级用户的访问（dbOwner 、userAdmin、userAdminAnyDatabase） 7. 内部角色：__system Read：允许用户读取指定数据库readWrite：允许用户读写指定数据库dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profileuserAdmin：允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户clusterAdmin：只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。root：只在admin数据库中可用。超级账号，超级权限 也可以创建角色: &gt; db.createRole( ... { ... role: &quot;manageOpRole&quot;, ... privileges: [ ... { resource: { cluster: true }, actions: [ &quot;killop&quot;, &quot;inprog&quot; ] }, ... { resource: { db: &quot;my_test&quot;, collection: &quot;my_collection&quot; }, ... actions: [ &quot;insert&quot;, &quot;update&quot;, &quot;remove&quot;, &quot;compact&quot;] } ... ], ... roles: [] ... } ... ) { &quot;role&quot; : &quot;manageOpRole&quot;, &quot;privileges&quot; : [ { &quot;resource&quot; : { &quot;cluster&quot; : true }, &quot;actions&quot; : [ &quot;killop&quot;, &quot;inprog&quot; ] }, { &quot;resource&quot; : { &quot;db&quot; : &quot;my_test&quot;, &quot;collection&quot; : &quot;my_collection&quot; }, &quot;actions&quot; : [ &quot;insert&quot;, &quot;update&quot;, &quot;remove&quot;, &quot;compact&quot; ] } ], &quot;roles&quot; : [ ] } &gt; 可以添加几个其他角色的用户来测试权限 要用用户登录的服务 so先关闭服务: &gt; db.shutdownServer() 启动带权限验证的mongodb服务: &gt; /usr/local/mongodb/bin/mongod --dbpath=/usr/local/mongodb/data/ --port=12345 --fork --logpath=/usr/local/mongodb/log/mongodb.log -auth 如果报错too many positional options是由于--的原因,需要写英文的两个- 连接 &gt; mongo 127.0.0.1:12345/admin 使用数据库 use admin 进行一些数据库操作 比如 &gt; show dbs 此时就会报错 用用户名密码验证权限 &gt; db.auth(&apos;root&apos;,&apos;anyao112233&apos;) 返回1表示成功 返回0表示失败 ; 此时再输入: show dbsshow collections 就会返回正常结果; 常见问题解决注意 : &gt; use test //用来切换别的数据库此时如果登录的用户没有操作此数据库的权限 show dbs就会报错#####*注意* : 此时关闭服务&gt; db.shutdownServer() 可能会报错,它提示没有shutdown的权限 解决方法: &gt; db.grantRolesToUser( &quot;root&quot; , [ { role: &quot;hostManager&quot;, db: &quot;admin&quot; } ]) 为用户root赋予hostManager角色的权限,然后就可以关闭了 输入&gt; exit 退出界面 注:可以用浏览器访问 127.0.0.1:27017注:有时候shutdown以后 无法再启动 报错 原因:1. mongodb没有正常关闭 解决方法:删除mongodb的data目录下的mongod.lock (不能解决就把log目录中日志删除) 2.上面试了还是无法启动,那就是mongodb服务可能没有访问data,log等目录的权限 解决方法:&gt; chmod -R 777 /usr/local/mongodb/","categories":[{"name":"数据库","slug":"数据库","permalink":"http://zj2626.github.io/categories/数据库/"}],"tags":[{"name":"Mongodb","slug":"Mongodb","permalink":"http://zj2626.github.io/tags/Mongodb/"}]},{"title":"Mongodb的基础操作详解","slug":"2017_Mongodb_curd","date":"2017-02-28T16:00:00.000Z","updated":"2018-01-13T02:29:22.229Z","comments":true,"path":"2017/03/01/2017_Mongodb_curd/","link":"","permalink":"http://zj2626.github.io/2017/03/01/2017_Mongodb_curd/","excerpt":"对数据库的操作&gt;show dbs 显示所有数据库 &gt;use admin 切换数据库(数据库可以自动新建) &gt;db.auth(&apos;username&apos;,&apos;password&apos;) 验证用户权限 &gt;db.dropDatabase() 删除数据库 对集合(collection)的操作(也就是对表的操作)&gt;db.集合名.drop() 删除表 &gt;show collections 显示所有的collection &gt;show tables 显示所有的collection","text":"对数据库的操作&gt;show dbs 显示所有数据库 &gt;use admin 切换数据库(数据库可以自动新建) &gt;db.auth(&apos;username&apos;,&apos;password&apos;) 验证用户权限 &gt;db.dropDatabase() 删除数据库 对集合(collection)的操作(也就是对表的操作)&gt;db.集合名.drop() 删除表 &gt;show collections 显示所有的collection &gt;show tables 显示所有的collection 对数据的操作查询&gt;db.集合名.find() 查询数据库中某个集合的数据 &gt;db.集合名.find({x:1}) 查询数据库 查询包含参数json字符串的数据 &gt;db.集合名.find().count() 查询数据库中数据的个数(可带参数 表条件) &gt;db.集合名.find().skip(5).limit(10).sort({x:1,y:1}) 查询条件:skip:跳过数据的个数;limit:查询条数;sort:按照某个字段排序(这里是先按x排序,再按y排序, 1表示正像排序,-1代表反向) &gt;db.集合名.find({y:{$exists:true}}) //查询y字段存在的数据 &gt;db.集合名.find({x:1}).explain() //带详细信息的查询 增加&gt;db.集合名.insert({x:1}) 插入数据(参数格式为json格式,集合名可以自动新建) 插入时会自动生成id(名叫&quot;_id&quot;的字段) &gt;db.集合名.insert({x:1, _id:1}) 带id的插入(需要保证_id全局唯一,不可重复) &gt;for(i=0;i&lt;100;i++) db.集合名.insert({x:i+200}) 使用循环插入数据库 更新Update有4个参数：(默认更新一条数据) 第一个selector(查询条件)， 第二个newValue(要更新的数据)， $set、$inc、$push 第三个upserts， true:查到就更新,没查到就新建 第四个multipleUpdate, true:批量更新 &gt; db.集合名.update({x:10},{x:100}) 更新方法: 第一个json:更新条件 ;第二个json:更新结果 (把x=1的数据更新为x=10) &gt; db.集合名.update({x:10},$set:{y:100}}) 部分更新: 只更新第二个json所改变的字段(不加set操作符,会把原来的所有的字段覆盖为更新结果) &gt; db.集合名.update({x:10},{x:100}, true) 更新或插入: 如果更新的数据不存在就插入一条数据(upsert = true) &gt; db.集合名.update({x:10},$set:{y:100}}, false, true) 批量更新: 为防止误操作,必须使用set操作,(upsert = false,) 删除(默认删除查到的所有数据) &gt; db.集合名.remove({x:200}) 删除操作:必须有参数 索引查看索引&gt;db.collection.getIndexes() //每个collection都会创建默认的一个索引 _id 创建索引&gt;db.collection.ensureIndex({x:1}) 1表示正像排序,-1代表反向 (最好在存在大量数据之前就已经添加好索引) &gt;db.collection.ensureIndex({x:1},{name:&quot;&quot;my_index}) 自定义命名索引名 删除索引&gt;db.collection.dropIndex(&quot;index_name&quot;) //参数是索引名 索引类型1. _id索引(默认的唯一索引) 2.单键索引: 普通索引(值为一个字符串,数字,日期等) db.collection.ensureIndex({x:1}) 3.多键索引: 当索引的字段为数组时，创建出的索引称为多key索引 如果存在一个多值的字段如: { &quot;_id&quot; : ObjectId(&quot;58bbcfeb48e281d3bc2a95b9&quot;), &quot;x&quot; : [ 1, 2, 3, 4, 5, 6 ] } 那么在这条记录创建时候 会自动建立多键索引(或手动创建 db.collection.createIndex( {x: 1} ) ) 查询: db.collection.find({x: 1}) 或者 db.collection.find({x: 3}) 4.复合索引: 相当于多个单键索引 创建方式: db.collection.ensureIndex({x:1,y:1}) 5.过期索引: (TTL) 一段时间后会过期(删除数据)的索引 (过期时间 单位是秒) 创建方式: db.collection.ensureIndex({x:1},{expireAfterSeconds:10}) 注意: 1.存储在过期索引字段的值必须是ISODate或ISODate数组,不能是其他,否则无法删除 2.如果是Date数组就按照时间从小到大删 3.不能是复合索引 4.删除不是准时的,而是60s的一个定时进程执行的删除 5.全文索引 db.collection.ensureIndex({&quot;key&quot;:&quot;text&quot;}) db.collection.ensureIndex({&quot;key&quot;:&quot;text&quot;,&quot;key2&quot;:&quot;text&quot;}) db.collection.ensureIndex({&quot;$**&quot;:&quot;text&quot;}) 其中key表示原来的”字段名”,键; text表示的不是原来的正序或倒序,而是要检索的内容(创建索引要写”text”)一个collection只能创建一个全文索引 全文索引测试: 创建内容: &gt; db.test.insert({&quot;x&quot;:&quot;aaa ccc&quot;}) &gt; db.test.insert({&quot;x&quot;:&quot;bbb&quot;}) &gt; db.test.insert({&quot;y&quot;:&quot;ccc&quot;}) &gt; db.test.insert({&quot;z&quot;:&quot;ccc&quot;}) &gt; db.test.insert({&quot;x&quot;:&quot;aaa111&quot;}) &gt; db.test.insert({&quot;y&quot;:&quot;aaa111&quot;}) &gt; db.test.insert({&quot;x&quot;:&quot;aaa222&quot;,&quot;y&quot;:&quot;ccc&quot;}) 查看创建的内容: db.test.find() //6条 创建索引: db.test.ensureIndex({&quot;x&quot;:&quot;text&quot;}) 查看所有索引:db.test.getIndexes() //2个,第一个是默认的索引 查询: &gt; db.test.find({$text:{$search:&quot;aaa&quot;}}) //没找到数据 &gt; db.test.find({$text:{$search:&quot;aaa111&quot;}}) //查到一条(全部匹配) { &quot;_id&quot; : ObjectId(&quot;58bcb92118bc95b8f476def1&quot;), &quot;x&quot; : &quot;aaa111&quot; } &gt; db.test.find({$text:{$search:&quot;ccc&quot;}}) { &quot;_id&quot; : ObjectId(&quot;58bf535ae830c0c5f89055e7&quot;), &quot;x&quot; : &quot;aaa ccc&quot; } &gt; db.test.find({$text:{$search:&quot;aaa111 aaa&quot;}}) //或查询 用户空格分开 { &quot;_id&quot; : ObjectId(&quot;58bf535ae830c0c5f89055e7&quot;), &quot;x&quot; : &quot;aaa ccc&quot; } { &quot;_id&quot; : ObjectId(&quot;58bcb92118bc95b8f476def1&quot;), &quot;x&quot; : &quot;aaa111&quot; } &gt; db.test.find({$text:{$search:&quot;aaa111 aaa -ccc&quot;}}) //或查询,其中&apos;-&apos;表示不包含 { &quot;_id&quot; : ObjectId(&quot;58bcb92118bc95b8f476def1&quot;), &quot;x&quot; : &quot;aaa111&quot; } &gt; db.test.find({$text:{$search:&quot;\\&quot;aaa\\&quot; \\&quot;aaa111\\&quot;&quot;}}) //与查询 1条 &gt; db.test.find({$text:{$search:&quot;\\&quot;aaa222\\&quot;&quot;}}) //1条 &gt; db.test.find({$text:{$search:&quot;\\&quot;aaa\\&quot; \\&quot;aa\\&quot;&quot;}}) //1条 &gt; db.test.find({$text:{$search:&quot;\\&quot;aaa\\&quot; \\&quot;aa\\&quot;&quot;}}) //1条 &gt; db.test.find({$text:{$search:&quot;\\&quot;aaa222\\&quot; \\&quot;aa\\&quot;&quot;}}) //1条 *全文索引相似度查询 返回查询到的结果与要查询的数据的相似度 {score:{$meta:&quot;textScore&quot;}} 得到的数越大表示相似度越高 &gt; db.test.find({$text:{$search:&quot;aaa222&quot;}},{score:{$meta:&quot;textScore&quot;}}) { &quot;_id&quot; : ObjectId(&quot;58bcb92518bc95b8f476def2&quot;), &quot;x&quot; : &quot;aaa222&quot;, &quot;y&quot; : &quot;ccc&quot;, &quot;score&quot; : 1.1 } &gt; db.test.find({$text:{$search:&quot;aaa&quot;}},{score:{$meta:&quot;textScore&quot;}}) { &quot;_id&quot; : ObjectId(&quot;58bf535ae830c0c5f89055e7&quot;), &quot;x&quot; : &quot;aaa ccc&quot;, &quot;score&quot; : 0.75 } //用相似度排序 &gt; db.test.find({$text:{$search:&quot;bbb&quot;}},{score:{$meta:&quot;textScore&quot;}}).sort({score:{$meta:&quot;textScore&quot;}}) *全文索引限制: 1.一次只能指定一个$text查询 2.$text不能使用$nor查询 3.查询中包含$text,则hint(强制指定索引)无效 4.目前已经支持中文查询(版本3.0.6) 6.地理位置索引 1. 2D索引:平面地理位置索引 创建索引: db.collection.ensureIndex({w:&quot;2d&quot;}) 位置表示方法:经纬度[经度, 纬度] //经度:-180 -&gt; 180; 纬度:-90 -&gt; 90 1.插入数据(插入数据超过范围时可能会有不可预知的错误) &gt; db.mytest4.find() { &quot;_id&quot; : ObjectId(&quot;58bfa69dbf18b69568aedc5c&quot;), &quot;w&quot; : [ 1, 1 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa6a1bf18b69568aedc5d&quot;), &quot;w&quot; : [ 1, 3 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa6aabf18b69568aedc5e&quot;), &quot;w&quot; : [ 10, 30 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa780bf18b69568aedc64&quot;), &quot;w&quot; : [ 180, 90 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa723bf18b69568aedc62&quot;), &quot;w&quot; : [ -100, 90 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa728bf18b69568aedc63&quot;), &quot;w&quot; : [ -150, 90 ] } 2.查询 1.普通查询 &gt; db.mytest4.find({w:{$near:[1,1]}}) //默认返回100个距离所求点最近的点的位置 2.查询某个距离内的点 &gt; db.mytest4.find({w:{$near:[1,1],$maxDistance:10}}) //$maxDistance设置最远距离(直线距离)(不支持$minDistance) { &quot;_id&quot; : ObjectId(&quot;58bfa69dbf18b69568aedc5c&quot;), &quot;w&quot; : [ 1, 1 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa6a1bf18b69568aedc5d&quot;), &quot;w&quot; : [ 1, 3 ] } 3.查询某个形状范围内的点 1.矩形: $geoWithin + $box (查询[0,0],[100,10]内的点) &gt; db.mytest4.find({w:{$geoWithin:{$box:[[0,0],[100,10]]}}}) { &quot;_id&quot; : ObjectId(&quot;58bfa69dbf18b69568aedc5c&quot;), &quot;w&quot; : [ 1, 1 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa6a1bf18b69568aedc5d&quot;), &quot;w&quot; : [ 1, 3 ] } 2.圆形: $geoWithin + $center (查询圆心为[0,0],半径为140内的点) &gt; db.mytest4.find({w:{$geoWithin:{$center:[[0,0],140]}}}) { &quot;_id&quot; : ObjectId(&quot;58bfa723bf18b69568aedc62&quot;), &quot;w&quot; : [ -100, 90 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa69dbf18b69568aedc5c&quot;), &quot;w&quot; : [ 1, 1 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa6a1bf18b69568aedc5d&quot;), &quot;w&quot; : [ 1, 3 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa6aabf18b69568aedc5e&quot;), &quot;w&quot; : [ 10, 30 ] } 3.多边形: $geoWithin + $polygon (查询这几个点围成的多边形内的点,写至少是三个点) &gt; db.mytest4.find({w:{$geoWithin:{$polygon:[[0,0],[80,91],[-45,70]]}}}) { &quot;_id&quot; : ObjectId(&quot;58bfa6a1bf18b69568aedc5d&quot;), &quot;w&quot; : [ 1, 3 ] } { &quot;_id&quot; : ObjectId(&quot;58bfa6aabf18b69568aedc5e&quot;), &quot;w&quot; : [ 10, 30 ] } #查询方式2 geoNear:要查询的collection名; near:基点; minDistance:搜索的最小距离; maxDistance:搜索的最大距离; num:查询数量 &gt; db.runCommand({geoNear:&quot;mytest4&quot;,near:[1,5],maxDistance:10,num:2}) { &quot;results&quot; : [ { &quot;dis&quot; : 2, &quot;obj&quot; : { &quot;_id&quot; : ObjectId(&quot;58bfa6a1bf18b69568aedc5d&quot;), &quot;w&quot; : [ 1, 3 ] } }, { &quot;dis&quot; : 4, &quot;obj&quot; : { &quot;_id&quot; : ObjectId(&quot;58bfa69dbf18b69568aedc5c&quot;), &quot;w&quot; : [ 1, 1 ] } } ], &quot;stats&quot; : { &quot;nscanned&quot; : 3, &quot;objectsLoaded&quot; : 2, &quot;avgDistance&quot; : 3, &quot;maxDistance&quot; : 4, &quot;time&quot; : 0 }, &quot;ok&quot; : 1 } 2. 2Dsphere索引:球面地理位置索引:geoNear查询 使用runCommand命令进行使用 1. 创建 db.collection.ensureIndex({w:&quot;2dsphere&quot;}) 位置表示方法:GeoJSON:可以描述一个点,线或各种形状等 {type:&quot;&quot;,coordinates:[&lt;coordinates&gt;]} 2. 查询 //待续... 索引属性1.name: db.collection.ensureIndex({x:1},{name:&quot;my_index&quot;}) 指定索引名称 2.unique: db.collection.ensureIndex({y:1},{unique:true}) 设置为true,则不允许在同一个collection中插入有相同唯一索引的字段(索引的数值不能重复) 注意:如果插入的数据没有指定的索引字段,则只能插入一条这样的数据,再插入则会报错(相当于重复) 3.sparse: db.collection.ensureIndex({y:1},{sparse:true}) 设置为true,则不会在没有的字段的数据上创建索引 &gt; db.collection.find({y:{$exists:true}}) //查询y字段存在的数据 测试: 先插入6条数据,其中1条包含有y字段 &gt; db.test3.ensureIndex({y:1},{name:&quot;mytest_y&quot;},{sparse:false}) //创建索引 &gt; db.test3.find({y:{$exists:false}}) //查询不存在y的数据 5条(数据库并没有为这5条数据建立y的索引,而是数据库优化的结果,这里查询并没有用上面的索引,so查到了) { &quot;_id&quot; : ObjectId(&quot;58bf69ced52555dec4840312&quot;), &quot;x&quot; : 1 } { &quot;_id&quot; : ObjectId(&quot;58bf6c00d52555dec4840319&quot;), &quot;x&quot; : 2111313, &quot;k&quot; : 1 } { &quot;_id&quot; : ObjectId(&quot;58bf6c13d52555dec484031a&quot;), &quot;x&quot; : 2111313, &quot;k&quot; : 2 } { &quot;_id&quot; : ObjectId(&quot;58bf6c15d52555dec484031b&quot;), &quot;x&quot; : 2111313, &quot;k&quot; : 3 } { &quot;_id&quot; : ObjectId(&quot;58bf6c19d52555dec484031c&quot;), &quot;x&quot; : 2111313, &quot;z&quot; : 3 } &gt; db.test3.find({y:{$exists:false}}).hint(&quot;mytest_y&quot;) //强制指定索引,使用指定的索引查询,就无法查到不包含y的数据 &gt; //没有查到数据 4.expireAfterSeconds 是否定时删除TTL(过期索引) &gt; db.collection.ensureIndex({x:1},{expireAfterSeconds:10}) 其他1. mongodb可以通过profile来监控数据，进行优化。 查看当前是否开启profile功能用命令 &gt; db.getProfilingLevel() 0 开启profile功能 &gt; db.setProfilingLevel(2) //0代表关闭，1代表记录慢命令，2代表全部 { &quot;was&quot; : 0, &quot;slowms&quot; : 100, &quot;ok&quot; : 1 } 查看当前的监控日志 db.system.profile.find()","categories":[{"name":"数据库","slug":"数据库","permalink":"http://zj2626.github.io/categories/数据库/"}],"tags":[{"name":"Mongodb","slug":"Mongodb","permalink":"http://zj2626.github.io/tags/Mongodb/"},{"name":"CRUD","slug":"CRUD","permalink":"http://zj2626.github.io/tags/CRUD/"}]},{"title":"Hibernate配置以及实体映射配置","slug":"2017_Hibernate","date":"2017-02-26T16:00:00.000Z","updated":"2018-01-13T02:29:22.220Z","comments":true,"path":"2017/02/27/2017_Hibernate/","link":"","permalink":"http://zj2626.github.io/2017/02/27/2017_Hibernate/","excerpt":"Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装,，它将POJO与数据库表建立映射关系Hibernate是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库 下面是测试用实体1—Student.java","text":"Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装,，它将POJO与数据库表建立映射关系Hibernate是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库 下面是测试用实体1—Student.java package com.em.entity; /** * Created by zhangjin on 2017/2/27. */ public class Student { private Integer id; private String name; private Integer age; private Double score; private Course course; public Student() { } public Student(String name, Integer age, Double score) { this.name = name; this.age = age; this.score = score; } public Student(String name, Integer age, Double score, Course course) { this.name = name; this.age = age; this.score = score; this.course = course; } public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } public Double getScore() { return score; } public void setScore(Double score) { this.score = score; } public Course getCourse() { return course; } public void setCourse(Course course) { this.course = course; } @Override public String toString() { return &quot;Student{&quot; + &quot;id=&quot; + id + &quot;, name=&apos;&quot; + name + &apos;\\&apos;&apos; + &quot;, age=&quot; + age + &quot;, course=&quot; + course + &apos;}&apos;; } } 其所对应的Hibernate映射文件为 Student.hbm.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot; &quot;http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd&quot;&gt; &lt;!-- package:包名--&gt; &lt;hibernate-mapping package=&quot;com.em.entity&quot;&gt; &lt;class name=&quot;Student&quot; table=&quot;STUDENT&quot;&gt; &lt;!--表的主键--&gt; &lt;id name=&quot;id&quot; type=&quot;java.lang.Integer&quot;&gt; &lt;column name=&quot;ID&quot;/&gt; &lt;!--主键的生成方式--&gt; &lt;!-- antive:数据库本地的方式(数据库自己生成主键的方式) increment:Hiernate以递增的方式生成(只测试时候用 因为有并发的问题) identity:由底层数据库负责生成标识符(数据库必须支持主键自增) sequence:利用底层数据库提供的序列生成标识符 hilo:Hibernate通过高低算法生成标识符 --&gt; &lt;generator class=&quot;native&quot;/&gt; &lt;/id&gt; &lt;!--属性映射 name:实体属性名--&gt; &lt;!--length:限制长度 但是我测试了好几次都不起作用 无论是String还是Integer--&gt; &lt;property name=&quot;name&quot; type=&quot;java.lang.String&quot; length=&quot;100&quot;&gt; &lt;!--column: 数据库中列名--&gt; &lt;column name=&quot;NAME&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;age&quot; type=&quot;java.lang.Integer&quot; length=&quot;10&quot;&gt; &lt;column name=&quot;AGE&quot;/&gt; &lt;/property&gt; &lt;!--index: 为SCORE列添加索引 索引名:score_index--&gt; &lt;property name=&quot;score&quot; type=&quot;java.lang.Double&quot; index=&quot;score_index&quot;&gt; &lt;column name=&quot;SCORE&quot;/&gt; &lt;/property&gt; &lt;!--映射关联关系(即外键) class:外键对应的类名 column:外键列名--&gt; &lt;many-to-one name=&quot;course&quot; class=&quot;Course&quot; column=&quot;COURSE_ID&quot;/&gt; &lt;!--匿名查询使用的查询语句(可以把部分查询语句配置在配置文件中 方便修改)--&gt; &lt;query name=&quot;findByName&quot;&gt;&lt;![CDATA[from Student where name like :name and score &gt; :score]]&gt;&lt;/query&gt; &lt;/class&gt; &lt;/hibernate-mapping&gt; 下面是测试用实体2—Course.javapackage com.em.entity; import java.sql.Timestamp; import java.util.HashSet; import java.util.Set; /** * Created by zhangjin on 2017/2/27. */ public class Course { private Integer id; private String courseName; private Timestamp courseTime; Set&lt;Student&gt; stuSet = new HashSet&lt;&gt;(); public Course() { } public Course(String courseName, Timestamp courseTime) { this.courseName = courseName; this.courseTime = courseTime; } public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getCourseName() { return courseName; } public void setCourseName(String courseName) { this.courseName = courseName; } public Timestamp getCourseTime() { return courseTime; } public void setCourseTime(Timestamp courseTime) { this.courseTime = courseTime; } public Set&lt;Student&gt; getStuSet() { return stuSet; } public void setStuSet(Set&lt;Student&gt; stuSet) { this.stuSet = stuSet; } @Override public String toString() { return &quot;Course{&quot; + &quot;id=&quot; + id + &quot;, courseName=&apos;&quot; + courseName + &apos;\\&apos;&apos; + &quot;, courseTime=&quot; + courseTime + &apos;}&apos;; } } 其所对应的Hibernate映射文件为 Course.hbm.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD 3.0//EN\" \"http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping package=\"com.em.entity\"&gt; &lt;!-- dynamic-insert:动态插入: 设置插入只插入非空的属性(默认为false) 设置之后insert语句只包含非空的参数, 没有值的字段不会出现在insert语句中 dynamic-update:动态更新: 同上,换成更新(默认false) 动态update对性能有一个重大的影响，就是打开了以后，不同的对象的sql语句会不一样， 如果你一次更新多条记录，hibernate将不能使用 executeBatch进行批量更新，这样效率降低很多。 同时，在这种情况下，多条sql意味着数据库要做多次sql语句编译。 select-before-update 设置在每次更新操作前都查询一次,(默认false) 如果查询的数据库中数据与要更新的实体相同就不会执行更新语句,但是无论是否更新都会先执行查询,效率低 --&gt; &lt;class name=\"Course\" table=\"COURSE\" dynamic-insert=\"true\" dynamic-update=\"false\" select-before-update=\"false\"&gt; &lt;id name=\"id\" type=\"java.lang.Integer\" length=\"10\"&gt; &lt;column name=\"ID\"/&gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;property name=\"courseName\" type=\"java.lang.String\" length=\"100\"&gt; &lt;column name=\"COURSE_NAME\"/&gt; &lt;/property&gt; &lt;property name=\"courseTime\" type=\"java.sql.Timestamp\" index=\"time_index\"&gt; &lt;column name=\"COURSE_TIME\"/&gt; &lt;/property&gt; &lt;!--映射一对多的集合属性--&gt; &lt;!--属性:fetch select(默认): 延迟检索 join : 迫切采用做外连接的方式初始化n关联的1的一端的属性 属性:lazy proxy : 延迟检索 false : 立即检索 属性:inverse:设置true的一方(Set端设置)放弃维护关联关系,可减少维护次数,减少内存消耗 属性:cascade:设置级联操作(默认none) --&gt; &lt;set name=\"stuSet\" inverse=\"true\" fetch=\"select\"&gt; &lt;key column=\"COURSE_ID\"/&gt;&lt;!--多的一端的数据库外键名--&gt; &lt;one-to-many class=\"Student\"/&gt;&lt;!--一对多对应的类--&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; hibernate.cfg.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\" \"http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd\"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!--连接数据库配置--&gt; &lt;property name=\"hibernate.connection.username\"&gt;root&lt;/property&gt; &lt;property name=\"hibernate.connection.password\"&gt;fangshuoit&lt;/property&gt; &lt;property name=\"hibernate.connection.driver_class\"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=\"hibernate.connection.url\"&gt;jdbc:mysql://127.0.0.1:3306/test&lt;/property&gt; &lt;!--hibernate信息配置--&gt; &lt;!--hibernate使用的数据库方言--&gt; &lt;property name=\"hibernate.dialect\"&gt;org.hibernate.dialect.MySQL57InnoDBDialect&lt;/property&gt; &lt;!--操作时是否在控制台打印sql--&gt; &lt;property name=\"show_sql\"&gt;true&lt;/property&gt; &lt;!--是否对sql进行格式化--&gt; &lt;property name=\"format_sql\"&gt;false&lt;/property&gt; &lt;!--指定自动生成数据表的策略--&gt; &lt;!--create:每次重新生成数据表 create-drop:每次重新生成表,SessionFactory关闭就删表 update:每次只是更新,不改变数据 validate:不一样就抛异常,不修改表--&gt; &lt;property name=\"hbm2ddl.auto\"&gt;update&lt;/property&gt; &lt;!--设置事务隔离级别--&gt; &lt;property name=\"connection.isolation\"&gt;2&lt;/property&gt; &lt;!--设置删除对象后 使其OID置为null--&gt; &lt;property name=\"use_identifier_rollback\"&gt;true&lt;/property&gt; &lt;!--c3p0连接池配置--&gt; &lt;!--连接池最大连接数--&gt; &lt;property name=\"c3p0.max_size\"&gt;10&lt;/property&gt; &lt;!--连接池最小连接数--&gt; &lt;property name=\"c3p0.min_size\"&gt;5&lt;/property&gt; &lt;!--连接池的连接耗尽时,一次向再获取多少个数据库连接--&gt; &lt;property name=\"c3p0.acquire_increment\"&gt;2&lt;/property&gt; &lt;!--连接对象在多久未使用,会被销毁 2s--&gt; &lt;property name=\"c3p0.idle_test_period\"&gt;2000&lt;/property&gt; &lt;!--多久时间检测一次连接超时情况--&gt; &lt;property name=\"c3p0.timeout\"&gt;2000&lt;/property&gt; &lt;!--缓存Statement对象数量--&gt; &lt;property name=\"c3p0.max_statements\"&gt;10&lt;/property&gt; &lt;!--mysql无效 oracle有效--&gt; &lt;!--设定jdbc的Statement读取数据的时候每次从数据库中取出多少记录条数--&gt; &lt;property name=\"jdbc.fetch_size\"&gt;100&lt;/property&gt; &lt;!--设定对数据库进行批量操作(增删改)时 一次操作的条数--&gt; &lt;property name=\"jdbc.batch_size\"&gt;50&lt;/property&gt; &lt;!--启用二级缓存--&gt; &lt;property name=\"cache.use_second_level_cache\"&gt;true&lt;/property&gt; &lt;property name=\"hibernate.cache.region.factory_class\"&gt;org.hibernate.cache.ehcache.EhCacheRegionFactory &lt;/property&gt; &lt;!--启用查询缓存--&gt; &lt;property name=\"cache.use_query_cache\"&gt;true&lt;/property&gt; &lt;!-- 配置管理session的方式 就是配置session绑定到某一运行环境 (将getCurrentSession()返回的session绑定到当前运行线程中 此session的上下文是thread) --&gt; &lt;!--注意：Spring3.x不能为thread，否则报错:org.hibernate.HibernateException: save is not valid without active transaction ， 以上配置在 增加、删除、修改 操作时，都能正确执行，事务也正常执行！ 当执行 查询 操作时，不需要事务的支持，问题来了，报错:org.hibernate.HibernateException: No Session found for current thread 意思是必须在transcation.isActive()条件下才能执行， 可以解决办法是：当方法不需要事务支持的时候，使用 Session session = sessionFactory.openSession()来获得Session对象，问题解决！ --&gt; &lt;!--&lt;property name=\"current_session_context_class\"&gt;thread&lt;/property&gt;--&gt; &lt;!--指定关联的.hbm.xml文件--&gt; &lt;mapping resource=\"com/em/entity/Student.hbm.xml\"/&gt; &lt;mapping resource=\"com/em/entity/Course.hbm.xml\"/&gt; &lt;!--设置使用二级缓存的类(类级别的二级缓存) 以及使用二级缓存的策略usage--&gt; &lt;class-cache class=\"com.em.entity.Student\" usage=\"read-write\"/&gt; &lt;class-cache class=\"com.em.entity.Course\" usage=\"read-write\"/&gt; &lt;!--设置使用二级缓存的类(集合级别的二级缓存) 以及使用二级缓存的策略usage--&gt; &lt;collection-cache collection=\"com.em.entity.Course.stuSet\" usage=\"read-write\"/&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 单元测试1234567891011121314151617181920212223242526272829303132package com.em.hibernate;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.cfg.Configuration;import org.hibernate.service.ServiceRegistry;import org.hibernate.service.ServiceRegistryBuilder;import org.junit.Test;/** * Created by zhangjin on 2017/2/27. */public class HibernateTest &#123; private static SessionFactory factory; static &#123;// .configuere()方法中参数为hibernate.cfg.xml配置文件位置 不填写表示取src目录下 Configuration configuration = new Configuration().configure(); ServiceRegistry serviceRegistry = new ServiceRegistryBuilder() .applySettings(configuration.getProperties()).buildServiceRegistry(); factory = configuration.buildSessionFactory(serviceRegistry); &#125; private Session getSession() &#123; return factory.openSession(); &#125; @Test public void test()&#123; //junit运行创建数据库表以及表结构 &#125;&#125;","categories":[{"name":"框架相关","slug":"框架相关","permalink":"http://zj2626.github.io/categories/框架相关/"}],"tags":[{"name":"Hibernate","slug":"Hibernate","permalink":"http://zj2626.github.io/tags/Hibernate/"}]},{"title":"彻底理解ThreadLocal(转载)","slug":"2017_ThreadLocal","date":"2017-02-14T16:00:00.000Z","updated":"2018-01-13T02:29:22.233Z","comments":true,"path":"2017/02/15/2017_ThreadLocal/","link":"","permalink":"http://zj2626.github.io/2017/02/15/2017_ThreadLocal/","excerpt":"http://blog.csdn.net/lufeng20/article/details/24314381 ThreadLocal是什么 早在JDK 1.2的版本中就提供Java.lang.ThreadLocal，ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。 当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。 从线程的角度看，目标变量就象是线程的本地变量，这也是类名中“Local”所要表达的意思。 所以，在Java中编写线程局部变量的代码相对来说要笨拙一些，因此造成线程局部变量没有在Java开发者中得到很好的普及。ThreadLocal的接口方法ThreadLocal类接口很简单，只有4个方法，我们先来了解一下：void set(Object value)设置当前线程的线程局部变量的值。public Object get()该方法返回当前线程所对应的线程局部变量。public void remove()将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。protected Object initialValue()返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。 值得一提的是，在JDK5.0中，ThreadLocal已经支持泛型，该类的类名已经变为ThreadLocal。API方法也相应进行了调整，新版本的API方法分别是void set(T value)、T get()以及T initialValue()。 ThreadLocal是如何做到为每一个线程维护变量的副本的呢？其实实现的思路很简单：在ThreadLocal类中有一个Map，用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值对应线程的变量副本。我们自己就可以提供一个简单的实现版本：[java] view plain copy print?在CODE上查看代码片派生到我的代码片","text":"http://blog.csdn.net/lufeng20/article/details/24314381 ThreadLocal是什么 早在JDK 1.2的版本中就提供Java.lang.ThreadLocal，ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。 当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。 从线程的角度看，目标变量就象是线程的本地变量，这也是类名中“Local”所要表达的意思。 所以，在Java中编写线程局部变量的代码相对来说要笨拙一些，因此造成线程局部变量没有在Java开发者中得到很好的普及。ThreadLocal的接口方法ThreadLocal类接口很简单，只有4个方法，我们先来了解一下：void set(Object value)设置当前线程的线程局部变量的值。public Object get()该方法返回当前线程所对应的线程局部变量。public void remove()将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。protected Object initialValue()返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。 值得一提的是，在JDK5.0中，ThreadLocal已经支持泛型，该类的类名已经变为ThreadLocal。API方法也相应进行了调整，新版本的API方法分别是void set(T value)、T get()以及T initialValue()。 ThreadLocal是如何做到为每一个线程维护变量的副本的呢？其实实现的思路很简单：在ThreadLocal类中有一个Map，用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值对应线程的变量副本。我们自己就可以提供一个简单的实现版本：[java] view plain copy print?在CODE上查看代码片派生到我的代码片 package com.test; public class TestNum { // ①通过匿名内部类覆盖ThreadLocal的initialValue()方法，指定初始值 private static ThreadLocal&lt;Integer&gt; seqNum = new ThreadLocal&lt;Integer&gt;() { public Integer initialValue() { return 0; } }; // ②获取下一个序列值 public int getNextNum() { seqNum.set(seqNum.get() + 1); return seqNum.get(); } public static void main(String[] args) { TestNum sn = new TestNum(); // ③ 3个线程共享sn，各自产生序列号 TestClient t1 = new TestClient(sn); TestClient t2 = new TestClient(sn); TestClient t3 = new TestClient(sn); t1.start(); t2.start(); t3.start(); } private static class TestClient extends Thread { private TestNum sn; public TestClient(TestNum sn) { this.sn = sn; } public void run() { for (int i = 0; i &lt; 3; i++) { // ④每个线程打出3个序列值 System.out.println(&quot;thread[&quot; + Thread.currentThread().getName() + &quot;] --&gt; sn[&quot; + sn.getNextNum() + &quot;]&quot;); } } } } 通常我们通过匿名内部类的方式定义ThreadLocal的子类，提供初始的变量值，如例子中①处所示。TestClient线程产生一组序列号，在③处，我们生成3个TestClient，它们共享同一个TestNum实例。运行以上代码，在控制台上输出以下的结果：thread[Thread-0] –&gt; sn[1]thread[Thread-1] –&gt; sn[1]thread[Thread-2] –&gt; sn[1]thread[Thread-1] –&gt; sn[2]thread[Thread-0] –&gt; sn[2]thread[Thread-1] –&gt; sn[3]thread[Thread-2] –&gt; sn[2]thread[Thread-0] –&gt; sn[3]thread[Thread-2] –&gt; sn[3]考察输出的结果信息，我们发现每个线程所产生的序号虽然都共享同一个TestNum实例，但它们并没有发生相互干扰的情况，而是各自产生独立的序列号，这是因为我们通过ThreadLocal为每一个线程提供了单独的副本。 Thread同步机制的比较 ThreadLocal和线程同步机制相比有什么优势呢？ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。 在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。 由于ThreadLocal中可以持有任何类型的对象，低版本JDK所提供的get()返回的是Object对象，需要强制类型转换。但JDK 5.0通过泛型很好的解决了这个问题，在一定程度地简化ThreadLocal的使用，代码清单 9 2就使用了JDK 5.0新的ThreadLocal版本。 概括起来说，对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 spring使用ThreadLocal解决线程安全问题我们知道在一般情况下，只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域。就是因为Spring对一些Bean（如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等）中非线程安全状态采用ThreadLocal进行处理，让它们也成为线程安全的状态，因为有状态的Bean就可以在多线程中共享了。 一般的Web应用划分为展现层、服务层和持久层三个层次，在不同的层中编写对应的逻辑，下层通过接口向上层开放功能调用。在一般情况下，从接收请求到返回响应所经过的所有程序调用都同属于一个线程，如图9‑2所示：通通透透理解ThreadLocal 同一线程贯通三层这样你就可以根据需要，将一些非线程安全的变量以ThreadLocal存放，在同一次请求响应的调用线程中，所有关联的对象引用到的都是同一个变量。 下面的实例能够体现Spring对有状态Bean的改造思路：代码清单3 TestDao：非线程安全[java] view plain copy print?在CODE上查看代码片派生到我的代码片 package com.test; import java.sql.Connection; import java.sql.SQLException; import java.sql.Statement; public class TestDao { private Connection conn;// ①一个非线程安全的变量 public void addTopic() throws SQLException { Statement stat = conn.createStatement();// ②引用非线程安全变量 // … } } 由于①处的conn是成员变量，因为addTopic()方法是非线程安全的，必须在使用时创建一个新TopicDao实例（非singleton）。下面使用ThreadLocal对conn这个非线程安全的“状态”进行改造：代码清单4 TestDao：线程安全 package com.test; import java.sql.Connection; import java.sql.SQLException; import java.sql.Statement; public class TestDaoNew { // ①使用ThreadLocal保存Connection变量 private static ThreadLocal&lt;Connection&gt; connThreadLocal = new ThreadLocal&lt;Connection&gt;(); public static Connection getConnection() { // ②如果connThreadLocal没有本线程对应的Connection创建一个新的Connection， // 并将其保存到线程本地变量中。 if (connThreadLocal.get() == null) { Connection conn = getConnection(); connThreadLocal.set(conn); return conn; } else { return connThreadLocal.get();// ③直接返回线程本地变量 } } public void addTopic() throws SQLException { // ④从ThreadLocal中获取线程对应的Connection Statement stat = getConnection().createStatement(); } } 不同的线程在使用TopicDao时，先判断connThreadLocal.get()是否是null，如果是null，则说明当前线程还没有对应的Connection对象，这时创建一个Connection对象并添加到本地线程变量中；如果不为null，则说明当前的线程已经拥有了Connection对象，直接使用就可以了。这样，就保证了不同的线程使用线程相关的Connection，而不会使用其它线程的Connection。因此，这个TopicDao就可以做到singleton共享了。当然，这个例子本身很粗糙，将Connection的ThreadLocal直接放在DAO只能做到本DAO的多个方法共享Connection时不发生线程安全问题，但无法和其它DAO共用同一个Connection，要做到同一事务多DAO共享同一Connection，必须在一个共同的外部类使用ThreadLocal保存Connection。 ConnectionManager.java package com.test; import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; public class ConnectionManager { private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() { @Override protected Connection initialValue() { Connection conn = null; try { conn = DriverManager.getConnection( &quot;jdbc:mysql://localhost:3306/test&quot;, &quot;username&quot;, &quot;password&quot;); } catch (SQLException e) { e.printStackTrace(); } return conn; } }; public static Connection getConnection() { return connectionHolder.get(); } public static void setConnection(Connection conn) { connectionHolder.set(conn); } } java.lang.ThreadLocal的具体实现那么到底ThreadLocal类是如何实现这种“为每个线程提供不同的变量拷贝”的呢？先来看一下ThreadLocal的set()方法的源码是如何实现的：[java] view plain copy print?在CODE上查看代码片派生到我的代码片 /** * Sets the current thread&apos;s copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the {@link #initialValue} * method to set the values of thread-locals. * * @param value the value to be stored in the current thread&apos;s copy of * this thread-local. */ public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } 在这个方法内部我们看到，首先通过getMap(Thread t)方法获取一个和当前线程相关的ThreadLocalMap，然后将变量的值设置到这个ThreadLocalMap对象中，当然如果获取到的ThreadLocalMap对象为空，就通过createMap方法创建。 线程隔离的秘密，就在于ThreadLocalMap这个类。ThreadLocalMap是ThreadLocal类的一个静态内部类，它实现了键值对的设置和获取（对比Map对象来理解），每个线程中都有一个独立的ThreadLocalMap副本，它所存储的值，只能被当前线程读取和修改。ThreadLocal类通过操作每一个线程特有的ThreadLocalMap副本，从而实现了变量访问在不同线程中的隔离。因为每个线程的变量都是自己特有的，完全不会有并发错误。还有一点就是，ThreadLocalMap存储的键值对中的键是this对象指向的ThreadLocal对象，而值就是你所设置的对象了。 为了加深理解，我们接着看上面代码中出现的getMap和createMap方法的实现：[java] view plain copy print?在CODE上查看代码片派生到我的代码片 /** * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ ThreadLocalMap getMap(Thread t) { return t.threadLocals; } /** * Create the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @param firstValue value for the initial entry of the map * @param map the map to store. */ void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } 接下来再看一下ThreadLocal类中的get()方法:[java] view plain copy print?在CODE上查看代码片派生到我的代码片 /** * Returns the value in the current thread&apos;s copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the {@link #initialValue} method. * * @return the current thread&apos;s value of this thread-local */ public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) return (T)e.value; } return setInitialValue(); } 再来看setInitialValue()方法： /** * Variant of set() to establish initialValue. Used instead * of set() in case user has overridden the set() method. * * @return the initial value */ private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; } 获取和当前线程绑定的值时，ThreadLocalMap对象是以this指向的ThreadLocal对象为键进行查找的，这当然和前面set()方法的代码是相呼应的。 进一步地，我们可以创建不同的ThreadLocal实例来实现多个变量在不同线程间的访问隔离，为什么可以这么做？因为不同的ThreadLocal对象作为不同键，当然也可以在线程的ThreadLocalMap对象中设置不同的值了。通过ThreadLocal对象，在多线程中共享一个值和多个值的区别，就像你在一个HashMap对象中存储一个键值对和多个键值对一样，仅此而已。 小结 ThreadLocal是解决线程安全问题一个很好的思路，它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。ConnectionManager.java package com.test; import java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; public class ConnectionManager { private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() { @Override protected Connection initialValue() { Connection conn = null; try { conn = DriverManager.getConnection( &quot;jdbc:mysql://localhost:3306/test&quot;, &quot;username&quot;, &quot;password&quot;); } catch (SQLException e) { e.printStackTrace(); } return conn; } }; public static Connection getConnection() { return connectionHolder.get(); } public static void setConnection(Connection conn) { connectionHolder.set(conn); } }","categories":[{"name":"多线程","slug":"多线程","permalink":"http://zj2626.github.io/categories/多线程/"}],"tags":[{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://zj2626.github.io/tags/ThreadLocal/"}]},{"title":"dbcp, c3p0, druid工具类","slug":"2017_dcd","date":"2017-02-13T16:00:00.000Z","updated":"2018-01-13T02:29:22.240Z","comments":true,"path":"2017/02/14/2017_dcd/","link":"","permalink":"http://zj2626.github.io/2017/02/14/2017_dcd/","excerpt":"DBCP工具类 public class DBCPUtils { private static DataSource dataSource = null; static { Properties properties = new Properties(); try { properties.load(DBCPUtils.class.getClassLoader().getResourceAsStream(\"com/jdbc/jdbc.properties\")); dataSource = BasicDataSourceFactory.createDataSource(properties); } catch (Exception e) { e.printStackTrace(); } } public DBCPUtils() { } public static Connection getConnetcion(){ Connection connection = null; try { connection = dataSource.getConnection(); } catch (SQLException e) { e.printStackTrace(); } return connection; } public static void releaseConnecion(Connection connection){ if(null != connection){ try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } }","text":"DBCP工具类 public class DBCPUtils { private static DataSource dataSource = null; static { Properties properties = new Properties(); try { properties.load(DBCPUtils.class.getClassLoader().getResourceAsStream(\"com/jdbc/jdbc.properties\")); dataSource = BasicDataSourceFactory.createDataSource(properties); } catch (Exception e) { e.printStackTrace(); } } public DBCPUtils() { } public static Connection getConnetcion(){ Connection connection = null; try { connection = dataSource.getConnection(); } catch (SQLException e) { e.printStackTrace(); } return connection; } public static void releaseConnecion(Connection connection){ if(null != connection){ try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } } #驱动 driverClassName=com.mysql.jdbc.Driver #数据库连接地址 url=jdbc:mysql://127.0.0.1:3306/test?zeroDateTimeBehavior=convertToNull&amp;useUnicode=true&amp;characterEncoding=UTF-8 #用户名 username=root #密码 password=anyao112233 #初始化连接 initialSize=10 #连接池的最大数据库连接数。设为0表示无限制 maxTotal=50 ##最小空闲连接 minIdle=10 #最大空闲数，数据库连接的最大空闲数。超过空闲时间，数据库连接将被标记为不可用，然后被释放。设为0表示无限制 #空闲连接:意思就是连接了数据库而最大的没有向数据库发送请求的连接 maxIdle=50 #超过时间限制，回收没有用(废弃)的连接（默认为 300秒） 以秒为单位 removeAbandonedTimeout=60 #超过removeAbandonedTimeout时间后，是否进行没用连接（废弃）的回收（默认为false，调整为true) removeAbandoned=true #最大建立连接等待时间 超过此时间将异常 设为-1表示无限制 以毫秒为单位 maxWaitMillis=60000 #在空闲连接回收器线程运行期间休眠的时间值,以毫秒为单位. 如果设置为非正数,则不运行空闲连接回收器线程(每60秒运行一次空闲连接回收器) timeBetweenEvictionRunsMillis=60000 #连接在池中保持空闲而不被空闲连接回收器线程(如果有)回收的最小时间值，单位毫秒(池中的连接空闲30s后被回收,默认值就是30分钟) minEvictableIdleTimeMillis=300000 C3P0工具类 public class C3P0Utils { private static DataSource dataSource = null; private static ThreadLocal threadLocal = new ThreadLocal(); static { //自动加载src下c3p0的配置文件【c3p0-config.xml】 dataSource = new ComboPooledDataSource(\"myApp\"); } public C3P0Utils() { } public static void beginTransaction(Connection connection) { try { connection.setAutoCommit(false); } catch (SQLException e) { e.printStackTrace(); } } public static void commitTransaction(Connection connection) { try { connection.commit(); } catch (SQLException e) { e.printStackTrace(); } } public static Connection getConnetcion() { Connection connection = threadLocal.get();//得到当前线程上绑定的连接 try { if (connection == null || !connection.isClosed()) { //当前没有绑定连接 connection = dataSource.getConnection();//新建连接 threadLocal.set(connection);//将局部变量connection的值设置为conn } } catch (SQLException e) { e.printStackTrace(); } return connection; } public static void releaseConnecion() { Connection connection = threadLocal.get(); try { if (null != connection && !connection.isClosed()) { connection.close(); //从线程局部变量中移除conn，如果没有移除掉，下次还会用这个已经关闭的连接，就会出错 threadLocal.remove(); } } catch (SQLException e) { e.printStackTrace(); } } } &lt;c3p0-config&gt; &lt;default-config&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;anyao112233&lt;/property&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/test&lt;/property&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;maxIdleTime&quot;&gt;30&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;100&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;10&lt;/property&gt; &lt;/default-config&gt; &lt;named-config name=&quot;myApp&quot;&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;anyao112233&lt;/property&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/test&lt;/property&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;maxIdleTime&quot;&gt;30&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;100&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;10&lt;/property&gt; &lt;/named-config&gt; &lt;/c3p0-config&gt; DRUID工具类","categories":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/categories/JDBC/"}],"tags":[{"name":"DBCP","slug":"DBCP","permalink":"http://zj2626.github.io/tags/DBCP/"},{"name":"C3P0","slug":"C3P0","permalink":"http://zj2626.github.io/tags/C3P0/"},{"name":"DRUID","slug":"DRUID","permalink":"http://zj2626.github.io/tags/DRUID/"},{"name":"工具类","slug":"工具类","permalink":"http://zj2626.github.io/tags/工具类/"}]},{"title":"c3p0参数解释(转载)","slug":"2017_c3p0","date":"2017-02-13T16:00:00.000Z","updated":"2018-01-13T02:29:22.237Z","comments":true,"path":"2017/02/14/2017_c3p0/","link":"","permalink":"http://zj2626.github.io/2017/02/14/2017_c3p0/","excerpt":"http://blog.csdn.net/xb12369/article/details/41517409 #最常用配置 #initialPoolSize：连接池初始化时创建的连接数,default : 3，取值应在minPoolSize与maxPoolSize之间c3p0.initialPoolSize=10 #minPoolSize：连接池保持的最小连接数,default : 3c3p0.minPoolSize=10 #maxPoolSize：连接池中拥有的最大连接数，如果获得新连接时会使连接总数超过这个值则不会再获取新连接，而是等待其他连接释放，所以这个值有可能会设计地很大,default : 15c3p0.maxPoolSize=50 #acquireIncrement：连接池在无空闲连接可用时一次性创建的新数据库连接数,default : 3c3p0.acquireIncrement=5","text":"http://blog.csdn.net/xb12369/article/details/41517409 #最常用配置 #initialPoolSize：连接池初始化时创建的连接数,default : 3，取值应在minPoolSize与maxPoolSize之间c3p0.initialPoolSize=10 #minPoolSize：连接池保持的最小连接数,default : 3c3p0.minPoolSize=10 #maxPoolSize：连接池中拥有的最大连接数，如果获得新连接时会使连接总数超过这个值则不会再获取新连接，而是等待其他连接释放，所以这个值有可能会设计地很大,default : 15c3p0.maxPoolSize=50 #acquireIncrement：连接池在无空闲连接可用时一次性创建的新数据库连接数,default : 3c3p0.acquireIncrement=5 #管理连接池的大小和连接的生存时间 #maxIdleTime：连接的最大空闲时间，如果超过这个时间，某个数据库连接还没有被使用，则会断开掉这个连接。如果为0，则永远不会断开连接,即回收此连接。default : 0 单位 sc3p0.maxIdleTime=600 #idleConnectionTestPeriod：每900秒检查所有连接池中的空闲连接c3p0.idleConnectionTestPeriod=900 #配置PreparedStatement缓存 #连接池为数据源缓存的PreparedStatement的总数。由于PreparedStatement属于单个Connection,所以这个数量应该根据应用中平均连接数乘以每个连接的平均PreparedStatement #来计算。同时maxStatementsPerConnection的配置无效。default : 0（不建议使用）c3p0.maxStatements=500 #连接池为数据源单个Connection缓存的PreparedStatement数，这个配置比maxStatements更有意义，因为它缓存的服务对象是单个数据连接， #如果设置的好，肯定是可以提高性能的。为0的时候不缓存。default : 0（看情况而论）c3p0.maxStatementsPerConnection=30 #重连相关配置 #acquireRetryAttempts：连接池在获得新连接失败时重试的次数，如果小于等于0则无限重试直至连接获得成功。default : 30（建议使用）c3p0.acquireRetryAttempts=5 #acquireRetryDelay:两次连接中间隔时间，单位毫秒，连接池在获得新连接时的间隔时间。default : 1000 单位ms（建议使用）c3p0.acquireRetryDelay=1000 #breakAfterAcquireFailure：如果为true，则当连接获取失败时自动关闭数据源，除非重新启动应用程序。所以一般不用。default : false（不建议使用）c3p0.breakAfterAcquireFailure=false #checkoutTimeout：配置当连接池所有连接用完时应用程序getConnection的等待时间。为0则无限等待直至有其他连接释放或者创建新的连接， #不为0则当时间到的时候如果仍没有获得连接，则会抛出SQLException。其实就是acquireRetryAttempts*acquireRetryDelay。default : 0（与上面两个，有重复，选择其中两个都行）c3p0.checkoutTimeout=100 #其他 #autoCommitOnClose：连接池在回收数据库连接时是否自动提交事务。如果为false，则会回滚未提交的事务，如果为true，则会自动提交事务。default : false（不建议使用）c3p0.autoCommitOnClose=false #c3p0是异步操作的，缓慢的JDBC操作通过帮助进程完成。扩展这些操作可以有效的提升性能 通过多线程实现多个操作同时被执行。Default: 3c3p0.numHelperThreads=10","categories":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/categories/JDBC/"}],"tags":[{"name":"C3P0","slug":"C3P0","permalink":"http://zj2626.github.io/tags/C3P0/"}]},{"title":"dbcp,c3p0,druid简单实例(包含配置介绍)","slug":"2017_three_pools","date":"2017-02-12T16:00:00.000Z","updated":"2018-01-13T02:29:22.262Z","comments":true,"path":"2017/02/13/2017_three_pools/","link":"","permalink":"http://zj2626.github.io/2017/02/13/2017_three_pools/","excerpt":"三种连接池的配置:dbcp、c3p0、druid","text":"三种连接池的配置:dbcp、c3p0、druid dbcp1.硬编码方式 @Test public void testDBCPCode() { //BasicDataSource实现接口DataSource DBCP连接池核心类 BasicDataSource dataSouce = new BasicDataSource(); dataSouce.setDriverClassName(&quot;com.mysql.jdbc.Driver&quot;); //驱动 dataSouce.setUrl(&quot;jdbc:mysql://127.0.0.1:3306/test&quot;); //数据库连接字符串 dataSouce.setUsername(&quot;root&quot;); //数据库用户名 dataSouce.setPassword(&quot;anyao112233&quot;); //数据库密码 dataSouce.setInitialSize(5); //设置初始化连接数 dataSouce.setMaxTotal(5); //设置最大连接数 dataSouce.setMaxWaitMillis(10000); //设置申请连接最大等待时间 dataSouce.setRemoveAbandonedTimeout(60); //设置空闲连接时长 超过就回收没用的连接 Connection connection = null; try { connection = dataSouce.getConnection(); // connection.prepareStatement(&quot;update student set f_name = &apos;fuk&apos; where f_id = 10&quot;).executeUpdate(); System.out.println(connection.getClass() + &quot;\\n&quot; + connection.getMetaData() + &quot;\\n&quot;); } catch (SQLException e) { e.printStackTrace(); } finally { // 关闭 if (connection != null) { try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } } 2.配置方式 文件jdbc.properties #驱动 driverClassName=com.mysql.jdbc.Driver #数据库连接地址 url=jdbc:mysql://127.0.0.1:3306/test?zeroDateTimeBehavior=convertToNull&amp;useUnicode=true&amp;characterEncoding=UTF-8 #用户名 username=root #密码 password=anyao112233 #初始化连接 initialSize=10 #连接池的最大数据库连接数。设为0表示无限制 maxTotal=50 ##最小空闲连接 minIdle=10 #最大空闲数，数据库连接的最大空闲数。超过空闲时间，数据库连接将被标记为不可用，然后被释放。设为0表示无限制 #空闲连接:意思就是连接了数据库而最大的没有向数据库发送请求的连接 maxIdle=50 #超过时间限制，回收没有用(废弃)的连接（默认为 300秒） 以秒为单位 removeAbandonedTimeout=60 #超过removeAbandonedTimeout时间后，是否进行没用连接（废弃）的回收（默认为false，调整为true) removeAbandoned=true #最大建立连接等待时间 超过此时间将异常 设为-1表示无限制 以毫秒为单位 maxWaitMillis=60000 #在空闲连接回收器线程运行期间休眠的时间值,以毫秒为单位. 如果设置为非正数,则不运行空闲连接回收器线程(每60秒运行一次空闲连接回收器) timeBetweenEvictionRunsMillis=60000 #连接在池中保持空闲而不被空闲连接回收器线程(如果有)回收的最小时间值，单位毫秒(池中的连接空闲30s后被回收,默认值就是30分钟) minEvictableIdleTimeMillis=300000 @Test public void testDBCPXML() throws Exception { Connection connection = null; try { Properties prop = new Properties(); InputStream inStream = this.getClass().getClassLoader() .getResourceAsStream(&quot;jdbc.properties&quot;); prop.load(inStream); System.out.println(prop); // 根据prop配置，直接创建数据源对象(BasicDataSourceFactory工厂) DataSource dataSouce = BasicDataSourceFactory.createDataSource(prop); // 获取连接 connection = dataSouce.getConnection(); // connection.prepareStatement(&quot;delete from student where f_id=1&quot;).executeUpdate(); } catch (SQLException e) { e.printStackTrace(); } finally { // 关闭 if (connection != null) { try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } } C3P01.硬编码方式@Test public void testC3P0Code() throws Exception { // 创建连接池核心工具类 ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setJdbcUrl(&quot;jdbc:mysql://localhost:3306/test&quot;); dataSource.setDriverClass(&quot;com.mysql.jdbc.Driver&quot;); dataSource.setUser(&quot;root&quot;); dataSource.setPassword(&quot;anyao112233&quot;); dataSource.setInitialPoolSize(3);//连接池初始化时创建的连接数 dataSource.setMaxPoolSize(6);//连接池中拥有的最大连接数 dataSource.setMaxIdleTime(1000); Connection connection = null; try { connection = dataSource.getConnection(); connection.prepareStatement(&quot;delete from student where f_name like &apos;%name%&apos;&quot;).executeUpdate(); } catch (SQLException e) { e.printStackTrace(); } finally { if (connection != null) { try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } } 2.配置方式&lt;c3p0-config&gt; &lt;default-config&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;anyao112233&lt;/property&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/test&lt;/property&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;maxIdleTime&quot;&gt;30&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;100&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;10&lt;/property&gt; &lt;/default-config&gt; &lt;named-config name=&quot;myApp&quot;&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;anyao112233&lt;/property&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql://localhost:3306/test&lt;/property&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;10&lt;/property&gt; &lt;property name=&quot;maxIdleTime&quot;&gt;30&lt;/property&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;100&lt;/property&gt; &lt;property name=&quot;minPoolSize&quot;&gt;10&lt;/property&gt; &lt;/named-config&gt; &lt;/c3p0-config&gt; @Test public void testC3P0XML() throws Exception { // 创建c3p0连接池核心工具类 // 自动加载src下c3p0的配置文件【c3p0-config.xml】 //如果要使用default-config无需传参数， //如果要使用named-config里面配置初始化数据源，则只要使用一个带参数的ComboPooledDataSource构造器就可以了 DataSource dataSource = new ComboPooledDataSource(&quot;myApp&quot;); Connection connection = null; try { connection = dataSource.getConnection(); connection.prepareStatement(&quot;delete from student where f_id = 20&quot;).executeUpdate(); } catch (SQLException e) { e.printStackTrace(); } finally { if (connection != null) { try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } } DRUID1.硬编码方式2.配置方式","categories":[{"name":"数据库连接池","slug":"数据库连接池","permalink":"http://zj2626.github.io/categories/数据库连接池/"}],"tags":[{"name":"DBCP","slug":"DBCP","permalink":"http://zj2626.github.io/tags/DBCP/"},{"name":"C3P0","slug":"C3P0","permalink":"http://zj2626.github.io/tags/C3P0/"},{"name":"DRUID","slug":"DRUID","permalink":"http://zj2626.github.io/tags/DRUID/"}]},{"title":"DBCP连接池介绍(转载)","slug":"2017_DBCP","date":"2017-02-11T16:00:00.000Z","updated":"2018-01-13T02:29:22.217Z","comments":true,"path":"2017/02/12/2017_DBCP/","link":"","permalink":"http://zj2626.github.io/2017/02/12/2017_DBCP/","excerpt":"文章发表时间: 2014-03-07,现在情况可能不同 http://www.myhack58.com/Article/60/61/2014/42761.htm DBCP连接池介绍 目前 DBCP 有两个版本分别是 1.3 和 1.4。DBCP 1.3 版本需要运行于 JDK 1.4-1.5 ，支持 JDBC 3。DBCP 1.4 版本需要运行于 JDK 1.6 ，支持 JDBC 4。1.3和1.4基于同一套源代码，含有所有的bug修复和新特性。因此在选择DBCP版本的时候，要看你用的是什么JDK版本。DBCP1.2版本性能一般，比c3p0差挺多。DBCP1.4和1.3，配合（依赖）commons pool 1.6的jar包,各方面功能、性能推进到新的高峰。相对1.2版本提高不少。超越(或相当)了c3p0.建议使用DBCP1.4或1.3 + commons pool 1.6 Tomcat7 中保留DBCP连接池，以兼容已有应用。并提供了新的Tomcat JDBC pool作为DBCP的可选替代。新出的Tomcat JDBC pool，据说比DBCP 1.4要好，未接触，也不在本文讨论范围内。 DBCP连接池配置参数讲解","text":"文章发表时间: 2014-03-07,现在情况可能不同 http://www.myhack58.com/Article/60/61/2014/42761.htm DBCP连接池介绍 目前 DBCP 有两个版本分别是 1.3 和 1.4。DBCP 1.3 版本需要运行于 JDK 1.4-1.5 ，支持 JDBC 3。DBCP 1.4 版本需要运行于 JDK 1.6 ，支持 JDBC 4。1.3和1.4基于同一套源代码，含有所有的bug修复和新特性。因此在选择DBCP版本的时候，要看你用的是什么JDK版本。DBCP1.2版本性能一般，比c3p0差挺多。DBCP1.4和1.3，配合（依赖）commons pool 1.6的jar包,各方面功能、性能推进到新的高峰。相对1.2版本提高不少。超越(或相当)了c3p0.建议使用DBCP1.4或1.3 + commons pool 1.6 Tomcat7 中保留DBCP连接池，以兼容已有应用。并提供了新的Tomcat JDBC pool作为DBCP的可选替代。新出的Tomcat JDBC pool，据说比DBCP 1.4要好，未接触，也不在本文讨论范围内。 DBCP连接池配置参数讲解 一、Apache官方DBCP文档给出的配置示例：可参见：http://tomcat.apache.org/tomcat-6.0-doc/jndi-datasource-examples-howto.html 二、常用参数说明：可参见：http://elf8848.iteye.com/blog/337981 &lt;Resource name=&quot;jdbc/TestDB&quot; JNDI数据源的name type=&quot;javax.sql.DataSource&quot; driverClassName=&quot;com.mysql.jdbc.Driver&quot; JDBC驱动类 url=&quot;&quot; username=&quot;&quot; 访问数据库用户名 password=&quot;&quot; 访问数据库的密码 maxActive=&quot;80&quot; 最大活动连接 //我使用版本是2.1,最大连接名称变为maxTotal initialSize=&quot;10&quot; 初始化连接 maxIdle=&quot;60&quot; 最大空闲连接 minIdle=&quot;10&quot; 最小空闲连接 maxWait=&quot;3000&quot; 从池中取连接的最大等待时间，单位ms. validationQuery = &quot;SELECT 1&quot; 验证使用的SQL语句 testWhileIdle = &quot;true&quot; 指明连接是否被空闲连接回收器(如果有)进行检验.如果检测失败,则连接将被从池中去除. testOnBorrow = &quot;false&quot; 借出连接时不要测试，否则很影响性能 timeBetweenEvictionRunsMillis = &quot;30000&quot; 每30秒运行一次空闲连接回收器 minEvictableIdleTimeMillis = &quot;1800000&quot; 池中的连接空闲30分钟后被回收 numTestsPerEvictionRun=&quot;3&quot; 在每次空闲连接回收器线程(如果有)运行时检查的连接数量 removeAbandoned=&quot;true&quot; 连接泄漏回收参数，当可用连接数少于3个时才执行 removeAbandonedTimeout=&quot;180&quot; 连接泄漏回收参数，180秒，泄露的连接可以被删除的超时值 /&gt; DBCP连接池的自我检测 默认配置的DBCP连接池，是不对池中的连接做测试的，有时连接已断开了，但DBCP连接池不知道，还以为连接是好的呢。应用从池中取出这样的连接访问数据库一定会报错。这也是好多人不喜欢DBCP的原因。 问题例一：MySQL8小时问题，Mysql服务器默认连接的“wait_timeout”是8小时，也就是说一个connection空闲超过8个小时，Mysql将自动断开该 connection。但是DBCP连接池并不知道连接已经断开了，如果程序正巧使用到这个已经断开的连接，程序就会报错误。 问题例二： 以前还使用Sybase数据库，由于某种原因，数据库死了后重启、或断网后恢复。 等了约10分钟后，DBCP连接池中的连接还都是不能使用的（断开的），访问数据应用一直报错，最后只能重启Tomcat问题才解决 。 解决方案： 方案1、定时对连接做测试，测试失败就关闭连接。 方案2、控制连接的空闲时间达到N分钟，就关闭连接，（然后可再新建连接）。 以上两个方案使用任意一个就可以解决以述两类问题。如果只使用方案2，建议 N &lt;= 5分钟。连接断开后最多5分钟后可恢复。 也可混合使用两个方案，建议 N = 30分钟。 下面就是DBCP连接池，同时使用了以上两个方案的配置配置 validationQuery = &quot;SELECT 1&quot; 验证连接是否可用，使用的SQL语句 testWhileIdle = &quot;true&quot; 指明连接是否被空闲连接回收器(如果有)进行检验.如果检测失败,则连接将被从池中去除. testOnBorrow = &quot;false&quot; 借出连接时不要测试，否则很影响性能 timeBetweenEvictionRunsMillis = &quot;30000&quot; 每30秒运行一次空闲连接回收器 minEvictableIdleTimeMillis = &quot;1800000&quot; 池中的连接空闲30分钟后被回收,默认值就是30分钟。 numTestsPerEvictionRun=&quot;3&quot; 在每次空闲连接回收器线程(如果有)运行时检查的连接数量，默认值就是3. 解释： 配置timeBetweenEvictionRunsMillis = &quot;30000&quot;后，每30秒运行一次空闲连接回收器（独立纯种）。并每次检查3个连接，如果连接空闲时间超过30分钟就销毁。销毁连接后，连接数量就少了，如果小于minIdle数量，就新建连接，维护数量不少于minIdle，过行了新老更替。 testWhileIdle = &quot;true&quot; 表示每30秒，取出3条连接，使用validationQuery = &quot;SELECT 1&quot; 中的SQL进行测试 ，测试不成功就销毁连接。销毁连接后，连接数量就少了，如果小于minIdle数量，就新建连接。 testOnBorrow = &quot;false&quot; 一定要配置，因为它的默认值是true。false表示每次从连接池中取出连接时，不需要执行validationQuery = &quot;SELECT 1&quot; 中的SQL进行测试。若配置为true,对性能有非常大的影响，性能会下降7-10倍。所在一定要配置为false. 每30秒，取出numTestsPerEvictionRun条连接（本例是3，也是默认值），发出&quot;SELECT 1&quot; SQL语句进行测试 ，测试过的连接不算是“被使用”了，还算是空闲的。连接空闲30分钟后会被销毁。 DBCP连接池配置参数注意事项 maxIdle值与maxActive值应配置的接近。因为，当连接数超过maxIdle值后，刚刚使用完的连接（刚刚空闲下来）会立即被销毁。而不是我想要的空闲M秒后再销毁起一个缓冲作用。这一点DBCP做的可能与你想像的不一样。若maxIdle应与maxActive相差较大，在高负载的系统中会导致频繁的创建、销毁连接，连接数在maxIdle与maxActive间快速频繁波动，这不是我想要的。高负载的系统的maxIdle值可以设置为与maxActive相同或设置为-1(-1表示不限制)，让连接数量在minIdle与maxIdle间缓冲慢速波动。 timeBetweenEvictionRunsMillis建议设置值initialSize=”5”，会在tomcat一启动时，创建5条连接，效果很理想。但同时我们还配置了minIdle=”10”，也就是说，最少要保持10条连接，那现在只有5条连接，哪什么时候再创建少的5条连接呢？1、等业务压力上来了， DBCP就会创建新的连接。2、配置timeBetweenEvictionRunsMillis=“时间”,DBCP会启用独立的工作线程定时检查，补上少的5条连接。销毁多余的连接也是同理。 连接销毁的逻辑 DBCP的连接数会在 0 - minIdle - maxIdle - maxActive 之间变化。变化的逻辑描述如下： 默认未配置initialSize(默认值是0)和timeBetweenEvictionRunsMillis参数时，刚启动tomcat时，连接数是0。当应用有一个并发访问数据库时DBCP创建一个连接。目前连接数量还未达到minIdle，但DBCP也不自动创建新连接已使数量达到minIdle数量（没有一个独立的工作线程来检查和创建）。随着应用并发访问数据库的增多，连接数也增多，但都与minIdle值无关，很快minIdle被超越，minIdle值一点用都没有。直到连接的数量达到maxIdle值，这时的连接都是只增不减的。 再继续发展，连接数再增多并超过maxIdle时，使用完的连接（刚刚空闲下来的）会立即关闭，总体连接的数量稳定在maxIdle但不会超过maxIdle。但活动连接（在使用中的连接）可能数量上瞬间超过maxIdle，但永远不会超过maxActive。这时如果应用业务压力小了，访问数据库的并发少了，连接数也不会减少（没有一个独立的线程来检查和销毁），将保持在maxIdle的数量。 默认未配置initialSize(默认值是0)，但配置了timeBetweenEvictionRunsMillis=“30000”（30秒）参数时，刚启动tomcat时，连接数是0。马上应用有一个并发访问数据库时DBCP创建一个连接。目前连接数量还未达到minIdle，每30秒DBCP的工作线程检查连接数是否少于minIdle数量，若少于就创建新连接直到达到minIdle数量。随着应用并发访问数据库的增多，连接数也增多，直到达到maxIdle值。这期间每30秒DBCP的工作线程检查连接是否空闲了30分钟，若是就销毁。但此时是业务的高峰期，是不会有长达30分钟的空闲连接的，工作线程查了也是白查，但它在工作。到这里连接数量一直是呈现增长的趋势。当连接数再增多超过maxIdle时，使用完的连接(刚刚空闲下来)会立即关闭，总体连接的数量稳定在maxIdle。停止了增长的趋势。但活动连接（在使用中的连接）可能数量上瞬间超过maxIdle，但永远不会超过maxActive。这时如果应用业务压力小了，访问数据库的并发少了，每30秒DBCP的工作线程检查连接(默认每次查3条)是否空闲达到30分钟(这是默认值)，若连接空闲达到30分钟，就销毁连接。这时连接数减少了，呈下降趋势，将从maxIdle走向minIdle。当小于minIdle值时，则DBCP创建新连接已使数量稳定在minIdle，并进行着新老更替。 配置initialSize=“10”时，tomcat一启动就创建10条连接。其它同上。 minIdle要与timeBetweenEvictionRunsMillis配合使用才有用,单独使用minIdle不会起作用。 Tomcat中配置DBCP连接池 Tomcat自带DBCP的包，是$CATALINA_HOME/lib/tomcat-dbcp.jar。omcat-dbcp.jar含有commons pool、commons DBCP两个包的内容。但只含有与连接池有关的类。数据源配置在context.xml文件中， 要在tomcat的lib目录中放jdbc 驱动包数据源配置在server.xml的host中，不需要在tomcat的lib目录中放jdbc 驱动包，只使用工程中的jdbc驱动包 JNDI配置:更改tomcat的server.xml或context.xml 全局的数据源： 如果需要配置全局的 Resource，则在server.xml的GlobalNamingResources节点里加入Resource，再在Context节点里加入ResourceLink的配置。 全局的resource只是为了重用，方便所有该tomcat下的web工程的数据源管理，但如果你的tomcat不会同时加载多个web工程，也就是说一个tomcat只加载一个web工程时，是没有必要配置全局的resource的。 每个web工程一个数据源：在$CATALINA_HOME/conf/context.xml的根节点Context里加入Resource配置。这种配置方法，你在context.xml配置了一个数据源，但Tomcat中有同时运行着5个工程，那了就坏事儿了，这个在Tomcat启动时数据源被创建了5份，每个工程1份数据源。连接数会是你配置的参数的5倍。只有在你的Tomcat只加载一个web工程时,才可以直接以context.xml配置数据源。 12345678910111213&lt;Resource name=\"jdbc/testDB\" //指定的jndi名称，会用于spring数据源bean的配置和ResourceLink的配置 type=\"javax.sql.DataSource\" //数据源床型，使用标准的javax.sql.DataSource driverClassName=\"com.mysql.jdbc.Driver\" //JDBC驱动器 url=\"jdbc:mysql://localhost:3306/test\" //数据库URL地址 username=\"test\" //数据库用户名 password=\"test\" //数据库密码 maxIdle=\"40\" //最大的空闲连接数 maxWait=\"4000\" //当池的数据库连接已经被占用的时候，最大等待时间 maxActive=\"40\" //连接池当中最大的数据库连接 removeAbandoned=\"true\" removeAbandonedTimeout=\"180\" logAbandoned=\"true\" //被丢弃的数据库连接是否做记录，以便跟踪 factory=\"org.apache.tomcat.dbcp.dbcp.BasicDataSourceFactory\" /&gt; 这里的factory指的是该Resource 配置使用的是哪个数据源配置类，这里使用的是tomcat自带的标准数据源Resource配置类，这个类也可以自己写，实现javax.naming.spi.ObjectFactory 接口即可。某些地方使用的commons-dbcp.jar中的org.apache.commons.dbcp.BasicDataSourceFactory，如果使用这个就需把commons-dbcp.jar及其依赖的jar包，都放在tomcat的lib下，光放在工程的WEB-INF/lib下是不够的。 ResourceLink 的配置有多种： 1)tomcat安装目录下的conf/context.xml，把全局的resource直接公开给该tomcat下的所有web工程，在Context节点中加入： 不建议在此文件中，不使用，而使用直接配置数据源，原因上面已说明了。 2)tomcat安装目录下的conf/server.xml，该方法可以指定把哪些source绑定到哪个web工程下。 也可在此文件中，不使用，而使用直接配置数据源。 3)安装目录下的conf/localhost/下建立一个xml文件，文件名是&lt;yourAppName&gt;.xml。比如工程名为test，则该xml名为test.xml。 &lt;?xml version=”1.0” encoding=”UTF-8”?&gt; 也可在此文件中，不使用，而使用直接配置数据源。 4)tomcat安装目录下的\\webapps\\test\\META-INF\\context.xml的Context节点中增加: 也可在此文件中，不使用，而使用直接配置数据源。 本文内容都在tomcat6.0上运行测试过，还下载了commons DBCP的源码，加入了跟踪日志，用于验证本文的理论。","categories":[{"name":"数据库连接池","slug":"数据库连接池","permalink":"http://zj2626.github.io/categories/数据库连接池/"}],"tags":[{"name":"DBCP","slug":"DBCP","permalink":"http://zj2626.github.io/tags/DBCP/"}]},{"title":"数据库连接池作用(转载)","slug":"2017_ljc","date":"2017-02-11T16:00:00.000Z","updated":"2018-01-13T02:29:22.257Z","comments":true,"path":"2017/02/12/2017_ljc/","link":"","permalink":"http://zj2626.github.io/2017/02/12/2017_ljc/","excerpt":"连接池的作用就是为了提高性能。 连接池的作用：连接池是将已经创建好的连接保存在池中， 当有请求来时，直接使用已经创建好的连接对数据库进行访问。 这样省略了创建连接和销毁连接的过程。这样性能上得到了提高。","text":"连接池的作用就是为了提高性能。 连接池的作用：连接池是将已经创建好的连接保存在池中， 当有请求来时，直接使用已经创建好的连接对数据库进行访问。 这样省略了创建连接和销毁连接的过程。这样性能上得到了提高。 基本原理是这样的： （1）建立数据库连接池对象（服务器启动）。 （2）按照事先指定的参数创建初始数量的数据库连接（即：空闲连接数）。 （3）对于一个数据库访问请求，直接从连接池中得到一个连接。如果数据库连接池对象中没有空闲的连接，且连接数没有达到最大（即：最大活跃连接数），创建一个新的数据库连接。 （4）存取数据库。 （5）关闭数据库，释放所有数据库连接（此时的关闭数据库连接，并非真正关闭，而是将其放入空闲队列中。如实际空闲连接数大于初始空闲连接数则释放连接）。 （6）释放数据库连接池对象（服务器停止、维护期间，释放数据库连接池对象，并释放所有连接）。 1 .连接池的概念和为什么要使用连接池？ 连接池放了N个Connection对象，本质上放在内存当中，在内存中划出一块缓存对象， 应用程序每次从池里获得Connection对象，而不是直接从数据里获得，这样不占用服务器的内存资源。 2 .如果不使用连接池会出现的情况： a.占用服务器的内存资源 b.导致服务器的速度非常慢 3 .应用连接池的三种方式： a.自定义连接池 b.使用第三方连接池 c.使用服务器自带的连接池 连接池一般比直接连接更有优越性,因为它提高了性能的同时还保存了宝贵的资源。在整个应用程序的使用过程,当中重复的打开直接连接将导致性能的下降。而池连接只在服务器启动时打开一次，从而消除了这种性能问题。 连接池主要考虑的是性能，每次获取连接和释放连接都有很大的工作量，会对性能有很大影响；而对资源来说起的是反作用，因为保存一定数量的连接是要消耗内存的。应用程序每次从池里获得Connection对象，而不是直接从数据里获得，这样不占用服务器的内存资源。所以一般要建立连接池，而连接的数量要适当，不能太大，太大会过多消耗资源。(所以，考虑2个方面，一个是内存，另一个是资源)。 连接池就是为了避免重复多次的打开数据库连接而造成的性能的下降和系统资源的浪费。","categories":[{"name":"数据库连接池","slug":"数据库连接池","permalink":"http://zj2626.github.io/categories/数据库连接池/"}],"tags":[]},{"title":"Jdbc实现简单的事务处理","slug":"2017_jdbc_transaction","date":"2017-02-09T16:00:00.000Z","updated":"2018-01-13T02:29:22.255Z","comments":true,"path":"2017/02/10/2017_jdbc_transaction/","link":"","permalink":"http://zj2626.github.io/2017/02/10/2017_jdbc_transaction/","excerpt":"","text":"package com.jdbc; import org.junit.Test; import java.io.IOException; import java.sql.*; import java.util.Properties; /** * Created by zj on 2017/2/10. */ public class ACID { /* JDBC实现数据库事务操作 1.原子性(事务不可分割) 2.一致性(一致性状态--&gt;另一个一致性状态) 3.隔离性(类似于加锁, 某一刻一个数据只能被一个事务操作) 4.持久性(事务提交,数据库的改变就是永久的) 要实现 需要多个操作使用同一个连接(Connection) */ @Test public void test() { Connection connection = null; try { connection = getConnection(&quot;update student set f_age = f_age + &quot; + 2 + &quot; where f_id = &quot; + 1, null); connection = getConnection(&quot;update student set f_age = f_age * &quot; + 10 + &quot; where f_id = &quot; + 1, connection); connection.commit();//如果前面的操作都成功,手动提交事务 } catch (SQLException e) { if (connection != null) { try { connection.rollback();//有异常就回滚事务 } catch (SQLException e1) { e1.printStackTrace(); } } } finally { close(connection, null, null);//关闭 } } private Connection getConnection(String sql, Connection connection) throws SQLException { int result; PreparedStatement preparedStatement = null; try { Properties properties = new Properties(); properties.load(this.getClass().getClassLoader().getResourceAsStream(&quot;com/jdbc/jdbc.properties&quot;)); String dirverClass = properties.getProperty(&quot;driver&quot;); String url = properties.getProperty(&quot;jdbc_url&quot;); String user = properties.getProperty(&quot;user&quot;); String password = properties.getProperty(&quot;password&quot;); Class.forName(dirverClass); if (connection == null) { connection = DriverManager.getConnection(url, user, password); //取消自动提交(Connection的默认提交行为) connection.setAutoCommit(false); } preparedStatement = connection.prepareStatement(sql); result = preparedStatement.executeUpdate(); System.out.println(result); } catch (IOException e) { throw new RuntimeException(); } catch (ClassNotFoundException e) { e.printStackTrace(); } finally { close(null, preparedStatement, null); } return connection; } private void close(Connection connection, PreparedStatement statement, ResultSet resultSet) { if (resultSet != null) { try { resultSet.close(); } catch (SQLException e) { e.printStackTrace(); } } if (statement != null) { try { statement.close(); } catch (SQLException e) { e.printStackTrace(); } } if (null != connection) { try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } }","categories":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/categories/JDBC/"}],"tags":[{"name":"事务","slug":"事务","permalink":"http://zj2626.github.io/tags/事务/"}]},{"title":"JDBC把文件作为数据对数据库的操作简单示例(Blob类型)","slug":"2017_jdbc_file","date":"2017-02-09T16:00:00.000Z","updated":"2018-01-13T02:29:22.249Z","comments":true,"path":"2017/02/10/2017_jdbc_file/","link":"","permalink":"http://zj2626.github.io/2017/02/10/2017_jdbc_file/","excerpt":":如果是插入某个文件可以用mysql的Blob类型Blob类型,二进制大对象,用来存储二进制文件(图片等)下面是简单的示例","text":":如果是插入某个文件可以用mysql的Blob类型Blob类型,二进制大对象,用来存储二进制文件(图片等)下面是简单的示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163package com.jdbc;import org.junit.Test;import java.io.*;import java.sql.*;import java.util.Properties;/** * Created by zj on 2017/2/10. */public class insertBlob &#123; @Test public void test() &#123; InputStream inputStream = null; /* 插入BLOB类型数据 (必须使用PreparedStatement) */ try &#123; inputStream = new FileInputStream(\"E:/app/Project/Test_Demo/src/java.jpg\"); insert(\"insert into teacher(name, birth, picture) values (?, ?, ?)\", \"fucc\", new Date(System.currentTimeMillis()), inputStream); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /* 查询并展示Blob类型数据 */ query(\"SELECT id id, name name, birth birth, picture picture FROM teacher WHERE id = ?\", 442); &#125; //插入方法(其实删除,修改也可以使用) //插入Blob类型(mysql)需要传入InputStream类型 public int insert(String sql, Object... args) &#123; Connection connection = null; PreparedStatement state = null; int result = 0; try &#123; connection = getConnection(); state = connection.prepareStatement(sql); for (int i = 0; i &lt; args.length; i++) &#123; //专门用来设置blob类型的方法是state.setBlob(InputStream inputstream); state.setObject(i + 1, args[i]); //遍历设置占位符的值 &#125; result = state.executeUpdate(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; finally &#123; close(connection, state, null); &#125; return result; &#125; //读取 读取Blob类型时, 需要用InputStream类型接收在用OutputStream读取到文件中方可访问 public void query(String sql, Object... args) &#123; Connection connection = null; PreparedStatement state = null; ResultSet resultSet = null; InputStream inputStream = null; OutputStream outputStream = null; try &#123; connection = getConnection(); state = connection.prepareStatement(sql); for (int i = 0; i &lt; args.length; i++) &#123; //专门用来设置blob类型的方法是state.setBlob(InputStream inputstream); state.setObject(i + 1, args[i]); //遍历设置占位符的值 &#125; resultSet = state.executeQuery(); while (resultSet.next()) &#123; int id = resultSet.getInt(1); String name = resultSet.getString(2); Date date = resultSet.getDate(3); Blob picture = resultSet.getBlob(4); System.out.println(id + \" \" + name + \" \" + date + \" \" + picture); //读取文件(Blob-&gt;InputStream-&gt;OutputStream-&gt;文件) inputStream = picture.getBinaryStream(); outputStream = new FileOutputStream(\"pic.jpg\"); byte[] bytes = new byte[50]; int len; while ((len = inputStream.read(bytes)) != -1) &#123; outputStream.write(bytes, 0, len); &#125; &#125; &#125; catch (SQLException | IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if(outputStream != null)&#123; try &#123; outputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if(inputStream != null)&#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; close(connection, state, resultSet); &#125; &#125; private Connection getConnection() &#123; Connection connection = null; try &#123; Properties properties = new Properties(); //读取文件中的数据库配置信息赋值给各个变量 properties.load(this.getClass().getClassLoader().getResourceAsStream(\"com/jdbc/jdbc.properties\")); String dirverClass = properties.getProperty(\"driver\"); String url = properties.getProperty(\"jdbc_url\"); String user = properties.getProperty(\"user\"); String password = properties.getProperty(\"password\"); Class.forName(dirverClass); connection = DriverManager.getConnection(url, user, password); &#125; catch (SQLException | IOException | ReflectiveOperationException e) &#123; e.printStackTrace(); &#125; return connection; &#125; private void close(Connection connection, PreparedStatement statement, ResultSet resultSet) &#123; if (resultSet != null) &#123; try &#123; resultSet.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (statement != null) &#123; try &#123; statement.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (null != connection) &#123; try &#123; connection.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;","categories":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/categories/JDBC/"}],"tags":[{"name":"Blob","slug":"Blob","permalink":"http://zj2626.github.io/tags/Blob/"}]},{"title":"Linux命令","slug":"2017_Linux","date":"2017-02-08T16:00:00.000Z","updated":"2018-01-13T02:29:22.226Z","comments":true,"path":"2017/02/09/2017_Linux/","link":"","permalink":"http://zj2626.github.io/2017/02/09/2017_Linux/","excerpt":"","text":"不停更新ing 贴一个搜索命令的网站 http://man.linuxde.net/ 1.各版本Linux安装命令 2.目录处理及文件处理命令 3.帮助命令 4.压缩命令 5.关机,重启与用户查看命令 6.挂载命令 7.挂载命令 8.Shell常用命令1.执行脚本2.别名与快捷键3.历史命令4.输出重定向5.管道符6.管通配","categories":[{"name":"Linux","slug":"Linux","permalink":"http://zj2626.github.io/categories/Linux/"}],"tags":[{"name":"常用命令","slug":"常用命令","permalink":"http://zj2626.github.io/tags/常用命令/"},{"name":"shell","slug":"shell","permalink":"http://zj2626.github.io/tags/shell/"}]},{"title":"JDBC工具类-利用java反射机制","slug":"2017_jdbc_reflect","date":"2017-02-07T16:00:00.000Z","updated":"2021-03-10T13:50:15.249Z","comments":true,"path":"2017/02/08/2017_jdbc_reflect/","link":"","permalink":"http://zj2626.github.io/2017/02/08/2017_jdbc_reflect/","excerpt":"利用java反射机制,动态进行数据库操作 可以对不同的表(对应相应的实体类)进行数据库操作而不需要修改操作代码 查询得到的数据通过反射机制已经动态赋值到实体对象中","text":"利用java反射机制,动态进行数据库操作 可以对不同的表(对应相应的实体类)进行数据库操作而不需要修改操作代码 查询得到的数据通过反射机制已经动态赋值到实体对象中 package com.jdbc; import org.junit.Test; import java.io.IOException; import java.lang.reflect.Field; import java.sql.*; import java.util.*; /** * Created by zj2626 on 17-1-19. */ public class utilsTest { @Test public void test() {&lt;img src=&quot;http://www.zj2626.github.io/wp-content/uploads/2017/02/jdbc-300x115.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;115&quot; class=&quot;alignnone size-medium wp-image-233&quot; /&gt; /** * 带占位符和别名的sql语句 查询 * 别名是为了匹配数据库中字段名与实体类中属性的差异(如数据库表中列f_id对应类中id属性) */ String sql = &quot;SELECT f_id id, f_name name, f_age age FROM student WHERE f_id = ?&quot;; List&lt;Student&gt; list = query(Student.class, sql, 122); System.out.println(list != null ? &quot;查询到的数据有&quot; + list.size() + &quot;条&quot; : &quot;没查到!!!&quot;); } //&lt;T&gt; List&lt;T&gt;中第一个T是泛型的声明,使T有意义,表示这是一个泛型方法 // (即告诉人们T代表任意类型,每次只能表示一个类型) private &lt;T&gt; List&lt;T&gt; query(Class&lt;T&gt; clazz, String sql, Object... args) {//使用可变参数表示查询条件 List&lt;T&gt; list = new ArrayList&lt;T&gt;(); //用来存放查询到的结果 Connection connection = null; PreparedStatement state = null; ResultSet resultSet = null; try { Properties properties = new Properties(); //读取文件中的数据库配置信息赋值给各个变量 properties.load(this.getClass().getClassLoader().getResourceAsStream(&quot;com/jdbc/jdbc.properties&quot;)); String dirverClass = properties.getProperty(&quot;driver&quot;); String url = properties.getProperty(&quot;jdbc_url&quot;); String user = properties.getProperty(&quot;user&quot;); String password = properties.getProperty(&quot;password&quot;); Class.forName(dirverClass); connection = DriverManager.getConnection(url, user, password); state = connection.prepareStatement(sql); for (int i = 0; i &lt; args.length; i++) { state.setObject(i + 1, args[i]); //遍历设置占位符的值 } /* 查询过程: 1.先利用sql语句进行查询 2.利用反射新建类的实体 3.获得sql语句中的别名,(tongg ResultSet的元数据对象--ReslutSetMetaData,其可以从结果集中获得所有信息,包括列名,别名等) 4.确定别名对应的属性并赋值给属性 */ resultSet = state.executeQuery();//查询并返回结果集 ResultSetMetaData metaData = resultSet.getMetaData();//得到结果集的元数据对象 while (resultSet.next()) { //利用反射新建类的实体 T entity = null; int len = metaData.getColumnCount(); for (int i = 0; i &lt; len; i++) { String columnName = metaData.getColumnName(i + 1);//遍历查看列名(这里并没用到) String columnLabel = metaData.getColumnLabel(i + 1);//遍历获取列的别名 System.out.println(columnName + &quot;--&quot; + columnLabel); Object columnValue = resultSet.getObject(columnLabel);//获取指定别名的列所对应的值 entity = clazz.newInstance();//newInstance()调用newInstance()必须有无参构造方法 //获取类的指定属性(一切皆对象,属性也是对象,都是Field类的实例) // Field field = clazz.getDeclaredField(columnLabel);//注:getField只能获得public字段 // field.setAccessible(true);//设置为可访问(属性为private 不能直接赋值) // field.set(entity, columnValue);//为指定的属性赋值 //赋值方法2: 以上三行的赋值功能可以用apache提供的一个工具类实现 BeanUtils.setProperty(entity, columnLabel, columnValue);//该方法是通过实体中的属性的setter方法实现的 } list.add(entity); } } catch (SQLException | IOException | ReflectiveOperationException e) { e.printStackTrace(); } finally { close(connection, state, resultSet); } return list; } private void close(Connection connection, PreparedStatement statement, ResultSet resultSet) { if (resultSet != null) { try { resultSet.close(); } catch (SQLException e) { e.printStackTrace(); } } if (statement != null) { try { statement.close(); } catch (SQLException e) { e.printStackTrace(); } } if (null != connection) { try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } } 注:如果是插入一条或者多条数据可以用下面的过程获取到插入后自动生成的主键()//上面是获取connection创建PreparedStatement对象 state.executeUpdate(); //获取生成的新所有主键 //返回的resultSet中只有一列--&gt; 列名:GENERATED_KEY resultSet = state.getGeneratedKeys(); while (resultSet.next()) { System.out.println(resultSet.getObject(1)); }","categories":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/categories/JDBC/"}],"tags":[{"name":"工具类","slug":"工具类","permalink":"http://zj2626.github.io/tags/工具类/"},{"name":"CRUD","slug":"CRUD","permalink":"http://zj2626.github.io/tags/CRUD/"}]},{"title":"重新学习JDBC之获取连接","slug":"2017_jdbc_curd","date":"2017-02-06T16:00:00.000Z","updated":"2018-01-13T02:29:22.247Z","comments":true,"path":"2017/02/07/2017_jdbc_curd/","link":"","permalink":"http://zj2626.github.io/2017/02/07/2017_jdbc_curd/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160package com.jdbc;import org.apache.commons.collections.map.HashedMap;import org.junit.Test;import java.io.IOException;import java.sql.*;import java.util.*;/** * Created by zj2626 on 17-1-19. */public class testUtils &#123; private static Connection connection = null; private static PreparedStatement state = null; private static ResultSet resultSet = null; @Test public void test() &#123; Integer id = 123; String name = \"name\"; Integer age = 20; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); list.add(id); list.add(name); list.add(age); //操作数据库版本一 String sql = \"insert into student(id, name, age) values(\" + id + \", '\" + name + \"', \" + age + \")\"; editWayOne(sql); //操作数据库版本二(可以防止sql注入) String sql2 = \"insert into student(id, name, age) values(?, ?, ?)\"; //editWayTwo(sql2, list); //查询 String sql3 = \"select id, name, age from student where id = ?\"; query(sql3, id); &#125; /** * low版本的增删改方法 (增删改都可用) * * @param sql 普通sql语句 * @return 执行成功的记录的条数 */ private int editWayOne(String sql) &#123; int num = 0; try &#123; getConnection(sql); num = state.executeUpdate(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; finally &#123; close(); &#125; return num; &#125; /** * @param sql 带占位符的sql语句 * @param list 占位符要传入的值 * @return 执行成功的记录的条数 */ private int editWayTwo(String sql, List&lt;Object&gt; list) &#123; int num = 0; try &#123; getConnection(sql); for (int i = 0; i &lt; list.size(); i++) &#123; //这里统一用setObject了 其实应该用相对应类型的方法(setString,setInt,setDate...) state.setObject(i + 1, list.get(i)); &#125; num = state.executeUpdate(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; finally &#123; close(); &#125; return num; &#125; /** * 查询 * * @param sql 查询语句 * @return 返回查询到的所有数据集合 */ private List&lt;Map&lt;String, Object&gt;&gt; query(String sql, Integer id) &#123; List&lt;Map&lt;String, Object&gt;&gt; result = new ArrayList&lt;&gt;(); try &#123; getConnection(sql); state.setObject(1, id); //结果集(ResultSet)是数据中查询结果返回的一种对象 该对象存储了查询出的数据需要遍历取出 resultSet = state.executeQuery(); while (resultSet.next()) &#123;//查看有没有下一条数据 Map&lt;String, Object&gt; map = new HashMap();//存放每条数据的每个查询到的字段 map.put(\"id\", resultSet.getInt(1));//遍历也可以通过resultSet.getInt(\"id\")更明确 map.put(\"name\", resultSet.getString(2)); map.put(\"age\", resultSet.getInt(3)); result.add(map); &#125; System.out.println(\"数据条数\" + result.size()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; finally &#123; close(); &#125; return result; &#125; private void getConnection(String sql) &#123; Properties properties = new Properties(); try &#123; properties.load(this.getClass().getClassLoader().getResourceAsStream(\"com/jdbc/jdbc.properties\")); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; String dirverClass = properties.getProperty(\"driver\"); String url = properties.getProperty(\"jdbc_url\"); String user = properties.getProperty(\"user\"); String password = properties.getProperty(\"password\"); try &#123; Class.forName(dirverClass); connection = DriverManager.getConnection(url, user, password); state = connection.prepareStatement(sql); &#125; catch (SQLException | ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125; private void close() &#123; if (resultSet != null) &#123; try &#123; resultSet.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (state != null) &#123; try &#123; state.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (null != connection) &#123; try &#123; connection.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;","categories":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/categories/JDBC/"}],"tags":[{"name":"工具类","slug":"工具类","permalink":"http://zj2626.github.io/tags/工具类/"},{"name":"CRUD","slug":"CRUD","permalink":"http://zj2626.github.io/tags/CRUD/"}]},{"title":"重新学习JDBC之获取statement","slug":"2017_jdbc_getStatement","date":"2017-02-05T16:00:00.000Z","updated":"2021-03-10T13:50:15.263Z","comments":true,"path":"2017/02/06/2017_jdbc_getStatement/","link":"","permalink":"http://zj2626.github.io/2017/02/06/2017_jdbc_getStatement/","excerpt":"Statement类 获取connection(见 http://www.zj2626.github.io/index.php/2017/02/06/cxxxjdbc/) 之后, 需要获得sql语句并发送然后执行sql语句,所以有了本章","text":"Statement类 获取connection(见 http://www.zj2626.github.io/index.php/2017/02/06/cxxxjdbc/) 之后, 需要获得sql语句并发送然后执行sql语句,所以有了本章 直接看代码 private Connection getConnection(String sql) { Properties properties = new Properties(); try { //获取配置文件中的数据库信息 properties.load(this.getClass().getClassLoader().getResourceAsStream(&quot;com/jdbc/jdbc.properties&quot;)); } catch (IOException e) { e.printStackTrace(); } String dirverClass = properties.getProperty(&quot;driver&quot;); String url = properties.getProperty(&quot;jdbc_url&quot;); String user = properties.getProperty(&quot;user&quot;); String password = properties.getProperty(&quot;password&quot;); Connection connection = null; Statement state = null; try { //加载数据库驱动 Class.forName(dirverClass); //获取数据库连接 connection = DriverManager.getConnection(url, user, password); //获取Statment对象 state = connection.createStatement(); //执行sql语句 state.execute(sql); } catch (SQLException | ClassNotFoundException e) { e.printStackTrace(); } if (state != null) {//关闭statment对象,释放资源 try { state.close(); } catch (SQLException e) { System.out.println(e); } } if (null != connection) {//关闭connction对象,释放资源 try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } } 升级Statement对象创建之后,没执行一次都会重新编译一次sql语句(sql语句是执行时候参数嘛),这很不好所以我们用其子类PreparedStatement 创建时的区别： Statement statement = conn.createStatement(); PreparedStatement preStatement = conn.prepareStatement(sql); 执行的时候: ResultSet rSet = statement.executeQuery(sql); ResultSet pSet = preStatement.executeQuery();看出，PreparedStatement有预编译的过程,已经绑定sql,之后无论执行多少遍,都不会再去进行编译,效率高 private static Connection connection = null; private static PreparedStatement prep = null; private void getConnection(String sql) { Properties properties = new Properties(); try { //获取配置文件中的数据库信息 properties.load(this.getClass().getClassLoader().getResourceAsStream(&quot;com/jdbc/jdbc.properties&quot;)); } catch (IOException e) { e.printStackTrace(); } String dirverClass = properties.getProperty(&quot;driver&quot;); String url = properties.getProperty(&quot;jdbc_url&quot;); String user = properties.getProperty(&quot;user&quot;); String password = properties.getProperty(&quot;password&quot;); try { //加载数据库驱动 Class.forName(dirverClass); //获取数据库连接 connection = DriverManager.getConnection(url, user, password); prep = connection.prepareStatement(sql); prep.execute();//这里是更新操作的事例 如果是查询等其他则调用方法有不同 } catch (SQLException | ClassNotFoundException e) { e.printStackTrace(); } } //执行数据库操作之后必须关闭各个对象(按顺序) public void close(Statement state, Connection connection) { if (state != null) { try { state.close(); } catch (SQLException e) { System.out.println(e); } } if (null != connection) { try { connection.close(); } catch (SQLException e) { e.printStackTrace(); } } }","categories":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/categories/JDBC/"}],"tags":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/tags/JDBC/"}]},{"title":"重新学习JDBC之获取连接","slug":"2017_jdbc_getConnection","date":"2017-02-05T16:00:00.000Z","updated":"2021-03-10T13:50:15.390Z","comments":true,"path":"2017/02/06/2017_jdbc_getConnection/","link":"","permalink":"http://zj2626.github.io/2017/02/06/2017_jdbc_getConnection/","excerpt":"JDBC是一种用于执行sql语句的javaAPI, 为多种关系数据库提供统一访问有java编写的类和接口组成 jdbc其实就是一种规范(基准),根据其可以自己构建更高级的框架,如(hibernate等),编程人员须根据这个规范编写来操作数据库","text":"JDBC是一种用于执行sql语句的javaAPI, 为多种关系数据库提供统一访问有java编写的类和接口组成 jdbc其实就是一种规范(基准),根据其可以自己构建更高级的框架,如(hibernate等),编程人员须根据这个规范编写来操作数据库 &gt;Driver 提供了一个接口 数据库厂商需要自己的产品编写此接口的实现类 通过创建实现类的对象(注册)加载相应的数据库驱动1,原始的jdbc尝试(获取数据库连接) 连接需要某个厂商的数据库驱动包 这里连接mysql官网下载地址 https://dev.mysql.com/downloads/connector/j/ 里面的 mysql-connector-java-.jar文件 @Test public void testDriver() throws SQLException { //创建Driver实现类(这里是mysql的实现类) 同时注册驱动(见下面mysql源码参照1) Driver driver = new com.mysql.jdbc.Driver(); //Properties类用于读取java的配置文件(.properties) 这里并没有读取文件 String url = &quot;jdbc:mysql://127.0.0.1:3306/test&quot;; //数据库地址 Properties properties = new Properties(); properties.put(&quot;user&quot;, &quot;root&quot;); //数据库用户名 properties.put(&quot;password&quot;, &quot;anyao112233&quot;);//数据库密码 //获取数据库连接 返回一个Connection的mysql的实现类 Connection connection = driver.connect(url, properties);//见下面源码参照2 System.out.println(connection); } mysql的源码参照1 package com.mysql.jdbc; //一旦声明了此类的对象就会先调用这里静态代码块中的代码 实现驱动的注册(registerDriver) public class Driver extends NonRegisteringDriver implements java.sql.Driver { public Driver() throws SQLException { } static { try { //其实在注册的时候就已经实例化过一次driver对象 不需要自己new或newInstance //但是,由于此实例化为匿名,so只能自己再实例一遍,以获得实例化的对象 DriverManager.registerDriver(new Driver()); } catch (SQLException var1) { throw new RuntimeException(&quot;Can\\&apos;t register driver!&quot;); } } } mysql的源码参照2 package com.mysql.jdbc; public class NonRegisteringDriver implements Driver { public Connection connect(String url, Properties info) throws SQLException { //检测url是否为空(现在URL是jdbc:mysql://127.0.0.1:3306/test) if(url != null) { //检测url是否以后者开头---否 if(StringUtils.startsWithIgnoreCase(url, &quot;jdbc:mysql:loadbalance://&quot;)) { return this.connectLoadBalanced(url, info); } //检测url是否以后者开头---否 if(StringUtils.startsWithIgnoreCase(url, &quot;jdbc:mysql:replication://&quot;)) { return this.connectReplicationConnection(url, info); } } Properties props = null; //获取url中信息存放到props对象中(HOST,user,password,DBNAME) if((props = this.parseURL(url, info)) == null) { return null; } else { try { //以props中的信息创建数据库连接 返回代表连接的对象 com.mysql.jdbc.Connection ex = ConnectionImpl.getInstance(this.host(props), this.port(props), props, this.database(props), url); //返回连接对象 return ex; //下面是各种异常 } catch (SQLException var6) { throw var6; } catch (Exception var7) { SQLException sqlEx = SQLError.createSQLException(Messages.getString(&quot;NonRegisteringDriver.17&quot;) + var7.toString() + Messages.getString(&quot;NonRegisteringDriver.18&quot;), &quot;08001&quot;); sqlEx.initCause(var7); throw sqlEx; } } } } 各位看官, 自己可以debug调试看看流程 其实也不难看懂,人家的代码都写得很清楚了2,升级版本配置文件内容(如图,地址要加字符编码,防止中文乱码) @Test public void test2() { getConnection(); } //把获取数据库连接封装为一个类,把数据库的信息存放到配置文件中 //原因:一般程序部署以后就不会再更改代码,如果数据有变,就可以只是更改配置文件, // 而要是这些信息放在代码中,则需要重新编译运行才能生效 private Connection getConnection() { String dirverClass; String url; String user; String password; //读取文件 //getClassLoader返回类的类加载器 //getResourceAsStream把指定目录的内容返回到一个输入流中 InputStream inputStream = getClass().getClassLoader().getResourceAsStream(&quot;com/jdbc/jdbc.properties&quot;); Properties properties = new Properties(); try { //读取输入流中的内容到properties对象中 properties.load(inputStream); } catch (IOException e) { e.printStackTrace(); } //按照键值对的形式读取对象中该键所对应的值 获取到数据库信息 dirverClass = properties.getProperty(&quot;driver&quot;); url = properties.getProperty(&quot;jdbc_url&quot;); user = properties.getProperty(&quot;user&quot;); password = properties.getProperty(&quot;password&quot;); Properties info = new Properties(); info.put(&quot;user&quot;, user); info.put(&quot;password&quot;, password); Driver driver; Connection connection = null; try { //forName用于使JVM加载指定的类(全类名,写在配置文件中),即动态加载和创建Class 对象 //所有类都是Class类的对象 //通过刚才加载的Class对象(也就是你需要的)来实例化加载了的所需类的对象,效果同new一个对象 driver = (Driver) Class.forName(dirverClass).newInstance(); //获取连接 connection = driver.connect(url, info); System.out.println(connection); } catch (InstantiationException | IllegalAccessException | ClassNotFoundException | SQLException e) { e.printStackTrace(); } finally { if (connection != null) { try { connection.close();//关闭连接 } catch (SQLException e) { e.printStackTrace(); } } } return null; } 3,再次升级版本此时发现,通过Driver类直接控制数据库连接太麻烦,于是有了DriverManager DriverManager用来管理数据库中所有的驱动程序,把driver的创建,获取连接等过程交由DriverManager管理 @Test public void test() { Properties properties = new Properties(); try { properties.load(this.getClass().getClassLoader().getResourceAsStream(&quot;com/jdbc/jdbc.properties&quot;)); } catch (IOException e) { e.printStackTrace(); } String dirverClass = properties.getProperty(&quot;driver&quot;); String url = properties.getProperty(&quot;jdbc_url&quot;); String user = properties.getProperty(&quot;user&quot;); String password = properties.getProperty(&quot;password&quot;); Connection connection = null; try { //加载数据库驱动 可以多个驱动程序注册(在注册时候就已经实例化了一个对象,不需要自己新建driver对象) Class.forName(dirverClass); //获取数据库连接 //获取的时候会扫描所有的注册的驱动 找到合适的驱动然后获取连接 connection = DriverManager.getConnection(url, user, password); System.out.println(connection); } catch (SQLException | ClassNotFoundException e) { e.printStackTrace(); } }","categories":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/categories/JDBC/"}],"tags":[{"name":"JDBC","slug":"JDBC","permalink":"http://zj2626.github.io/tags/JDBC/"}]},{"title":"jaxp解析xml文档实现增删改查","slug":"2017_jaxp","date":"2017-02-04T16:00:00.000Z","updated":"2018-01-13T02:29:22.244Z","comments":true,"path":"2017/02/05/2017_jaxp/","link":"","permalink":"http://zj2626.github.io/2017/02/05/2017_jaxp/","excerpt":"这是被解析的示例xml1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;&lt;书架&gt; &lt;书&gt; &lt;书名&gt;java实战&lt;/书名&gt; &lt;作者&gt;张三&lt;/作者&gt; &lt;售价&gt;121元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt; &lt;书&gt; &lt;书名 color=\"yellow\" name=\"XXX\"&gt;c测试&lt;/书名&gt; &lt;作者&gt;李四&lt;/作者&gt; &lt;售价 color=\"rrr\"&gt;54元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt;&lt;/书&gt;&lt;/书架&gt; 增加","text":"这是被解析的示例xml1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;&lt;书架&gt; &lt;书&gt; &lt;书名&gt;java实战&lt;/书名&gt; &lt;作者&gt;张三&lt;/作者&gt; &lt;售价&gt;121元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt; &lt;书&gt; &lt;书名 color=\"yellow\" name=\"XXX\"&gt;c测试&lt;/书名&gt; &lt;作者&gt;李四&lt;/作者&gt; &lt;售价 color=\"rrr\"&gt;54元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt;&lt;/书&gt;&lt;/书架&gt; 增加 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package cn.xml;import java.io.FileOutputStream;import java.io.OutputStream;import javax.xml.crypto.dsig.Transform;import javax.xml.parsers.DocumentBuilder;import javax.xml.parsers.DocumentBuilderFactory;import javax.xml.transform.*;import javax.xml.transform.dom.DOMSource;import javax.xml.transform.stream.StreamResult;import org.w3c.dom.Document;import org.w3c.dom.Element;import org.w3c.dom.Node;public class Demo03_xml_add &#123; //4.向XML文档中添加节点 &lt;售价&gt;12元&lt;/售价&gt; public void add() throws Exception&#123; DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.parse(\"src/cn/xml/book.xml\"); //在内存中的xml中创造一个节点 Element price = document.createElement(\"售价\");//得到标签 price.setTextContent(\"12元\");//添加标签中内容 //先得到书节点 转换为标签 Element book = (Element)document.getElementsByTagName(\"书\").item(0); //把创造的节点添加到xml文档中书标签下 book.appendChild(price); //此时只更新了内存中的XML文档(document对象指向的) 所以要把document对象指向的内存中的xml文档更新到硬盘中的xml文档 //更新后的写入XML文档 //创建工厂实例 TransformerFactory tf = TransformerFactory.newInstance(); //通过工厂实例得到Transformer对象(transform方法可以转化来源到目的地) Transformer tr = tf.newTransformer(); //DOMSource是Source的实现类 把Document类型封装为Source类型 Source s = new DOMSource(document); //声明输出流对象 指向硬盘中的XML文件 OutputStream f= new FileOutputStream(\"src/cn/xml/book.xml\"); //把输出流对象通过流方法转化为Result对象 Result对象指向硬盘中的XML文件 Result r = new StreamResult(f); //transform方法(来源, 目的地) 把s写入r tr.transform(s, r); &#125; //5.向XML文档中指定位置添加节点 &lt;售价&gt;999元&lt;/售价&gt; public void add2() throws Exception&#123; DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.parse(\"src/cn/xml/book.xml\"); Element price = document.createElement(\"售价\"); price.setTextContent(\"999元\"); //得到参考节点 即下一个标签(Element是Node的一个子集 Element是Node的扩展) Element refNode = (Element) document.getElementsByTagName(\"售价\").item(1); //得到要插入的节点 Element book = (Element) document.getElementsByTagName(\"书\").item(0); //插入book节点的指定位置 把price节点插入refNode节点之前 book.insertBefore(price, refNode);//参数也可以是标签 TransformerFactory tf = TransformerFactory.newInstance(); Transformer tr = tf.newTransformer(); tr.transform(new DOMSource(document), new StreamResult(new FileOutputStream(\"src/cn/xml/book.xml\"))); &#125; //6.向XML文档中添加属性 public void add3() throws Exception&#123; DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.parse(\"src/cn/xml/book.xml\"); //得到节点 Element bookname = (Element) document.getElementsByTagName(\"书名\").item(0); bookname.setAttribute(\"name\", \"XXX\"); TransformerFactory tf = TransformerFactory.newInstance(); Transformer tr = tf.newTransformer(); tr.transform(new DOMSource(document), new StreamResult(new FileOutputStream(\"src/cn/xml/book.xml\"))); &#125;&#125; 删除 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package cn.xml;import java.io.FileOutputStream;import javax.xml.parsers.DocumentBuilder;import javax.xml.parsers.DocumentBuilderFactory;import javax.xml.transform.Transformer;import javax.xml.transform.TransformerFactory;import javax.xml.transform.dom.DOMSource;import javax.xml.transform.stream.StreamResult;import org.w3c.dom.Document;import org.w3c.dom.Element;public class Demo03_xml_delete &#123; public void delete() throws Exception&#123; DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.parse(\"src/cn/xml/book.xml\"); //得到要删除的节点 Element price = (Element) document.getElementsByTagName(\"售价\").item(2); //得到要删除节点的父节点 Element book = (Element) document.getElementsByTagName(\"书\").item(1); //通过父节点删除子节点 book.removeChild(price); TransformerFactory tf = TransformerFactory.newInstance(); Transformer tr = tf.newTransformer(); tr.transform(new DOMSource(document), new StreamResult(new FileOutputStream(\"src/cn/xml/book.xml\"))); &#125; public void delete2() throws Exception&#123; DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.parse(\"src/cn/xml/book.xml\"); Element price = (Element) document.getElementsByTagName(\"售价\").item(3); //通过子节点得到父节点再删除自己 price.getParentNode().removeChild(price); //其他:通过子节点得到父节点的父节点的父节点 (删除父节点)...删除整个xml文档中的节点 //price.getParentNode().getParentNode().getParentNode().removeChild(price.getParentNode().getParentNode()); //删除指定节点的属性 //price.removeAttribute(\"color\"); TransformerFactory tf = TransformerFactory.newInstance(); Transformer tr = tf.newTransformer(); tr.transform(new DOMSource(document), new StreamResult(new FileOutputStream(\"src/cn/xml/book.xml\"))); &#125;&#125; 更新 12345678910111213141516171819202122232425262728293031package cn.xml;import java.io.FileOutputStream;import java.io.IOException;import javax.xml.parsers.DocumentBuilder;import javax.xml.parsers.DocumentBuilderFactory;import javax.xml.transform.Transformer;import javax.xml.transform.TransformerFactory;import javax.xml.transform.dom.DOMSource;import javax.xml.transform.stream.StreamResult;import org.w3c.dom.Document;import org.w3c.dom.Element;import org.xml.sax.SAXException;public class Demo03_xml_update &#123; public void update() throws Exception&#123; DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.parse(\"src/cn/xml/book.xml\"); Element price = (Element) document.getElementsByTagName(\"售价\").item(1); price.setTextContent(\"123.456元\");//更新标签中内容 price.setAttribute(\"color\", \"eeed\");//更新标签属性 TransformerFactory tf = TransformerFactory.newInstance(); Transformer tr = tf.newTransformer(); tr.transform(new DOMSource(document), new StreamResult(new FileOutputStream(\"src/cn/xml/book.xml\"))); &#125;&#125; 遍历 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package cn.xml;import javax.xml.parsers.DocumentBuilder;import javax.xml.parsers.DocumentBuilderFactory;import org.w3c.dom.Document;import org.w3c.dom.Element;import org.w3c.dom.Node;import org.w3c.dom.NodeList;public class Demo03_xml_read&#123; //使用DOM方式对XML文档进行crud(增删改查) public void read1() throws Exception&#123; //1.创建工厂(得到DOM解析器的工厂实例) ---这个工厂类是抽象类,so用其newInstance方法得到DOM的新实例 DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); //2.从DOM工厂获得DOM解析器 有了这个实例才可以解析 DocumentBuilder builder = factory.newDocumentBuilder(); //3.将给定URI的内容解析为一个XML文档，并且返回一个新的DOM Document对象 Document document = builder.parse(\"src/cn/xml/book.xml\"); //4.以后的处理都是对Document对象进行的 //1.读取XML文档中&lt;书名&gt;....&lt;/书名&gt;节点中的值 NodeList list = document.getElementsByTagName(\"书名\");//按文档顺序返回包含在文档中且具有给定标记名称的所有 Element 的 NodeList。 返回节点集合 Node node = list.item(1);//取第二个\"书名\"的节点 String s = node.getTextContent();//得到节点的文本内容 System.out.println(s); &#125; //2.遍历整个XML文档中的所有节点(标签) public void read2() throws Exception&#123; DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.parse(\"src/cn/xml/book.xml\"); //得到根节点 Node root = document.getElementsByTagName(\"书架\").item(0);//得到\"书架\"节点(根) //得到孩子并打印 this.glist(root); &#125; private void glist(Node node)&#123; //instanceof 在运行时指出对象是否是特定类的一个实例 返回布尔值 if(node instanceof Element)&#123;//判断node是不是标签(元素) (因为xml的空格和换行符也能传进来) System.out.println(node.getNodeName());//打印节点名称 NodeList list = node.getChildNodes();//得到孩子节点 返回孩子节点的集合 for (int i = 0; i &lt; list.getLength(); i++) &#123; Node child = list.item(i); glist(child); &#125; &#125; &#125; //3.得到\"书名\"标签中属性值 public void read3() throws Exception&#123; DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.parse(\"src/cn/xml/book.xml\"); NodeList list = document.getElementsByTagName(\"书名\"); //两种方法 第二个不推荐 //把得到的\"书名\"节点强行转为标签类型 Element bookname = (Element)list.item(0); String s = bookname.getAttribute(\"color\");//此方法可取得属性值/* Node bookname = list.item(0); String s= bookname.getAttributes().getNamedItem(\"color\").getNodeValue();*/ System.out.println(s); &#125;&#125;","categories":[{"name":"DOM操作","slug":"DOM操作","permalink":"http://zj2626.github.io/categories/DOM操作/"},{"name":"XML","slug":"DOM操作/XML","permalink":"http://zj2626.github.io/categories/DOM操作/XML/"}],"tags":[{"name":"jaxp","slug":"jaxp","permalink":"http://zj2626.github.io/tags/jaxp/"}]},{"title":"1.了解java","slug":"20170205001_了解java","date":"2017-02-04T16:00:00.000Z","updated":"2018-01-13T02:29:22.242Z","comments":true,"path":"2017/02/05/20170205001_了解java/","link":"","permalink":"http://zj2626.github.io/2017/02/05/20170205001_了解java/","excerpt":"来自&lt;&lt;深入了解java虚拟机&gt;&gt;: Java不仅是一门编程语言, 也是一个由一系列计算机软件和规范形成的技术体系 java技术体系包括(这是sun公司定义的) Java程序设计语言 各种硬件平台上的java虚拟机 Java API类库 Class文件 各种第三方Java类库 其中前三部分共同统称——&gt;JDK (Java Development Kit) 这是支持Java程序开发的最小环境JavaAPI类库中的JavaSE API子集和Java虚拟机统称——&gt;JRE (Java Runtime Environment) 这是支持Java程序运行的标准环境","text":"来自&lt;&lt;深入了解java虚拟机&gt;&gt;: Java不仅是一门编程语言, 也是一个由一系列计算机软件和规范形成的技术体系 java技术体系包括(这是sun公司定义的) Java程序设计语言 各种硬件平台上的java虚拟机 Java API类库 Class文件 各种第三方Java类库 其中前三部分共同统称——&gt;JDK (Java Development Kit) 这是支持Java程序开发的最小环境JavaAPI类库中的JavaSE API子集和Java虚拟机统称——&gt;JRE (Java Runtime Environment) 这是支持Java程序运行的标准环境 *(这是原书上的附图)* *java技术体系按照业务领域目前分为4个平台** Java Card ——&gt; 支持Java小程序(Applets) 运行在小内存设备(智能卡)上的平台 Java ME (Micro Edition) —–&gt; 支持Java程序运行在移动终端(手机, PDA)上的平台, 也称为J2ME Java SE (Standard Edition) –&gt; 支持面向桌面的级应用(如windows下的应用程序)的Java平台 提供了完整的Java核心API, 也称为J2SE Java EE (Enterprise Edition) –&gt; 支持使用多层架构的企业应用的Java平台, 提供了JavaSE API以及其它扩充,也称为J2EE . *Java发展史** 其他大事 1999年4月,HotSpot虚拟机发布 (其原虚拟机研发公司于1997年被sun公司收购),JDK1.3以后成为所有SunJDK的默认虚拟机 JDK1.5以前版本语法变化较小,发布的1.5的语法层面进行了巨大改进,包括自动装箱,泛型,动态注解,foreach等,并改进了java内存模型 JDK1.6以后就不叫J2ME,J2SE,J2EE而改名为Java ME6, Java SE6, Java EE6 2006年在JavaOne大会上 Sun公司将Java陆续开源 2009年Sun公司被Oracle收购 (但Java语言由JCP组织管理) *Java虚拟机发展史(部分)**虚拟机版本有 Sun Classic VM –&gt;世界上第一个商用虚拟机 (JDK1.0的运行环境) Sun HotSpot VM –&gt;目前使用范围最广的Java虚拟机 ,Sun JDK,Open JDK所带的虚拟机 :: (#当初设计 的目标是达到C语言50%以上的执行效率) KVM (Sun公司) –&gt;简单,轻量,高度可移植,运行速度慢.广泛运用于Android,iOS等智能手机系统 JRockit VM (BEA公司) –&gt;专注服务器应用的虚拟机,所以可以不关注启动速度而运行速度快,其在垃圾回收器和MissionControl服务套件等部分的实现处于领先地位 IBM J9 VM (IBM公司) –&gt; 一款多用途虚拟机 Microsoft JVM(微软) –&gt; 这是可以说是最有意思的……当初微软也是Java技术的铁杆支持者,并且自行开发了只有win平台的java虚拟机,然而Sun公司起诉微软侵权,微软败诉于是被迫终止了Java虚拟机的研究,移除了WindowsXP中自家Java虚拟机．有趣的是当初怼人家时候说人侵权要阻止人家支持Java,真的成了之后Sun公司又到处登报纸希望Windows继续支持Java,因为那时候Sun真的是已经日薄西山了 (讽刺啊!!) OpenJDK源码仓库地址*http://hg.openjdk.java.net/jdk7u/jdk7u-dev OpenJDK官方源码包http://jdk7.java.net/source.html ps:尽量在linux或者mac上构建OpenJDK","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"sax解析xml文档实现打印xml(遍历全部和指定位置)","slug":"2017_sax","date":"2017-02-04T16:00:00.000Z","updated":"2018-01-13T02:29:22.259Z","comments":true,"path":"2017/02/05/2017_sax/","link":"","permalink":"http://zj2626.github.io/2017/02/05/2017_sax/","excerpt":"这是示例被解析xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt; &lt;书架&gt; &lt;书&gt; &lt;书名&gt;java实战&lt;/书名&gt; &lt;作者&gt;张三&lt;/作者&gt; &lt;售价&gt;121元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt; &lt;书&gt; &lt;书名 color=&quot;yellow&quot; name=&quot;XXX&quot;&gt;c测试&lt;/书名&gt; &lt;作者&gt;李四&lt;/作者&gt; &lt;售价 color=&quot;rrr&quot;&gt;54元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt;&lt;/书&gt; &lt;/书架&gt;","text":"这是示例被解析xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt; &lt;书架&gt; &lt;书&gt; &lt;书名&gt;java实战&lt;/书名&gt; &lt;作者&gt;张三&lt;/作者&gt; &lt;售价&gt;121元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt; &lt;书&gt; &lt;书名 color=&quot;yellow&quot; name=&quot;XXX&quot;&gt;c测试&lt;/书名&gt; &lt;作者&gt;李四&lt;/作者&gt; &lt;售价 color=&quot;rrr&quot;&gt;54元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt;&lt;/书&gt; &lt;/书架&gt; 遍历全部123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120package cn.sax;import java.io.IOException;import javax.sql.rowset.spi.XmlReader;import javax.xml.parsers.ParserConfigurationException;import javax.xml.parsers.SAXParser;import javax.xml.parsers.SAXParserFactory;import org.junit.Test;import org.xml.sax.Attributes;import org.xml.sax.ContentHandler;import org.xml.sax.Locator;import org.xml.sax.SAXException;import org.xml.sax.XMLReader;public class sax解析xml &#123; @Test public void main() throws ParserConfigurationException, SAXException, IOException &#123; //1.创建解析工厂 抽象工厂 SAXParserFactory factory = SAXParserFactory.newInstance(); //2.得到解析器 SAXParser parser = factory.newSAXParser(); //3.得到读取器 XMLReader reader = parser.getXMLReader(); //4.设置内容处理器 reader.setContentHandler(new ListHandler()); //5.读取文档内容 解析xml文档 解析一点就调用处理器处理 所以要先设置内容处理器 reader.parse(\"src/book.xml\"); &#125;&#125;//内容处理器 得到xml文档所有内容class ListHandler implements ContentHandler&#123; //实现接口中的方法 @Override public void startElement(String uri, String localName, String qName, Attributes atts) throws SAXException &#123;//当得到开始标签时 调用这个方法 // TODO Auto-generated method stub System.out.print(\"&lt;\" + qName );//打印 //获取属性 还要判断属性有没有(是否为null) for (int i = 0; atts != null &amp;&amp; i &lt; atts.getLength(); i++) &#123; String att_Name = atts.getQName(i); String att_Vlaue = atts.getValue(i); System.out.print(att_Name + \"=\" + att_Vlaue); &#125; System.out.println( \"&gt;\"); &#125; @Override public void characters(char[] ch, int start, int length) throws SAXException &#123; //当解析到标签中内容时就调用这个方法 // TODO Auto-generated method stub System.out.println(new String(ch, start, length));//String解码(要解码的字符集,要解码的第一个byte位置,解码的长度) &#125; @Override public void endElement(String uri, String localName, String qName) throws SAXException &#123; //当解析到结束标签时 调用这个方法 // TODO Auto-generated method stub System.out.println(\"&lt;/\"+ qName +\"&gt;\"); &#125; @Override public void setDocumentLocator(Locator locator) &#123; // TODO Auto-generated method stub &#125; @Override public void startDocument() throws SAXException &#123; // TODO Auto-generated method stub &#125; @Override public void endDocument() throws SAXException &#123; // TODO Auto-generated method stub &#125; @Override public void startPrefixMapping(String prefix, String uri) throws SAXException &#123; // TODO Auto-generated method stub &#125; @Override public void endPrefixMapping(String prefix) throws SAXException &#123; // TODO Auto-generated method stub &#125; @Override public void ignorableWhitespace(char[] ch, int start, int length) throws SAXException &#123; // TODO Auto-generated method stub &#125; @Override public void processingInstruction(String target, String data) throws SAXException &#123; // TODO Auto-generated method stub &#125; @Override public void skippedEntity(String name) throws SAXException &#123; // TODO Auto-generated method stub &#125;&#125; 遍历指定标签 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 //打印指定标签的值(这里指定第二个作者的值)package cn.sax;import java.io.IOException;import javax.xml.parsers.ParserConfigurationException;import javax.xml.parsers.SAXParser;import javax.xml.parsers.SAXParserFactory;import org.junit.Test;import org.xml.sax.Attributes;import org.xml.sax.SAXException;import org.xml.sax.XMLReader;import org.xml.sax.helpers.DefaultHandler;public class sax解析获得指定标签的值&#123; @Test public void main() throws ParserConfigurationException, SAXException, IOException &#123; //1.创建解析工厂 抽象工厂 SAXParserFactory factory = SAXParserFactory.newInstance(); //2.得到解析器 SAXParser parser = factory.newSAXParser(); //3.得到读取器 XMLReader reader = parser.getXMLReader(); //4.设置内容处理器 reader.setContentHandler(new TagValueHandler()); //5.读取文档内容 解析xml文档 reader.parse(\"src/book.xml\"); &#125;&#125;//获取指定标签的值class TagValueHandler extends DefaultHandler&#123; private String currentTag;//用来记住当前解析到的是什么标签 private int needNumber = 2; //需要的标签是第几个标签 private int currentNumber; //当前解析到的是第几个标签 @Override public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException &#123; // TODO Auto-generated method stub super.startElement(uri, localName, qName, attributes);//可以不写 currentTag = qName; if(currentTag.equals(\"作者\"))&#123; currentNumber++; &#125; &#125; @Override public void endElement(String uri, String localName, String qName) throws SAXException &#123; // TODO Auto-generated method stub super.endElement(uri, localName, qName); currentTag = null;//置空 &#125; @Override public void characters(char[] ch, int start, int length) throws SAXException &#123; // TODO Auto-generated method stub super.characters(ch, start, length); if(\"作者\".equals(currentTag) &amp;&amp; currentNumber==needNumber)&#123; System.out.println(new String(ch, start, length)); &#125; &#125;&#125;","categories":[{"name":"DOM操作","slug":"DOM操作","permalink":"http://zj2626.github.io/categories/DOM操作/"},{"name":"XML","slug":"DOM操作/XML","permalink":"http://zj2626.github.io/categories/DOM操作/XML/"}],"tags":[{"name":"sax","slug":"sax","permalink":"http://zj2626.github.io/tags/sax/"}]},{"title":"2.Java运行时数据区","slug":"20170205002_Java运行时数据区","date":"2017-02-04T16:00:00.000Z","updated":"2021-05-31T15:18:48.200Z","comments":true,"path":"2017/02/05/20170205002_Java运行时数据区/","link":"","permalink":"http://zj2626.github.io/2017/02/05/20170205002_Java运行时数据区/","excerpt":"概述 :Java将new的对象的管理权交由Java虚拟机,so对于Java程序员,不需要写配套的delete/free代码,不容易出现内存溢出或泄露,但是一旦出现了,就需要了解虚拟机如何使用内存来排除bug Java虚拟机在执行程序时会把管理的内存划分为多个不同的数据区域, 1.程序计数器—&gt;线程私有的区域占用内存较小,作用是作为当前线程执行的字节码的行号指示器。在概念模型里,字节码解释器工作时通过改变程序计数器的值来选取下一条需要执行的字节码指令。分支，循环，跳转，异常处理，线程恢复等基础功能都需要此计数器完成。Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式实现的，so每次处理器只执行一个线程。 so 每个线程都拥有一个独立的程序计数器，各线程计数器互不影响，独立储存。若执行的是Native方法，则程序计数器值为空（Undefined） &lt;——唯一","text":"概述 :Java将new的对象的管理权交由Java虚拟机,so对于Java程序员,不需要写配套的delete/free代码,不容易出现内存溢出或泄露,但是一旦出现了,就需要了解虚拟机如何使用内存来排除bug Java虚拟机在执行程序时会把管理的内存划分为多个不同的数据区域, 1.程序计数器—&gt;线程私有的区域占用内存较小,作用是作为当前线程执行的字节码的行号指示器。在概念模型里,字节码解释器工作时通过改变程序计数器的值来选取下一条需要执行的字节码指令。分支，循环，跳转，异常处理，线程恢复等基础功能都需要此计数器完成。Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式实现的，so每次处理器只执行一个线程。 so 每个线程都拥有一个独立的程序计数器，各线程计数器互不影响，独立储存。若执行的是Native方法，则程序计数器值为空（Undefined） &lt;——唯一 2.Java虚拟机栈—&gt;线程私有的区域描述了Java方法执行的内存模式，每个方法在执行同时会创建一个栈帧，用来存储 局部变量表 （编译时即确定内存大小，方法执行时不会改变其大小）1.1. 存放编译期各种可知的基本数据类型 (64位长度的long，double占两个局部变量空间，其他占一个)1.2. 对象引用 (指向对象其实地址的指针或是指向代表对象的句柄或其他与此对象相关的位置)1.3. returnAddress类型 (指向一个字节码指令的地址) 操作数栈 动态链接 方法出口 方法的执行就是栈帧在虚拟机栈中的入栈到出栈的过程。人们常说的Java内存分配的堆内存(Heap)，栈内存(Stack) 中 后者就是这里的虚拟机栈。当线程请求的栈深度大于虚拟机所允许的深度 ——— StackOverflowError（当然，目前虚拟机栈都是可以动态扩展的）当无法申请到足够的内存 ——————–OutOfMemoryError 3.本地方法栈（Native Method Stack）功能与虚拟机栈相似 虚拟机栈：为虚拟机执行Java方法（字节码）服务 本地方法栈：为虚拟机使用的Native方法服务 4.Java堆—&gt;所有线程共享内存最大，虚拟机启动时创建， Java垃圾收集器主要管理区域（也叫GC堆）作用：存放对象实例（和数组） 即为对象实例分配内存可以进行进一步划分多个线程私有的分配缓冲区可以处于物理不连续的内存空间，但逻辑连续；可以实现成扩展，也可以固定（可通过-Xmx -Xms控制） 5.方法区—&gt;所有线程共享用于存储已被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等别名 Non-Heap可以物理内存不连续， 可以固定或可扩展， 可选择不实现垃圾收集（需要对常量池回收和对类型进行卸载，否则 易出现内存泄漏） 6.运行时常量池（Runtime Constant Pool）方法区的一部分，用于存储编译期生成的各种字面符号引用(一般也存储翻译出来的直接引用)Java对Class文件每部分（类版本，字段，方法，接口，常量池等）格式有严格规定，符合规定才能被虚拟机认可，装载，执行。but对运行时常量池，无规定。具有动态性（Class文件常量池无动态性） 7.直接内存（堆外内存）不是虚拟机运行时数据区的一部分，不归虚拟机管理减少了垃圾回收的工作（垃圾回收会暂停其他的工作）加快了复制的速度。因为堆内在flush到远程时，会先复制到直接内存（非堆内存），然后在发送；而堆外内存相当于省略掉了这个工作。堆外内存难以控制，如果内存泄漏，那么很难排查堆外内存相对来说，不适合存储很复杂的对象。一般简单的对象或者扁平化的比较适合。此处来源：http://blog.csdn.net/qq_17612199/article/details/52316719","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"sax解析xml文档(用javabean封装xml文档)","slug":"2017_sax2","date":"2017-02-04T16:00:00.000Z","updated":"2018-01-13T02:29:22.260Z","comments":true,"path":"2017/02/05/2017_sax2/","link":"","permalink":"http://zj2626.github.io/2017/02/05/2017_sax2/","excerpt":"被解析的xml示例 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt; &lt;书架&gt; &lt;书&gt; &lt;书名&gt;java实战&lt;/书名&gt; &lt;作者&gt;张三&lt;/作者&gt; &lt;售价&gt;121元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt; &lt;书&gt; &lt;书名 color=&quot;yellow&quot; name=&quot;XXX&quot;&gt;c测试&lt;/书名&gt; &lt;作者&gt;李四&lt;/作者&gt; &lt;售价 color=&quot;rrr&quot;&gt;54元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt;&lt;/书&gt; &lt;/书架&gt;","text":"被解析的xml示例 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt; &lt;书架&gt; &lt;书&gt; &lt;书名&gt;java实战&lt;/书名&gt; &lt;作者&gt;张三&lt;/作者&gt; &lt;售价&gt;121元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt; &lt;书&gt; &lt;书名 color=&quot;yellow&quot; name=&quot;XXX&quot;&gt;c测试&lt;/书名&gt; &lt;作者&gt;李四&lt;/作者&gt; &lt;售价 color=&quot;rrr&quot;&gt;54元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt;&lt;/书&gt; &lt;/书架&gt; 封装用的javabean123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112package cn.sax;//这是封装用的类public class BookObject &#123; private String name; private String author; private String price; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getAuthor() &#123; return author; &#125; public void setAuthor(String author) &#123; this.author = author; &#125; public String getPrice() &#123; return price; &#125; public void setPrice(String price) &#123; this.price = price; &#125;&#125;**解析**package cn.sax;import java.awt.print.Book;import java.io.IOException;import java.util.ArrayList;import java.util.List;import javax.xml.parsers.ParserConfigurationException;import javax.xml.parsers.SAXParser;import javax.xml.parsers.SAXParserFactory;import org.junit.Test;import org.xml.sax.Attributes;import org.xml.sax.SAXException;import org.xml.sax.XMLReader;import org.xml.sax.helpers.DefaultHandler;public class sax解析xml_javabean封装xml &#123; @Test public void main() throws ParserConfigurationException, SAXException, IOException &#123; //1.创建解析工厂 抽象工厂 SAXParserFactory factory = SAXParserFactory.newInstance(); //2.得到解析器 SAXParser parser = factory.newSAXParser(); //3.得到读取器 XMLReader reader = parser.getXMLReader(); //4.设置内容处理器 读取使xml内容放在list中的book对象中 BeanListHandler hand = new BeanListHandler(); reader.setContentHandler(hand); //5.读取文档内容 解析xml文档 reader.parse(\"src/book.xml\"); List list = hand.getBooks(); System.out.println(list); &#125;&#125;//把xml文档中的每一本书封装到每个book对象中 并把多个book对象放在List集合中返回class BeanListHandler extends DefaultHandler&#123; private List list = new ArrayList(); private String currentTag;//解析到的当前的标签名称(所有) private BookObject book;//book对象封装得到的book标签 @Override public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException &#123;//开始标签 currentTag = qName; if(\"书\".equals(currentTag))&#123; //如果是书 就要用一个book对象来封装这个书 book = new BookObject(); &#125; &#125; @Override public void characters(char[] ch, int start, int length) throws SAXException &#123; //内容 if(\"书名\".equals(currentTag))&#123;//如果标签是 书名 则创造字符串对象放标签的内容 String name = new String(ch, start, length); book.setName(name); &#125; if(\"作者\".equals(currentTag))&#123; String author = new String(ch, start, length); book.setAuthor(author); &#125; if(\"售价\".equals(currentTag))&#123; String price = new String(ch, start, length); book.setPrice(price); &#125; &#125; @Override public void endElement(String uri, String localName, String qName) throws SAXException &#123; //结束标签 currentTag = null;//currentTag不能不清空 以为解析xml文档会读取到空格和换行 干扰 空指针异常 if (\"书\".equals(qName)) &#123; list.add(book);//把book对象加入到list中 book = null;//book对象置空 &#125; &#125; //由于list对象是私有的 所以需要这个 public List getBooks() &#123; return list; &#125;&#125;","categories":[{"name":"DOM操作","slug":"DOM操作","permalink":"http://zj2626.github.io/categories/DOM操作/"},{"name":"XML","slug":"DOM操作/XML","permalink":"http://zj2626.github.io/categories/DOM操作/XML/"}],"tags":[{"name":"sax","slug":"sax","permalink":"http://zj2626.github.io/tags/sax/"}]},{"title":"Centos下用yum安装mysql5.6","slug":"2017_centos","date":"2017-02-04T16:00:00.000Z","updated":"2018-01-13T02:29:22.238Z","comments":true,"path":"2017/02/05/2017_centos/","link":"","permalink":"http://zj2626.github.io/2017/02/05/2017_centos/","excerpt":"","text":"1. 输入命令 查看当前安装的mysql: rpm -qa | grep mysql 2. 如果有 卸载: rpm -e mysql // 普通删除模式 rpm -e --nodeps mysql // 强力删除模式，如果使用上面命令删除时，提示有依赖的其它文件，则用该命令可以对其进行强力删除 3. 查看yum上提供的mysql版本信息 : yum list | grep mysql 4.安装 : yum install -y mysql-server mysql mysql-devel 在CentOS7下安装mysql 可能会提示“No package mysql-server available.” 解决办法: rpm -Uvh http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm 然后再安装 mysql-server 5.查看安装好的mysql信息: rpm -qi mysql-server 6.启动: service mysqld start 7. 设置密码: mysql -u root 进入mysql界面 SET PASSWORD FOR &apos;root&apos;@&apos;localhost&apos; = PASSWORD(&apos;newpass&apos;); 8. 新建新用户,用于远程连接(也可以修改root用户访问权限) CREATE USER &apos;username&apos;@&apos;host&apos; IDENTIFIED BY &apos;password&apos;; * username - 你将创建的用户名, * host - 指定该用户在哪个主机上可以登陆,如果是本地用户可用localhost, 如果想让该用户可以从任意远程主机登陆,可以使用通配符%. * password - 该用户的登陆密码,密码可以为空,如果为空则该用户可以不需要密码登陆服务器 9. 为用户授权: GRANT privileges ON databasename.tablename TO &apos;username&apos;@&apos;host&apos; * privileges - 用户的操作权限,如SELECT , INSERT , UPDATE 等(详细列表见该文最后面).如果要授予所的权限则使用ALL.; * databasename - 数据库名, * tablename-表名,如果要授予该用户对所有数据库和表的相应操作权限则可用*表示, 如*.*. 10.设置密码: SET PASSWORD FOR &apos;username&apos;@&apos;host&apos; = PASSWORD(&apos;newpassword&apos;);","categories":[{"name":"数据库","slug":"数据库","permalink":"http://zj2626.github.io/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://zj2626.github.io/tags/mysql/"}]},{"title":"XPath解析xml文档","slug":"2017_XPath","date":"2017-02-04T16:00:00.000Z","updated":"2018-01-13T02:29:22.235Z","comments":true,"path":"2017/02/05/2017_XPath/","link":"","permalink":"http://zj2626.github.io/2017/02/05/2017_XPath/","excerpt":"","text":"这是被解析的xml文档示例123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;&lt;用户&gt; &lt;user id=\"1\" username=\"aaa\" password=\"123\" email=\"abc.com\"/&gt; &lt;user id=\"2\" username=\"bbb\" password=\"123\" email=\"abc.com\"/&gt; &lt;书架&gt; &lt;书&gt; &lt;书名&gt;java实战&lt;/书名&gt; &lt;作者&gt;张三&lt;/作者&gt; &lt;售价&gt;121元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt; &lt;书&gt; &lt;书名 color=\"yellow\" name=\"XXX\"&gt;c测试&lt;/书名&gt; &lt;作者&gt;李四&lt;/作者&gt; &lt;售价 color=\"rrr\"&gt;54元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt;&lt;/书&gt; &lt;/书架&gt;&lt;/用户&gt; 123456789101112131415161718192021222324252627282930313233343536373839package cn.xml;import java.io.File;import org.dom4j.Document;import org.dom4j.DocumentException;import org.dom4j.Node;import org.dom4j.io.SAXReader;import org.junit.Test;//用XPath提取xml文档数据public class Xpath&#123; @Test public void read() throws DocumentException &#123; SAXReader reader = new SAXReader();//解析器 Document document = reader.read(new File(\"src/book.xml\"));//解析 String s = document.selectSingleNode(\"//作者\").getText();//得到第一个作者的内容 //selectSingleNode是取第一个\"作者\"节点 要取所有则用selectNodes System.out.println(s); &#125; @Test public void find() throws DocumentException &#123;//检测xml文档中有没有相匹配的用户账号密码 String username = \"aaa\"; String password = \"123\"; SAXReader reader = new SAXReader();//解析器 Document document = reader.read(new File(\"src/book.xml\"));//解析 //选择含有属性username且其值为'aa'的user元素( 这里注意空格有无是不同的) Node node = document.selectSingleNode(\"//user[@username= '\" + username + \"' and @password= '\" + password + \"' ]\"); if (node == null) &#123; System.out.println(\"用户名/密码错误\"); &#125;else&#123; System.out.println(\"登陆成功\"); &#125; &#125;&#125;","categories":[{"name":"DOM操作","slug":"DOM操作","permalink":"http://zj2626.github.io/categories/DOM操作/"},{"name":"XML","slug":"DOM操作/XML","permalink":"http://zj2626.github.io/categories/DOM操作/XML/"}],"tags":[{"name":"XPath","slug":"XPath","permalink":"http://zj2626.github.io/tags/XPath/"}]},{"title":"运用存储过程批量更新数据库中某个字段","slug":"2017_Procedure","date":"2017-02-04T16:00:00.000Z","updated":"2021-03-10T15:34:29.330Z","comments":true,"path":"2017/02/05/2017_Procedure/","link":"","permalink":"http://zj2626.github.io/2017/02/05/2017_Procedure/","excerpt":"这是目标表 这是来源表 **目的:要把exam_add表中的memo字段根据idCard字段对应更新到w_secondary_score表的memo **","text":"这是目标表 这是来源表 **目的:要把exam_add表中的memo字段根据idCard字段对应更新到w_secondary_score表的memo ** 1234567891011121314151617181920BEGIN DECLARE pidCard varchar(20); /*存放idCard*/DECLARE pmemo varchar(255); /*存放memo*/ declare done int default -1; DECLARE cur CURSOR FOR(SELECT idCard, memo from exam_end); /*定义一个游标*/ DECLARE continue handler for not found set done=1; OPEN cur; myLoop: LOOP FETCH cur INTO pidCard,pmemo; /*把游标内数据赋值给变量*/ if done = 1 then leave myLoop; end if; UPDATE w_secondary_score set memo = pmemo where idCard = pidCard; /*循环更新*/ end loop myLoop; CLOSE cur; 更新成功!!!!!!ps:在导入excel表到数据库的时候(通过navicat软件),出现中文乱码, 解决方案: 方法1.把excel表格编码修改为与数据库相同的编码(我的是utf-8),像这样(百度说可以, 然而我试了依然乱码) 方法2:我看到navicat可以导入.txt文件 那么可以把excel先转为.txt文件设置编码为utf-8,然后再导入—–&gt;成功!","categories":[{"name":"数据库","slug":"数据库","permalink":"http://zj2626.github.io/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://zj2626.github.io/tags/mysql/"},{"name":"存储过程","slug":"存储过程","permalink":"http://zj2626.github.io/tags/存储过程/"}]},{"title":"Dom4j解析xml文档实现增删改查","slug":"2017_Dom4j","date":"2017-02-04T16:00:00.000Z","updated":"2018-01-13T02:29:22.218Z","comments":true,"path":"2017/02/05/2017_Dom4j/","link":"","permalink":"http://zj2626.github.io/2017/02/05/2017_Dom4j/","excerpt":"这是被解析的xml文档示例123456789101112131415&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;&lt;书架&gt; &lt;书&gt; &lt;书名&gt;java实战&lt;/书名&gt; &lt;作者&gt;张三&lt;/作者&gt; &lt;售价&gt;121元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt; &lt;书&gt; &lt;书名 color=\"yellow\" name=\"XXX\"&gt;c测试&lt;/书名&gt; &lt;作者&gt;李四&lt;/作者&gt; &lt;售价 color=\"rrr\"&gt;54元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt;&lt;/书架&gt;","text":"这是被解析的xml文档示例123456789101112131415&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?&gt;&lt;书架&gt; &lt;书&gt; &lt;书名&gt;java实战&lt;/书名&gt; &lt;作者&gt;张三&lt;/作者&gt; &lt;售价&gt;121元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt; &lt;书&gt; &lt;书名 color=\"yellow\" name=\"XXX\"&gt;c测试&lt;/书名&gt; &lt;作者&gt;李四&lt;/作者&gt; &lt;售价 color=\"rrr\"&gt;54元&lt;/售价&gt; &lt;售价&gt;12元&lt;/售价&gt; &lt;/书&gt;&lt;/书架&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113package cn.xml;import java.io.File;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.FileWriter;import java.io.IOException;import java.io.OutputStreamWriter;import java.io.UnsupportedEncodingException;import java.util.Iterator;import java.util.List;import org.dom4j.Document;import org.dom4j.DocumentException;import org.dom4j.DocumentHelper;import org.dom4j.Element;import org.dom4j.io.OutputFormat;import org.dom4j.io.SAXReader;import org.dom4j.io.XMLWriter;import org.junit.Test;public class Dom4j &#123; @Test public void read() throws DocumentException&#123;//读 SAXReader reader = new SAXReader();//解析器 Document document = reader.read(new File(\"src/book.xml\"));//解析 Element root = document.getRootElement();//得到根节点 \"书架\" Element book = (Element) root.elements(\"书\").get(1);//得到\"书\"节点中第二个\"书\"节点 String value = book.element(\"书名\").getText();//得到售\"书名\"节点的内容 String attribute = book.element(\"书名\").attribute(\"color\").getValue();//得到属性值 String attribute1 = book.element(\"书名\").attributeValue(\"color\");//得到的同上 System.out.println(value); System.out.println(attribute); System.out.println(attribute1); &#125; //@Test public void add() throws DocumentException, IOException&#123;//增 SAXReader reader = new SAXReader();//解析器 Document document = reader.read(new File(\"src/book.xml\"));//解析 Element book = document.getRootElement().element(\"书\");//得到第一本书 book.addElement(\"售价\").setText(\"45元\");//在书上添加售价节点 同时添加节点内容 OutputFormat format = new OutputFormat().createPrettyPrint();//格式化输出器 format.setEncoding(\"UTF-8\");//设置格式化输出器的编码为UTF-8编码 使document按照utf-8格式输出 //把修改写入文件 document是UTF-8编码的 //XMLWriter writer = new XMLWriter(new FileWriter(\"src/book.xml\"));//可能出现乱码 //OutputStreamWriter可以指点采用什么字符集编码 XMLWriter writer = new XMLWriter(new FileOutputStream(\"src/book.xml\"), format); writer.write(document);//把document对象写入 writer.close();//关闭流 &#125; //@Test public void add2() throws DocumentException, IOException&#123;//在指定位置添加(通过更改保存所有孩子的List集合顺序) SAXReader reader = new SAXReader();//解析器 Document document = reader.read(new File(\"src/book.xml\"));//解析 Element book = document.getRootElement().element(\"书\");//得到第一本书 List list = book.elements();//得到所有的孩子 [书名, 孩子, 售价] //创建要加入的标签 以及内容 Element helper = DocumentHelper.createElement(\"其他\"); helper.setText(\"内容\"); //加入list集合 需要把加入位置的元素移动到下一位 然后把其加入到位置(自动) list.add(2, helper);//添加到第三个位置 OutputFormat format = new OutputFormat().createPrettyPrint();//格式化输出器 format.setEncoding(\"UTF-8\"); XMLWriter writer = new XMLWriter(new FileOutputStream(\"src/book.xml\"), format); writer.write(document);//把document对象写入 writer.close();//关闭流 &#125; //@Test public void delete() throws DocumentException, IOException&#123;//删除 SAXReader reader = new SAXReader();//解析器 Document document = reader.read(new File(\"src/book.xml\"));//解析 Element price = document.getRootElement().element(\"书\").element(\"售价\");//得到售价节点 price.getParent().remove(price);//用父母删孩子 OutputFormat format = new OutputFormat().createPrettyPrint();//格式化输出器 format.setEncoding(\"UTF-8\"); XMLWriter writer = new XMLWriter(new FileOutputStream(\"src/book.xml\"), format); writer.write(document);//把document对象写入 writer.close();//关闭流 &#125; @Test public void update() throws Exception&#123;//更新 SAXReader reader = new SAXReader();//解析器 Document document = reader.read(new File(\"src/book.xml\"));//解析 Element book = (Element)document.getRootElement().elements(\"书\").get(1); book.element(\"书名\").setText(\"初日\"); OutputFormat format = new OutputFormat().createPrettyPrint();//格式化输出器 format.setEncoding(\"UTF-8\"); XMLWriter writer = new XMLWriter(new FileOutputStream(\"src/book.xml\"), format); writer.write(document);//把document对象写入 writer.close();//关闭流 &#125;&#125;","categories":[{"name":"DOM操作","slug":"DOM操作","permalink":"http://zj2626.github.io/categories/DOM操作/"},{"name":"XML","slug":"DOM操作/XML","permalink":"http://zj2626.github.io/categories/DOM操作/XML/"}],"tags":[{"name":"Dom4j","slug":"Dom4j","permalink":"http://zj2626.github.io/tags/Dom4j/"}]},{"title":"3.HotSpot虚拟机 对象创建","slug":"20170205003_对象创建","date":"2017-02-04T16:00:00.000Z","updated":"2018-01-13T02:29:22.221Z","comments":true,"path":"2017/02/05/20170205003_对象创建/","link":"","permalink":"http://zj2626.github.io/2017/02/05/20170205003_对象创建/","excerpt":"","text":"对象创建 new指令 （new一个对象） 检查这个指令的参数是否能在常量池中定位到一个类符号引用 检查此符号引用代表的类是否被加载，解析，初始化过 否：执行相应的类加载 是（类被加载过后），虚拟机为新生的对象分配内存（大小在类加载时确定），把某大小的堆内存划分给此对象 5.1. 如果堆内存整齐划分：分配内存实质是把指向空闲内存的指针移动该对象大小相等的位置，这种分配方式叫指针碰壁 5.2 如果堆内存空闲内存与非空闲随机：则虚拟机会维护一个内存列表，每次分配都划分相应的内存给对象，这种分配方式叫空闲列表 分配方式决定于Java堆是否规整，Java堆是否规整决定于采用的垃圾回收器是否有压缩整理功能。 6.1 并发情况下，对于修改指针指向位置，有两种方案 1.对分配内存空间进行同步处理--实际上，虚拟机采用CAS配上失败重试的方法保证更新操作的原子性 2.把内存的分配的动作按照线程划分在不同的空间进行，即每个线程在Java堆中预先分配一小块内存（称为本地线程分配缓冲TLAB），哪个线程需要分配内存，就在哪个线程的TLAB上分配，当TLAB用完需要分配新的TLAB时才同步锁定 ----- 可以通过-XX:+/-UseTLAB参数设定 内存分配完毕，虚拟机把分配的内存初始化为零值（不包括对象头），使用TLAB则此可以在TLAB前执行。此步骤保证了对象的实例字段在代码中不赋初值即可使用，程序可访问到这些字段的数据类型所对应的默认初始值 虚拟机对对象进行必要的设置（指明类，找到类的元数据信息，对象的哈希码等）这些存放在对象的对象头（Object Header）中。 对于虚拟机，新的对象已经产生。对于程序，才刚刚开始 执行&lt; init &gt;方法，把对象按照程序员意愿进行初始化。可以用的对象新建成功","categories":[{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://zj2626.github.io/categories/java虚拟机/"}],"tags":[{"name":"深入了解java虚拟机","slug":"深入了解java虚拟机","permalink":"http://zj2626.github.io/tags/深入了解java虚拟机/"},{"name":"java","slug":"java","permalink":"http://zj2626.github.io/tags/java/"}]},{"title":"jaxp解析XML","slug":"2017_jaxp2","date":"2017-02-04T16:00:00.000Z","updated":"2018-01-13T02:29:22.245Z","comments":true,"path":"2017/02/05/2017_jaxp2/","link":"","permalink":"http://zj2626.github.io/2017/02/05/2017_jaxp2/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package cn.utils;//包名import java.io.FileOutputStream;import javax.xml.crypto.dsig.Transform;import javax.xml.parsers.DocumentBuilder;import javax.xml.parsers.DocumentBuilderFactory;import javax.xml.parsers.ParserConfigurationException;import javax.xml.transform.Transformer;import javax.xml.transform.TransformerConfigurationException;import javax.xml.transform.TransformerFactory;import javax.xml.transform.dom.DOMSource;import javax.xml.transform.stream.StreamResult;import org.w3c.dom.Document;//工具类 执行那些重复的代码块 默认为静态public class XmlUtils &#123; private static String filename = \"src/exam.xml\"; //得到解析器并解析xml文档 public static Document getDocument() throws Exception&#123; //1.创建工厂(得到DOM解析器的工厂实例) ---这个工厂类是抽象类,so用其newInstance方法得到DOM的新实例 DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); //2.从DOM工厂获得DOM解析器 有了这个实例才可以解析 DocumentBuilder builder = factory.newDocumentBuilder(); //3.将给定URI的内容解析为一个XML文档，并且返回一个新的DOM Document对象 Document document = builder.parse(\"src/cn/xml/book.xml\"); //4.以后的处理都是对Document对象进行的 return document; &#125; //把得到的数据写入xml文档 public static void write2Xml(Document document) throws Exception&#123; TransformerFactory factory = TransformerFactory.newInstance();//产生转化器 Transformer tf = factory.newTransformer(); tf.transform(new DOMSource(document), new StreamResult(new FileOutputStream(filename))); //原理 /* //创建工厂实例 TransformerFactory tf = TransformerFactory.newInstance(); //通过工厂实例得到Transformer对象(transform方法可以转化来源到目的地) Transformer tr = tf.newTransformer(); //DOMSource是Source的实现类 把Document类型封装为Source类型 Source s = new DOMSource(document); //声明输出流对象 指向硬盘中的XML文件 OutputStream f= new FileOutputStream(\"src/cn/xml/book.xml\"); //把输出流对象通过流方法转化为Result对象 Result对象指向硬盘中的XML文件 Result r = new StreamResult(f); //transform方法(来源, 目的地) 把s写入r tr.transform(s, r); */ &#125;&#125;","categories":[{"name":"DOM操作","slug":"DOM操作","permalink":"http://zj2626.github.io/categories/DOM操作/"},{"name":"XML","slug":"DOM操作/XML","permalink":"http://zj2626.github.io/categories/DOM操作/XML/"}],"tags":[{"name":"jaxp","slug":"jaxp","permalink":"http://zj2626.github.io/tags/jaxp/"}]}]}
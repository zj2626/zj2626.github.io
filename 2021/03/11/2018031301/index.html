<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="欢迎来到晋的博客,本博客用来收录平时学习笔记,欢迎访问"><title>使用多种算法对泰坦尼克号乘客获救原因进行分析 | ZJ_BLOG</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.1"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="/js/instantclick.min.js"></script><script>InstantClick.init();
InstantClick.on('change', function (isInitialLoad) {
         if (isInitialLoad === false) {
         if (typeof MathJax !== 'undefined') // support MathJax
         MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
         if (typeof prettyPrint !== 'undefined') // support google code prettify
         prettyPrint();
         if (typeof _hmt !== 'undefined')  // support 百度统计
         _hmt.push(['_trackPageview', location.pathname + location.search]);
         if (typeof ga !== 'undefined')  // support google analytics
         ga('send', 'pageview', location.pathname + location.search);
         }
 });
</script><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">使用多种算法对泰坦尼克号乘客获救原因进行分析</h1><a id="logo" href="/.">ZJ_BLOG</a><p class="description">Silence的博客</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">使用多种算法对泰坦尼克号乘客获救原因进行分析</h1><div class="post-meta">Mar 11, 2021<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#线性回归-步骤"><span class="toc-number">1.</span> <span class="toc-text">线性回归 步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Univariate-feature-selection：单变量的特征选择"><span class="toc-number">2.</span> <span class="toc-text">Univariate feature selection：单变量的特征选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Recursive-feature-elimination：循环特征选择"><span class="toc-number">3.</span> <span class="toc-text">Recursive feature elimination：循环特征选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#L1-based-featureselection："><span class="toc-number">4.</span> <span class="toc-text">L1-based featureselection：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tree-based-featureselection：决策树特征选择"><span class="toc-number">5.</span> <span class="toc-text">Tree-based featureselection：决策树特征选择</span></a></li></ol></div></div><div class="post-content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line">titanic = pandas.read_csv(<span class="string">'titanic_train.csv'</span>)</span><br><span class="line">titanic.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据简单统计</span></span><br><span class="line">titanic.describe()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由表Age列有部分缺失，影响最终模型效果</span></span><br><span class="line"><span class="comment"># 解决方法： 填充中位数 (使用fillna()方法填充缺失值NaN， 使用median()获得中位数/中值)</span></span><br><span class="line">titanic[<span class="string">'Age'</span>] = titanic[<span class="string">'Age'</span>].fillna(titanic[<span class="string">'Age'</span>].median())</span><br><span class="line">titanic.describe()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 处理原始数据，其中有的是字符量需要映射为数值</span></span><br><span class="line"><span class="keyword">print</span> (titanic[<span class="string">'Sex'</span>].unique())</span><br><span class="line">titanic.loc[titanic[<span class="string">'Sex'</span>] == <span class="string">'male'</span>, <span class="string">'Sex'</span>] = <span class="number">0</span></span><br><span class="line">titanic.loc[titanic[<span class="string">'Sex'</span>] == <span class="string">'female'</span>, <span class="string">'Sex'</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (titanic[<span class="string">'Embarked'</span>].unique())</span><br><span class="line">titanic[<span class="string">'Embarked'</span>] = titanic[<span class="string">'Embarked'</span>].fillna(<span class="string">'S'</span>)<span class="comment"># 缺失值填充，填充数量最多的类别</span></span><br><span class="line">titanic.loc[titanic[<span class="string">'Embarked'</span>] == <span class="string">'S'</span>, <span class="string">'Embarked'</span>] = <span class="number">0</span></span><br><span class="line">titanic.loc[titanic[<span class="string">'Embarked'</span>] == <span class="string">'C'</span>, <span class="string">'Embarked'</span>] = <span class="number">1</span></span><br><span class="line">titanic.loc[titanic[<span class="string">'Embarked'</span>] == <span class="string">'Q'</span>, <span class="string">'Embarked'</span>] = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">titanic.head()</span><br></pre></td></tr></table></figure>
<h3 id="线性回归-步骤"><a href="#线性回归-步骤" class="headerlink" title="线性回归 步骤"></a>线性回归 步骤</h3><ol>
<li>观察数据，填充缺失值，改变数据形式（数据映射）</li>
<li>使用交叉验证减少过拟合风险</li>
<li>使用线性回归算法计算预测值</li>
<li>确定阈值，计算精度</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 线性回归</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"><span class="comment"># 要使用的特征 船仓等级、性别、年龄、兄弟姐妹人数、老人孩子人数、船票价格、上船位置</span></span><br><span class="line">predictors = [<span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Embarked'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建线性回归</span></span><br><span class="line">alg = LinearRegression()</span><br><span class="line">kf = KFold(titanic.shape[<span class="number">0</span>], n_folds=<span class="number">3</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">predictions0 = []</span><br><span class="line"><span class="keyword">for</span> train, test <span class="keyword">in</span> kf:</span><br><span class="line">    <span class="comment"># print (train.shape, test.shape)</span></span><br><span class="line">    train_predictors = titanic.loc[train, predictors]</span><br><span class="line">    train_targets = titanic.loc[train, [<span class="string">'Survived'</span>]]</span><br><span class="line">    <span class="keyword">print</span> (train_predictors.shape, train_targets.shape)</span><br><span class="line">    test_features = titanic.loc[test, predictors]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练 拟合数据 使用交叉验证拆分出来的训练集</span></span><br><span class="line">    alg.fit(train_predictors, train_targets)</span><br><span class="line">    <span class="comment"># 验证 使用交叉验证拆分出来的验证集</span></span><br><span class="line">    test_predictions = alg.predict(test_features)</span><br><span class="line">    </span><br><span class="line">    predictions0.append(test_predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三组预测值</span></span><br><span class="line"><span class="keyword">print</span> (len(predictions0), <span class="string">'\n\n'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 设定一个阈值 大于阈值表示获救 小于阈值表示未获救</span></span><br><span class="line">predictions = np.concatenate(predictions0, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">predictions[predictions &gt;  <span class="number">0.5</span>] = <span class="number">1</span></span><br><span class="line">predictions[predictions &lt;= <span class="number">0.5</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (type(predictions), type(titanic[<span class="string">'Survived'</span>].values))</span><br><span class="line"><span class="keyword">print</span> (predictions.shape,titanic[<span class="string">'Survived'</span>].values.reshape(<span class="number">-1</span>, <span class="number">1</span>).shape)</span><br><span class="line"></span><br><span class="line">accuracy = len(predictions[predictions == titanic[<span class="string">'Survived'</span>].values.reshape(<span class="number">-1</span>, <span class="number">1</span>)]) / len(predictions)</span><br><span class="line"><span class="keyword">print</span> (accuracy)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机森林</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">predictors = [<span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Embarked'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造随机森林</span></span><br><span class="line"><span class="comment"># n_estimators：构造的树个数  min_samples_split：最小切分点  min_samples_leaf：叶子节点最小个数</span></span><br><span class="line">alg = RandomForestClassifier(random_state=<span class="number">1</span>, n_estimators=<span class="number">10</span>, min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 交叉验证</span></span><br><span class="line">kf = cross_validation.KFold(titanic.shape[<span class="number">0</span>], n_folds=<span class="number">3</span>, random_state=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line">scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[<span class="string">'Survived'</span>], cv=kf)</span><br><span class="line"><span class="comment"># 平均准确率</span></span><br><span class="line"><span class="keyword">print</span> (scores.mean())</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机森林调优： 修改参数 </span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">&gt; RandomForestClassifier参数：</span></span><br><span class="line"><span class="string">1. max_features:随机森林允许单个决策树使用特征的最大数量, 增加max_features一般能提高模型的性能,同时降低算法的速度</span></span><br><span class="line"><span class="string">2. n_estimators:在利用最大投票数或平均值来预测之前，想要建立子树的数量。较多的子树可以让模型有更好的性能，但同时让你的代码变慢</span></span><br><span class="line"><span class="string">3. min_sample_leaf:最小样本叶片大小</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment">#1 构建随机森林模型(分类器)</span></span><br><span class="line">alg = RandomForestClassifier(random_state=<span class="number">1</span>, n_estimators=<span class="number">50</span>, min_samples_split=<span class="number">4</span>, min_samples_leaf=<span class="number">10</span>)</span><br><span class="line"><span class="comment">#2 构建交叉验证</span></span><br><span class="line">kf = cross_validation.KFold(titanic.shape[<span class="number">0</span>], n_folds=<span class="number">3</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">&gt; cross_validation.cross_val_score参数：</span></span><br><span class="line"><span class="string">1. alg:分类器，可以是任何的分类器，比如支持向量机分类器。alg = svm.SVC(kernel='linear', C=1)</span></span><br><span class="line"><span class="string">2. cv：交叉验证（cross validation）方法，如果cv是一个int数字的话，并且如果提供了raw target参数，那么就代表使用StratifiedKFold分类方式，如果没有提供raw target参数，那么就代表使用KFold分类方式。</span></span><br><span class="line"><span class="string">3. raw data,raw target：验证使用的数据（feature以及label）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">4. 返回值：对于每次不同的的划分raw data时，在test data（验证集）上得到的分类的准确率</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment">#3 进行交叉验证</span></span><br><span class="line">scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[<span class="string">'Survived'</span>], cv=kf)</span><br><span class="line"><span class="keyword">print</span> (len(scores), <span class="string">'-----'</span>, scores.mean(), <span class="string">'-----'</span>, scores)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机森林调优： 添加特征</span></span><br><span class="line">titanic[<span class="string">'FamilySize'</span>] = titanic[<span class="string">'SibSp'</span>] + titanic[<span class="string">'Parch'</span>]</span><br><span class="line">titanic[<span class="string">'NameLength'</span>] = titanic[<span class="string">'Name'</span>].apply(<span class="keyword">lambda</span> x: len(x))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征重要程度</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest,f_classif</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">predictors = [<span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'SibSp'</span>, <span class="string">'Parch'</span>, <span class="string">'Fare'</span>, <span class="string">'Embarked'</span>, <span class="string">'FamilySize'</span>, <span class="string">'NameLength'</span>]</span><br></pre></td></tr></table></figure>
<h3 id="Univariate-feature-selection：单变量的特征选择"><a href="#Univariate-feature-selection：单变量的特征选择" class="headerlink" title="Univariate feature selection：单变量的特征选择"></a>Univariate feature selection：单变量的特征选择</h3><p>单变量特征选择的原理是分别单独的计算每个变量的某个统计指标，根据该指标来判断哪些指标重要。剔除那些不重要的指标。</p>
<p>sklearn.feature_selection模块中主要有以下几个方法：</p>
<blockquote>
<p>SelectKBest和SelectPercentile比较相似，前者选择排名排在前n个的变量，后者选择排名排在前n%的变量。而他们通过什么指标来给变量排名呢？这需要二外的指定。</p>
</blockquote>
<blockquote>
<p>对于regression问题，可以使用f_regression指标。对于classification问题，可以使用chi2或者f_classif变量。</p>
</blockquote>
<p><em>使用的例子：</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selectionimport SelectPercentile, f_classif</span><br><span class="line">selector =SelectPercentile(f_classif, percentile=<span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="Recursive-feature-elimination：循环特征选择"><a href="#Recursive-feature-elimination：循环特征选择" class="headerlink" title="Recursive feature elimination：循环特征选择"></a>Recursive feature elimination：循环特征选择</h3><p>不单独的检验某个变量的价值，而是将其聚集在一起检验。它的基本思想是，对于一个数量为d的feature的集合，他的所有的子集的个数是2的d次方减1（包含空集）。指定一个外部的学习算法，比如SVM之类的。通过该算法计算所有子集的validationerror。选择error最小的那个子集作为所挑选的特征。</p>
<p>由以下两个方法实现：sklearn.feature_selection.RFE，sklearn.feature_selection.RFECV</p>
<h3 id="L1-based-featureselection："><a href="#L1-based-featureselection：" class="headerlink" title="L1-based featureselection："></a>L1-based featureselection：</h3><p>该思路的原理是：在linearregression模型中，有的时候会得到sparsesolution。意思是说很多变量前面的系数都等于0或者接近于0。这说明这些变量不重要，那么可以将这些变量去除。</p>
<h3 id="Tree-based-featureselection：决策树特征选择"><a href="#Tree-based-featureselection：决策树特征选择" class="headerlink" title="Tree-based featureselection：决策树特征选择"></a>Tree-based featureselection：决策树特征选择</h3><p>基于决策树算法做出特征选择</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">selector = SelectKBest(f_classif, k=<span class="number">5</span>)</span><br><span class="line">selector.fit(titanic[predictors], titanic[<span class="string">'Survived'</span>])</span><br><span class="line"></span><br><span class="line">scores = -np.log10(selector.pvalues_)</span><br><span class="line"><span class="keyword">print</span> (scores)</span><br><span class="line"></span><br><span class="line">plt.bar(range(len(predictors)), scores)</span><br><span class="line">plt.xticks(range(len(predictors)), predictors, rotation=<span class="string">'vertical'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多种算法集成预测</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两个算法集成到一起使用</span></span><br><span class="line">algorithms = [</span><br><span class="line">    [GradientBoostingClassifier(random_state=<span class="number">1</span>, n_estimators=<span class="number">25</span>, max_depth=<span class="number">3</span>),  [<span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'Fare'</span>, <span class="string">'Embarked'</span>, <span class="string">'FamilySize'</span>]],</span><br><span class="line">     [LogisticRegression(random_state=<span class="number">1</span>), [<span class="string">'Pclass'</span>, <span class="string">'Sex'</span>, <span class="string">'Age'</span>, <span class="string">'Fare'</span>, <span class="string">'Embarked'</span>]]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">kf = KFold(titanic.shape[<span class="number">0</span>], n_folds=<span class="number">3</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">predictions = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两个算法分别预测</span></span><br><span class="line"><span class="keyword">for</span> train, test <span class="keyword">in</span> kf:</span><br><span class="line">    train_target = titanic.loc[train, [<span class="string">'Survived'</span>]]</span><br><span class="line">    full_test_predictions = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 循环分类算法，获得不同算法求得的概率</span></span><br><span class="line">    <span class="keyword">for</span> alg, predictors <span class="keyword">in</span> algorithms:</span><br><span class="line">        <span class="comment"># alg：分类算法   predictors：特征</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用训练集 拟合数据</span></span><br><span class="line">        alg.fit(titanic.loc[train, predictors], train_target)</span><br><span class="line">        <span class="comment"># 使用验证集 计算 (这里 直接取预测的概率的第二个值--&gt;[:, 1])</span></span><br><span class="line">        test_predictions = alg.predict_proba(titanic.loc[test, predictors].astype(float))[:, <span class="number">1</span>]</span><br><span class="line">        full_test_predictions.append(test_predictions)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用不同的分类算法之后计算平均概率</span></span><br><span class="line">    test_predictions = (full_test_predictions[<span class="number">0</span>] + full_test_predictions[<span class="number">1</span>]) / <span class="number">2</span></span><br><span class="line">    test_predictions[test_predictions &lt;= <span class="number">0.5</span>] = <span class="number">0</span></span><br><span class="line">    test_predictions[test_predictions &gt;  <span class="number">0.5</span>] = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    predictions.append(test_predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得的分类结果</span></span><br><span class="line">predictions = np.concatenate(predictions, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算精确度</span></span><br><span class="line">accuracy = len(predictions[predictions == titanic[<span class="string">'Survived'</span>]]) / len(predictions)</span><br><span class="line"><span class="keyword">print</span> (accuracy)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>个人博客 欢迎来访： <a href="http://zj2626.github.io">http://zj2626.github.io</a></p>
</blockquote>
</div><script type="text/javascript" src="/js/share.js?v=0.0.1" async></script><a class="article-share-link" data-url="http://zj2626.github.io/2021/03/11/2018031301/" data-id="ckpdsy5ws006hp4ut4603jgwk" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACJ0lEQVR42u3aQXKDQAwEQP//06Qqp1yAkWS7wm5zcsWAaQ6KVrOvV3wcv8ffz2d/Ofv27Nqzc16fODAwMB7LOC6P/GfOrj27qsq+vj8GBsYOjKTIJkWzh7ku5dfPhoGBgZG0g3nLOCm+GBgYGHnBzYtjte2rtqEYGBi7MZJF7PUgbN4afmktjoGB8UBGLxj4zueP5xsYGBj/nnG0jjwGqJ7TeyoMDIy1GXnb19uEMWn48tEbBgbG2oxJKZwsXKsv6OYcDAyMDRi9m5brenHon5dvDAwMjGrDNxn359s4ygUXAwPj4YxqEczL4rwdLGewGBgYyzF6BbFXoOehQjTaw8DAWI5R3bw1aSXLkWT+DwADA2MDRnJBdWSWBwzVWOJm3IaBgbENI/mBahtXfUGFV4OBgbEBIx+xVbdizKPN0bYwDAyMRRmTLVyTMt0LUDEwMHZg5JHAZCg22aJR4GFgYCzNmMeWvaiyN5K7eTYMDIxFGfNbzEvwfAmNgYGxD6O3sKwGmUkgUV70YmBgbMBI2rtqY5dgeps5TltDDAyMRRm9KDFpHMvtXTF+iIovBgbGwxlH8ai+lWrA0CviGBgYazN64/55G5csepP7Y2Bg7MPIi2y1pM5DSgwMDIx3bd7Kz3xXqBlNDTEwMDZm5AvU6jCuFx5gYGBgVB9ivp5OhnGjdTYGBsZjGdVymfxkEn/2mk4MDIzdGL1gIG8ce68sfxEYGBhLM34AKGuyUGq4YGcAAAAASUVORK5CYII=">分享</a><div class="tags"><a href="/tags/python/">python</a><a href="/tags/机器学习/">机器学习</a></div><div class="post-nav"><a class="pre" href="/2021/06/01/201703092017_对象在HotSpot虚拟机中/">对象在HotSpot虚拟机中</a><a class="next" href="/2021/03/11/2018030701/">构建逻辑回归模型实例</a></div><div id="container"></div><link rel="stylesheet" href="/css/default.css?v=0.0.1"><script src="/js/gitment.browser.js?v=0.0.1"></script><script>var gitment = new Gitment({
  owner: 'zj2626',
  repo: 'zj2626.github.io',
  oauth: {
    client_id: '22769c7edffa5f05d10d',
    client_secret: '7bac8fc03397cb64c178fbdfe3a01d2abb459704',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/BUG解决/">BUG解决</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DOM操作/">DOM操作</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/DOM操作/XML/">XML</a><span class="category-list-count">6</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/JDBC/">JDBC</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java虚拟机/">java虚拟机</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java语言基础/">java语言基础</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/多线程/">多线程</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库连接池/">数据库连接池</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构和算法/">数据结构和算法</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架相关/">框架相关</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/框架相关/前端技术/">前端技术</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架相关/权限管理/">权限管理</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/正则/">正则</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/程序安装与配置/">程序安装与配置</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机网络/">计算机网络</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/深入了解java虚拟机/" style="font-size: 15px;">深入了解java虚拟机</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/注解/" style="font-size: 15px;">注解</a> <a href="/tags/元数据/" style="font-size: 15px;">元数据</a> <a href="/tags/HTML/" style="font-size: 15px;">HTML</a> <a href="/tags/iframe/" style="font-size: 15px;">iframe</a> <a href="/tags/Maven/" style="font-size: 15px;">Maven</a> <a href="/tags/Hexo优化/" style="font-size: 15px;">Hexo优化</a> <a href="/tags/Shiro/" style="font-size: 15px;">Shiro</a> <a href="/tags/jenkins/" style="font-size: 15px;">jenkins</a> <a href="/tags/Git/" style="font-size: 15px;">Git</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/C语言/" style="font-size: 15px;">C语言</a> <a href="/tags/junit/" style="font-size: 15px;">junit</a> <a href="/tags/Mybatis/" style="font-size: 15px;">Mybatis</a> <a href="/tags/定义/" style="font-size: 15px;">定义</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/转码/" style="font-size: 15px;">转码</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/DBCP/" style="font-size: 15px;">DBCP</a> <a href="/tags/常用命令/" style="font-size: 15px;">常用命令</a> <a href="/tags/shell/" style="font-size: 15px;">shell</a> <a href="/tags/Dom4j/" style="font-size: 15px;">Dom4j</a> <a href="/tags/Hibernate/" style="font-size: 15px;">Hibernate</a> <a href="/tags/Mongodb/" style="font-size: 15px;">Mongodb</a> <a href="/tags/CRUD/" style="font-size: 15px;">CRUD</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/存储过程/" style="font-size: 15px;">存储过程</a> <a href="/tags/ThreadLocal/" style="font-size: 15px;">ThreadLocal</a> <a href="/tags/XPath/" style="font-size: 15px;">XPath</a> <a href="/tags/C3P0/" style="font-size: 15px;">C3P0</a> <a href="/tags/DRUID/" style="font-size: 15px;">DRUID</a> <a href="/tags/工具类/" style="font-size: 15px;">工具类</a> <a href="/tags/Vue/" style="font-size: 15px;">Vue</a> <a href="/tags/jaxp/" style="font-size: 15px;">jaxp</a> <a href="/tags/Blob/" style="font-size: 15px;">Blob</a> <a href="/tags/JDBC/" style="font-size: 15px;">JDBC</a> <a href="/tags/事务/" style="font-size: 15px;">事务</a> <a href="/tags/sax/" style="font-size: 15px;">sax</a> <a href="/tags/逻辑回归/" style="font-size: 15px;">逻辑回归</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20210601001_OutOfMemoryError/">4.OutOfMemoryError</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20170924_VM-options配置/">VM options配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20170924_JVM运行原理/">JVM运行原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20170924_JVM的年轻代以及GC回收细节/">JVM的年轻代以及GC回收细节</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20170924_GC之间的区别/">Minor GC、Major GC和Full GC之间的区别</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/201703101259_垃圾收集器与内存分配策略/">垃圾收集器与内存分配策略</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/201703092017_对象在HotSpot虚拟机中/">对象在HotSpot虚拟机中</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/11/2018031301/">使用多种算法对泰坦尼克号乘客获救原因进行分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/11/2018030701/">构建逻辑回归模型实例</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/11/2018031201/">scikit-learn数据预处理fit_transform()与transform()的区别(转)</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/zj2626/" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">ZJ_BLOG.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.1" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.1" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.1"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
    search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script>var _hmt = _hmt || [];
(function () {
    var hm = document.createElement("script");
    hm.src = '//hm.baidu.com/hm.js?' + 'c9a692191e9aca9e30daa3f6326cc789';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.1"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.1"></script></div></body></html>
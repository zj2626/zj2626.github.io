<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="欢迎来到晋的博客,本博客用来收录平时学习笔记,欢迎访问"><title>构建逻辑回归模型实例 | ZJ_BLOG</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.1"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="/js/instantclick.min.js"></script><script>InstantClick.init();
InstantClick.on('change', function (isInitialLoad) {
         if (isInitialLoad === false) {
         if (typeof MathJax !== 'undefined') // support MathJax
         MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
         if (typeof prettyPrint !== 'undefined') // support google code prettify
         prettyPrint();
         if (typeof _hmt !== 'undefined')  // support 百度统计
         _hmt.push(['_trackPageview', location.pathname + location.search]);
         if (typeof ga !== 'undefined')  // support google analytics
         ga('send', 'pageview', location.pathname + location.search);
         }
 });
</script><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">构建逻辑回归模型实例</h1><a id="logo" href="/.">ZJ_BLOG</a><p class="description">Silence的博客</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">构建逻辑回归模型实例</h1><div class="post-meta">Mar 11, 2021<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#逻辑回归"><span class="toc-number">1.</span> <span class="toc-text">逻辑回归</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#构建逻辑回归模型步骤："><span class="toc-number">2.</span> <span class="toc-text">构建逻辑回归模型步骤：</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-数据与任务"><span class="toc-number">2.1.</span> <span class="toc-text">1. 数据与任务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#信用卡欺诈数据"><span class="toc-number">2.1.1.</span> <span class="toc-text">信用卡欺诈数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#要使用逻辑回归对数据进行建模-任务：二分类，-把数据分为有欺诈和无欺诈的两种数据"><span class="toc-number">2.1.2.</span> <span class="toc-text">要使用逻辑回归对数据进行建模 任务：二分类， 把数据分为有欺诈和无欺诈的两种数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-使用sklearn进行数据预处理"><span class="toc-number">2.2.</span> <span class="toc-text">2. 使用sklearn进行数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-处理数据-数据下采样"><span class="toc-number">2.2.1.</span> <span class="toc-text">1. 处理数据 数据下采样</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-预处理数据-修改列”Amount”数据分布"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">1.1  预处理数据,修改列”Amount”数据分布</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-数据处理-去除不需要的特征"><span class="toc-number">2.2.2.</span> <span class="toc-text">1.2  数据处理,去除不需要的特征</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-下采样"><span class="toc-number">2.3.</span> <span class="toc-text">3.下采样</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-区分正常数据和异常数据-通过特征’Class’区分"><span class="toc-number">2.3.1.</span> <span class="toc-text">1.3  区分正常数据和异常数据: 通过特征’Class’区分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-下采样处理数据-把多的一方数据进行随机减少到与少的一方相同"><span class="toc-number">2.3.2.</span> <span class="toc-text">1.4 下采样处理数据 把多的一方数据进行随机减少到与少的一方相同</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-数据索引合并-意思就是把新的正常数据和原来的异常数据进行拼接"><span class="toc-number">2.3.3.</span> <span class="toc-text">1.5 数据索引合并 (意思就是把新的正常数据和原来的异常数据进行拼接)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-获取合并数据中的feature-特征-和label-分类"><span class="toc-number">2.3.4.</span> <span class="toc-text">1.6 获取合并数据中的feature(特征)和label(分类)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-切分数据为训练和测试"><span class="toc-number">2.3.5.</span> <span class="toc-text">2. 切分数据为训练和测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#评估标准：召回率（recall）"><span class="toc-number">2.4.</span> <span class="toc-text">评估标准：召回率（recall）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型评估表："><span class="toc-number">2.4.1.</span> <span class="toc-text">模型评估表：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#一些术语："><span class="toc-number">2.4.2.</span> <span class="toc-text">一些术语：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分类器性能评价指标"><span class="toc-number">2.4.3.</span> <span class="toc-text">分类器性能评价指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-通过多次循环交叉验证-确定正则化参数-random-state：随机种子数"><span class="toc-number">2.4.4.</span> <span class="toc-text">3. 通过多次循环交叉验证 确定正则化参数 random_state：随机种子数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ndarray数据格式化-set-printoptions"><span class="toc-number">2.4.4.1.</span> <span class="toc-text">ndarray数据格式化: set_printoptions</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-使用最好的正则化参数-构建逻辑回归模型并进行测试"><span class="toc-number">2.4.5.</span> <span class="toc-text">4. 使用最好的正则化参数 构建逻辑回归模型并进行测试</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-使用最好的正则化参数-构建逻辑回归模型并进行测试-使用原始数据的测试集和训练集"><span class="toc-number">2.4.6.</span> <span class="toc-text">4. 使用最好的正则化参数 构建逻辑回归模型并进行测试 (使用原始数据的测试集和训练集)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-修改阈值以获取最好的逻辑回归模型"><span class="toc-number">2.4.7.</span> <span class="toc-text">5. 修改阈值以获取最好的逻辑回归模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#过采样"><span class="toc-number">2.5.</span> <span class="toc-text">过采样</span></a></li></ol></li></ol></div></div><div class="post-content"><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><blockquote>
<p>逻辑回归是应用非常广泛的一个分类机器学习算法，它将数据拟合到一个logit函数(或者叫做logistic函数)中，从而能够完成对事件发生的概率进行预测。</p>
</blockquote>
<h1 id="构建逻辑回归模型步骤："><a href="#构建逻辑回归模型步骤：" class="headerlink" title="构建逻辑回归模型步骤："></a>构建逻辑回归模型步骤：</h1><ul>
<li>导入数据</li>
<li>预处理数据</li>
<li>对不平衡的数据进行下采样（或者过采样）处理</li>
<li>把处理之后的数据进行切分，切分为训训练集和测试集</li>
<li>对训练集进行交叉验证，同时寻找最佳的正则化参数以减少过拟合</li>
<li>使用最佳的正则化参数对处理之后的数据进行训练并预测，观察召回率和精确率</li>
<li>使用最佳的正则化参数对处理之后的数据进行训练并预测，观察召回率和精确率</li>
<li>修改阈值以获得更好的召回率和精确率</li>
</ul>
<h2 id="1-数据与任务"><a href="#1-数据与任务" class="headerlink" title="1. 数据与任务"></a>1. 数据与任务</h2><h3 id="信用卡欺诈数据"><a href="#信用卡欺诈数据" class="headerlink" title="信用卡欺诈数据"></a>信用卡欺诈数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">"creditcard.csv"</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<img src="/2021/03/11/2018030701/20180307115819.png" title="如图">
<h3 id="要使用逻辑回归对数据进行建模-任务：二分类，-把数据分为有欺诈和无欺诈的两种数据"><a href="#要使用逻辑回归对数据进行建模-任务：二分类，-把数据分为有欺诈和无欺诈的两种数据" class="headerlink" title="要使用逻辑回归对数据进行建模 任务：二分类， 把数据分为有欺诈和无欺诈的两种数据"></a>要使用逻辑回归对数据进行建模 任务：二分类， 把数据分为有欺诈和无欺诈的两种数据</h3><h2 id="2-使用sklearn进行数据预处理"><a href="#2-使用sklearn进行数据预处理" class="headerlink" title="2. 使用sklearn进行数据预处理"></a>2. 使用sklearn进行数据预处理</h2><blockquote>
<p>公式为：(X-mean)/std  计算时对每个属性/每列分别进行。</p>
</blockquote>
<p>Standardization标准化:将特征数据的分布调整成标准正太分布，也叫高斯分布，也就是使得数据的均值维0，方差为1</p>
<p>标准化的原因在于如果有些特征的方差过大，则会主导目标函数从而使参数估计器无法正确地去学习其他特征。</p>
<p>标准化的过程为两步：去均值的中心化（均值变为0）；方差的规模化（方差变为1）。</p>
<p>在sklearn.preprocessing中提供了一个scale的方法，可以实现以上功能。如下面所示:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">1.</span>, <span class="number">-1.</span>, <span class="number">2.</span>],</span><br><span class="line">              [<span class="number">2.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">              [<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line"><span class="comment"># 将每一列特征标准化为标准正太分布，注意，标准化是针对每一列而言的</span></span><br><span class="line">x_scale = preprocessing.scale(x)</span><br><span class="line">x_scale</span><br></pre></td></tr></table></figure>
<p>preprocessing这个模块还提供了一个实用类StandarScaler，它可以在训练数据集上做了标准转换操作之后，把相同的转换应用到测试训练集中。<br>可以对训练数据，测试数据应用相同的转换，以后有新的数据进来也可以直接调用，不用再重新把数据放在一起再计算一次了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用fit方法，根据已有的训练数据创建一个标准化的转换器</span></span><br><span class="line">scaler = preprocessing.StandardScaler().fit(x)</span><br><span class="line"></span><br><span class="line">scaler</span><br><span class="line"></span><br><span class="line">StandardScaler(copy=<span class="literal">True</span>, with_mean=<span class="literal">True</span>, with_std=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用上面这个转换器去转换训练数据x,调用transform方法</span></span><br><span class="line">scaler.transform(x)</span><br></pre></td></tr></table></figure>
<p><em>StandardScaler()中可以传入两个参数：with_mean,with_std.这两个都是布尔型的参数，默认情况下都是true,但也可以自定义成false.即不要均值中心化或者不要方差规模化为1.</em></p>
<h3 id="1-处理数据-数据下采样"><a href="#1-处理数据-数据下采样" class="headerlink" title="1. 处理数据 数据下采样"></a>1. 处理数据 数据下采样</h3><h4 id="1-1-预处理数据-修改列”Amount”数据分布"><a href="#1-1-预处理数据-修改列”Amount”数据分布" class="headerlink" title="1.1  预处理数据,修改列”Amount”数据分布"></a>1.1  预处理数据,修改列”Amount”数据分布</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入预处理sklearn中预处理模块的标准化模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">'Amount'</span> <span class="keyword">in</span> data.columns:</span><br><span class="line">    <span class="comment"># 转化特征为新的特征</span></span><br><span class="line">    data[<span class="string">'normAount'</span>] = StandardScaler().fit_transform(data[<span class="string">'Amount'</span>].reshape(<span class="number">-1</span>, <span class="number">1</span>))  <span class="comment"># reshape:改变数组的形状,参数为改变后的行列数 </span></span><br><span class="line"><span class="comment"># fit_transform：对数据进行变换 矩阵旋转：-1表示自动识别 根据另一个矩阵列（行）数确定本行（列）数</span></span><br></pre></td></tr></table></figure>
<h3 id="1-2-数据处理-去除不需要的特征"><a href="#1-2-数据处理-去除不需要的特征" class="headerlink" title="1.2  数据处理,去除不需要的特征"></a>1.2  数据处理,去除不需要的特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 去掉两个没用的特征（列） axis=1表示对每一行去做这个操作，axis=0表示对每一列做相同的这个操作</span></span><br><span class="line"><span class="keyword">if</span> (<span class="string">'Time'</span>) <span class="keyword">in</span> data.columns:</span><br><span class="line">    data = data.drop([<span class="string">'Time'</span>], axis=<span class="number">1</span>) </span><br><span class="line"><span class="keyword">if</span> (<span class="string">'Amount'</span>) <span class="keyword">in</span> data.columns:</span><br><span class="line">    data = data.drop([<span class="string">'Amount'</span>], axis=<span class="number">1</span>) </span><br><span class="line">print(data.columns, len(data.columns))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.2.1 数据图形化展示(1的数据太少索引看上去没有)</span></span><br><span class="line">count_classes = pd.value_counts(data[<span class="string">'Class'</span>], sort=<span class="literal">True</span>).sort_index() <span class="comment"># 画图显示按某列分类之后的数据数量比例</span></span><br><span class="line">count_classes.plot(kind = <span class="string">'bar'</span>) <span class="comment"># bar：条形图</span></span><br><span class="line">plt.xlabel(<span class="string">"Class"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Frequency"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.2.2 原数据特征和分类</span></span><br><span class="line">X = data.loc[:, data.columns != <span class="string">"Class"</span>]</span><br><span class="line">y = data.loc[:, data.columns == <span class="string">'Class'</span>]</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"SHAPE"</span>, X.shape, y.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Class为0的数量远远大于1的数据，需要使数据个数相近 解决方案： 1.下采样（多的数据抽取部分） 2.过采样（少的数据生成更多）</span></span><br></pre></td></tr></table></figure>
<img src="/2021/03/11/2018030701/20180307120121.png" title="如图">
<h2 id="3-下采样"><a href="#3-下采样" class="headerlink" title="3.下采样"></a>3.下采样</h2><blockquote>
<p>把数据相对多的减少,可减少为和数据少的数量相同的数量</p>
</blockquote>
<h3 id="1-3-区分正常数据和异常数据-通过特征’Class’区分"><a href="#1-3-区分正常数据和异常数据-通过特征’Class’区分" class="headerlink" title="1.3  区分正常数据和异常数据: 通过特征’Class’区分"></a>1.3  区分正常数据和异常数据: 通过特征’Class’区分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.3.1 异常数据-信息</span></span><br><span class="line">number_records = data[data.Class == <span class="number">1</span>]</span><br><span class="line"><span class="comment"># 1.3.2 异常数据个数</span></span><br><span class="line">number_records_fraud = len(number_records)</span><br><span class="line"><span class="comment"># 1.3.3 异常数据索引</span></span><br><span class="line">frand_indices = np.array(number_records.index)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"异常样本索引 有&#123;&#125;个"</span>.format(number_records_fraud), frand_indices[:<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.3.4 正常数据-索引</span></span><br><span class="line">normal_indices = data[data.Class == <span class="number">0</span>].index</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"正常样本索引 有&#123;&#125;个"</span>.format(len(normal_indices)), normal_indices[<span class="number">-10</span>:])</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;所有数据 正常异常比 "</span>, len(normal_indices), <span class="string">'\t'</span>, number_records_fraud)</span><br><span class="line">print(<span class="string">"**************"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="1-4-下采样处理数据-把多的一方数据进行随机减少到与少的一方相同"><a href="#1-4-下采样处理数据-把多的一方数据进行随机减少到与少的一方相同" class="headerlink" title="1.4 下采样处理数据 把多的一方数据进行随机减少到与少的一方相同"></a>1.4 下采样处理数据 把多的一方数据进行随机减少到与少的一方相同</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在所有的正常样本索引normal_indices中随机获取，随机选取number_records_fraud个</span></span><br><span class="line"><span class="comment"># np.random.choice: 可以从一个int数字或1维array里随机选取内容，并将选取结果放入n维array中返回。</span></span><br><span class="line">random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace=<span class="literal">False</span>)</span><br><span class="line">random_normal_indices = np.array(random_normal_indices)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"'下采样'后有正常样本个数："</span>, len(random_normal_indices))</span><br></pre></td></tr></table></figure>
<h3 id="1-5-数据索引合并-意思就是把新的正常数据和原来的异常数据进行拼接"><a href="#1-5-数据索引合并-意思就是把新的正常数据和原来的异常数据进行拼接" class="headerlink" title="1.5 数据索引合并 (意思就是把新的正常数据和原来的异常数据进行拼接)"></a>1.5 数据索引合并 (意思就是把新的正常数据和原来的异常数据进行拼接)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">under_sample_indices = np.concatenate([frand_indices, random_normal_indices])</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"合并后有样本个数："</span>, len(under_sample_indices))</span><br><span class="line">under_sample_data = data.iloc[under_sample_indices, :]</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"合并后样本："</span>, under_sample_data[:<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;下采样数据 正常异常比 "</span>, len(under_sample_data[under_sample_data == <span class="number">0</span>]), <span class="string">'\t'</span>, len(under_sample_data[under_sample_data == <span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<h3 id="1-6-获取合并数据中的feature-特征-和label-分类"><a href="#1-6-获取合并数据中的feature-特征-和label-分类" class="headerlink" title="1.6 获取合并数据中的feature(特征)和label(分类)"></a>1.6 获取合并数据中的feature(特征)和label(分类)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_undersample = under_sample_data.loc[:, under_sample_data.columns != <span class="string">'Class'</span>]</span><br><span class="line">y_undersample = under_sample_data.loc[:, under_sample_data.columns == <span class="string">'Class'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (X_undersample.shape, y_undersample.shape)</span><br><span class="line"><span class="keyword">print</span> (len(under_sample_data[under_sample_data[<span class="string">"Class"</span>] == <span class="number">1</span>]), len(under_sample_data[under_sample_data[<span class="string">"Class"</span>] == <span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<img src="/2021/03/11/2018030701/20180307120308.png" title="如图">
<h3 id="2-切分数据为训练和测试"><a href="#2-切分数据为训练和测试" class="headerlink" title="2. 切分数据为训练和测试"></a>2. 切分数据为训练和测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切分原始数据 取数据集中80%的数据作为训练集（建立model） 其他20%的为测试集(测试model)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (X.shape, y.shape)</span><br><span class="line"><span class="comment">## 2.1.对原始数据进行切分 （最终需要使用原数据集中的测试数据进行测试）</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>) <span class="comment"># test_size测试集所占比例 random_state切分之前进行乱序</span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"1.训练集数据大小"</span>, X_train.shape)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"2.测试集数据大小"</span>, X_test.shape)</span><br><span class="line"><span class="keyword">print</span> (len(X_train) + len(X_test), len(y_train), len(y_test), <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 2.2.对下采样数据进行切分</span></span><br><span class="line">X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample, y_undersample, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>) <span class="comment"># test_size测试集大小 random_state切分之前进行乱序</span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"3.训练集数据大小"</span>, X_train_undersample.shape)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"4.测试集数据大小"</span>, X_test_undersample.shape)</span><br><span class="line"><span class="keyword">print</span> (len(X_train_undersample) + len(X_test_undersample), len(y_train_undersample), len(y_test_undersample), <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切分训练集 把训练集平均切分为三分然后进行交叉验证 （三组数据分别进行建模和验证）</span></span><br></pre></td></tr></table></figure>
<img src="/2021/03/11/2018030701/20180307120401.png" title="如图">
<h2 id="评估标准：召回率（recall）"><a href="#评估标准：召回率（recall）" class="headerlink" title="评估标准：召回率（recall）"></a>评估标准：召回率（recall）</h2><p><em>不适用准确率，因为准确率不能正确的得到所求的，是没用的</em></p>
<h3 id="模型评估表："><a href="#模型评估表：" class="headerlink" title="模型评估表："></a>模型评估表：</h3><table>
<thead>
<tr>
<th></th>
<th style="text-align:center">相关（Relevant），正类</th>
<th style="text-align:right">不相关（NonRelevant），负类</th>
</tr>
</thead>
<tbody>
<tr>
<td>被检测到（Retrieved）</td>
<td style="text-align:center">true positives （TP）</td>
<td style="text-align:right">false positives  （FP）</td>
</tr>
<tr>
<td>未被检测到（Retrieved）</td>
<td style="text-align:center">false negatives （FN）</td>
<td style="text-align:right">true negatives （TN）</td>
</tr>
</tbody>
</table>
<h3 id="一些术语："><a href="#一些术语：" class="headerlink" title="一些术语："></a>一些术语：</h3><ul>
<li>TP：True Positive，即正确预测出的正样本个数</li>
<li>FP：False Positive，即错误预测出的正样本个数（本来是负样本，被我们预测成了正样本）</li>
<li>TN：True Negative，即正确预测出的负样本个数</li>
<li>FN：False Negative，即错误预测出的负样本个数（本来是正样本，被我们预测成了负样本）</li>
</ul>
<h3 id="分类器性能评价指标"><a href="#分类器性能评价指标" class="headerlink" title="分类器性能评价指标"></a>分类器性能评价指标</h3><p>由以上四个指标，可以进一步衍生出其他三个常用的评价分类器性能的指标</p>
<ul>
<li>Precision(精确率)：TP÷(TP+FP)TP÷(TP+FP)，分类器预测出的正样本中，真实正样本的比例</li>
<li>Recall(召回率)：TP÷(TP+FN)TP÷(TP+FN)，在所有真实正样本中，分类器中能找到多少</li>
<li>Accuracy(准确率)：(TP+TN)÷(TP+NP+TN+FN)(TP+TN)÷(TP+NP+TN+FN)，分类器对整体的判断能力，即正确预测的比例</li>
</ul>
<blockquote>
<p>过拟合： 数据在训练集表现很好 在测试集表现很差</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression  <span class="comment"># 逻辑回归</span></span><br><span class="line"><span class="comment"># 注意这里导入的 不是from sklearn.model_selection import KFold</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold  <span class="comment"># 交叉验证  # cross_val_score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, recall_score, classification_report <span class="comment"># 混淆矩阵</span></span><br></pre></td></tr></table></figure>
<h3 id="3-通过多次循环交叉验证-确定正则化参数-random-state：随机种子数"><a href="#3-通过多次循环交叉验证-确定正则化参数-random-state：随机种子数" class="headerlink" title="3. 通过多次循环交叉验证 确定正则化参数 random_state：随机种子数"></a>3. 通过多次循环交叉验证 确定正则化参数 random_state：随机种子数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printing_Kfold_scores</span><span class="params">(x_train_data, y_train_data)</span>:</span></span><br><span class="line">    <span class="comment"># KFold：切分数据集 （这里切分为5部分） shuffle:是否每次都"洗牌"(Falses时，其效果等同于random_state等于整数，每次划分的结果相同)</span></span><br><span class="line">    fold = KFold(len(y_train_data), <span class="number">5</span>, shuffle=<span class="literal">False</span>) </span><br><span class="line">    <span class="keyword">print</span> (type(fold), len(y_train_data), len(fold)) <span class="comment"># 长度是5</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 正则化惩罚项(正则化参数) 预设了多个惩罚值，具体使用哪个需要尝试 列举了5个</span></span><br><span class="line">    c_param_range = [<span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 新建DataFrame类型的数据用来存放不同正则化之后的结果</span></span><br><span class="line">    results_table = pd.DataFrame(index = range(len(c_param_range)), columns = [<span class="string">'C_parameter'</span>, <span class="string">'Mean recall score'</span>])</span><br><span class="line">    results_table[<span class="string">'C_parameter'</span>] = c_param_range</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先按照正则化参数进行循环以确定最好的参数 然后对每个逻辑回归进行交叉验证以获得最好的逻辑回归函数</span></span><br><span class="line">    <span class="comment"># 循环正则化参数 获取最好的c参数</span></span><br><span class="line">    <span class="keyword">for</span> index, c_param <span class="keyword">in</span> enumerate(c_param_range):</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;"</span>)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"C_parameter "</span>, c_param)</span><br><span class="line">        </span><br><span class="line">        recall_accs = []</span><br><span class="line">        <span class="comment"># 循环进行交叉验证 </span></span><br><span class="line">        <span class="comment"># 每次循环次数为数据切分的大小,切分为n块就交叉验证n次,每次都是区其中n-1块为训练集1块为验证集</span></span><br><span class="line">        <span class="comment"># start=1:开始索引为1</span></span><br><span class="line">        <span class="comment"># iteration为索引 indices为划分好的数据:其中有n-1数据大小的训练集以及1数据代销的验证集</span></span><br><span class="line">        <span class="comment"># 循环中集合每次都不一样,所有的数据都会当一次验证集:例如 三个数据[1,2,3],循环使得数据分别为训练和验证每次为:[[1],[2, 3]], [[2],[1, 3]], [[3],[1, 2]]</span></span><br><span class="line">        <span class="keyword">for</span> iteration,  indices <span class="keyword">in</span> enumerate(fold, start=<span class="number">1</span>):</span><br><span class="line">            <span class="comment"># 这里并不是用fold直接划分训练集数据, 而是把索引进行1:5的划分, 然后按照索引获取数据中的对应的数据</span></span><br><span class="line">            <span class="keyword">print</span> (iteration, len(indices[<span class="number">0</span>]), len(indices[<span class="number">1</span>]))</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 建立逻辑回归模型</span></span><br><span class="line">            lr = LogisticRegression(C = c_param, penalty = <span class="string">'l1'</span>) <span class="comment"># C:正则化参数; penalty:惩罚项:使用L1正则化(惩罚) ‘l1’ or ‘l2’(默认: ‘l2’)</span></span><br><span class="line">            <span class="comment"># 在调参时如果我们主要的目的只是为了解决过拟合，一般penalty选择L2正则化就够了。</span></span><br><span class="line">            <span class="comment"># 但是如果选择L2正则化发现还是过拟合，即预测效果差的时候，就可以考虑L1正则化。</span></span><br><span class="line">            <span class="comment"># 另外，如果模型的特征非常多，我们希望一些不重要的特征系数归零，从而让模型系数稀疏化的话，也可以使用L1正则化。</span></span><br><span class="line">            <span class="comment"># print ("LR-逻辑回归表达式---", lr)</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 训练 参数一:训练数据特征(feature) 参数二:训练数据分类(label)</span></span><br><span class="line">            lr.fit(x_train_data.iloc[indices[<span class="number">0</span>],:], y_train_data.iloc[indices[<span class="number">0</span>],:].values.ravel())</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 预测</span></span><br><span class="line">            y_pred_undersample = lr.predict(x_train_data.iloc[indices[<span class="number">1</span>], :].values)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算召回率 召回率 =提取出的正确信息条数 /样本中的信息条数。通俗地说，就是所有准确的条目有多少被检索出来了。</span></span><br><span class="line">            <span class="comment"># 参数: 1.真实数据集  2.预测数据集</span></span><br><span class="line">            recall_acc = recall_score(y_train_data.iloc[indices[<span class="number">1</span>],:].values, y_pred_undersample)</span><br><span class="line">            recall_accs.append(recall_acc)</span><br><span class="line">            <span class="keyword">print</span> (len(indices), <span class="string">"Iteration "</span>, iteration, <span class="string">": recall score = "</span>, recall_acc)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 求每个惩罚值经过交叉验证之后平均召回率</span></span><br><span class="line">        results_table.loc[index, <span class="string">'Mean recall score'</span>] = np.mean(recall_accs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'\nMean recall score '</span>, np.mean(recall_accs), <span class="string">'\n'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">print</span> (results_table)</span><br><span class="line">    </span><br><span class="line">    best_c = results_table.loc[results_table[<span class="string">'Mean recall score'</span>].idxmax()][<span class="string">'C_parameter'</span>]</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"finally-------best is--------&gt; "</span>, best_c)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_c</span><br><span class="line"></span><br><span class="line">best_c = printing_Kfold_scores(X_train_undersample, y_train_undersample)</span><br></pre></td></tr></table></figure>
<img src="/2021/03/11/2018030701/20180307120616.png" title="如图">
<img src="/2021/03/11/2018030701/20180307120702.png" title="如图">
<img src="/2021/03/11/2018030701/20180307120717.png" title="如图">
<h4 id="ndarray数据格式化-set-printoptions"><a href="#ndarray数据格式化-set-printoptions" class="headerlink" title="ndarray数据格式化: set_printoptions"></a>ndarray数据格式化: set_printoptions</h4><blockquote>
<p>set_printoptions(precision=None,<br>                 threshold=None,<br>                 edgeitems=None,<br>                 linewidth=None,<br>                 suppress=None,<br>                 nanstr=None,<br>                 infstr=None,<br>                 formatter=None)</p>
</blockquote>
<ul>
<li>precision:输出结果保留精度的位数 (num)</li>
<li>threshold:array数量的个数在小于threshold的时候不会被折叠 (num)</li>
<li>edgeitems:在array已经被折叠后，开头和结尾都会显示edgeitems个数 (num)</li>
<li>formatter:这个很有意思，像python3里面str.format(),就是可以对你的输出进行自定义的格式化 其他的暂时没用到</li>
</ul>
<h3 id="4-使用最好的正则化参数-构建逻辑回归模型并进行测试"><a href="#4-使用最好的正则化参数-构建逻辑回归模型并进行测试" class="headerlink" title="4. 使用最好的正则化参数 构建逻辑回归模型并进行测试"></a>4. 使用最好的正则化参数 构建逻辑回归模型并进行测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建逻辑回归模型</span></span><br><span class="line">lr = LogisticRegression(C = best_c, penalty=<span class="string">'l1'</span>)</span><br><span class="line"><span class="comment"># 训练回归模型</span></span><br><span class="line">lr.fit(X_train_undersample, y_train_undersample.values.ravel())</span><br><span class="line"><span class="comment"># 使用模型进行测试</span></span><br><span class="line">y_pred_undersample = lr.predict(X_test_undersample.values)</span><br><span class="line"><span class="comment"># y_pred_undersample为预测(分类)值, y_test_undersample为真实测试集的(分类)值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (type(y_pred_undersample), len(y_pred_undersample), <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印和绘制混淆矩阵</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_confusion_matrix</span><span class="params">(cm, classes, title=<span class="string">'Confussion matrix'</span>, cmap=plt.cm.Blues)</span>:</span></span><br><span class="line">    <span class="comment">#设置显示混淆矩阵</span></span><br><span class="line">    plt.imshow(cm, interpolation=<span class="string">'nearest'</span>, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置坐标数</span></span><br><span class="line">    tick_marks = np.arange(len(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=<span class="number">0</span>)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line">    </span><br><span class="line">    thresh = cm.max() / <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># itertools.product可进行多层次循环 传入参数个数(n)和索引个数相同 可循环n^2次</span></span><br><span class="line">    <span class="comment"># 设置每个方块中的文字    </span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(range(cm.shape[<span class="number">0</span>]), range(cm.shape[<span class="number">1</span>])):</span><br><span class="line">        <span class="comment"># print (j, i, cm[i, j])</span></span><br><span class="line">        <span class="comment"># 因为i表示横坐标的位置, j表示纵坐标的位置 所以需要把i和j交换位置</span></span><br><span class="line">        plt.text(j, i, cm[i, j], horizontalalignment=<span class="string">"center"</span>, color=<span class="string">"white"</span> <span class="keyword">if</span> cm[i, j] &gt; thresh <span class="keyword">else</span> <span class="string">"black"</span>)</span><br><span class="line">    </span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    <span class="comment"># 设置坐标文字</span></span><br><span class="line">    plt.ylabel(<span class="string">"True label"</span>)      <span class="comment"># 真实数据 </span></span><br><span class="line">    plt.xlabel(<span class="string">"Predicted label"</span>) <span class="comment"># 预测数据 1表示正例 0表示负例</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 画混淆矩阵图 参数: 1.y_true, 2.y_pred</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test_undersample, y_pred_undersample)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Recall metric in the testing dataset: "</span>, cnf_matrix[<span class="number">1</span>, <span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>, <span class="number">0</span>] + cnf_matrix[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">class_names = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names, title=<span class="string">'Confusion matrix'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由图可见, 召回率为 85 / (85 + 6) = 93.41%</span></span><br><span class="line"><span class="comment">#           精确率为 (85) / (85 + 9) = 90.43%</span></span><br><span class="line"><span class="comment">#           准确率为 (85 + 97) / (85 + 9 + 6 + 97) = 92.39%</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以上计算都是基于下采样数据集的,还需要在原数据的测试集上进行测试操作 (与上面同理)</span></span><br></pre></td></tr></table></figure>
<img src="/2021/03/11/2018030701/20180307120847.png" title="如图">
<h3 id="4-使用最好的正则化参数-构建逻辑回归模型并进行测试-使用原始数据的测试集和训练集"><a href="#4-使用最好的正则化参数-构建逻辑回归模型并进行测试-使用原始数据的测试集和训练集" class="headerlink" title="4. 使用最好的正则化参数 构建逻辑回归模型并进行测试 (使用原始数据的测试集和训练集)"></a>4. 使用最好的正则化参数 构建逻辑回归模型并进行测试 (使用原始数据的测试集和训练集)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在原数据的测试集上进行测试操作</span></span><br><span class="line">lr = LogisticRegression(C = best_c, penalty=<span class="string">'l1'</span>)</span><br><span class="line">lr.fit(X_train, y_train.values.ravel())</span><br><span class="line">y_pred = lr.predict(X_test.values)</span><br><span class="line"><span class="comment"># y_pred为预测(分类)值, y_test为真实测试集的(分类)值</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cnf_matrix = confusion_matrix(y_test, y_pred)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Recall metric in the testing dataset: "</span>, cnf_matrix[<span class="number">1</span>, <span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>, <span class="number">0</span>] + cnf_matrix[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">class_names = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names, title=<span class="string">'Confusion matrix'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="5-修改阈值以获取最好的逻辑回归模型"><a href="#5-修改阈值以获取最好的逻辑回归模型" class="headerlink" title="5. 修改阈值以获取最好的逻辑回归模型"></a>5. 修改阈值以获取最好的逻辑回归模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 阈值: 默认使用sigma函数默认值:0.5, 意思是当预测概率大于0.5表示True,概率小鱼0.5表示False</span></span><br><span class="line"></span><br><span class="line">lr = LogisticRegression(C = best_c, penalty=<span class="string">'l1'</span>)</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">lr.fit(X_train, y_train.values.ravel())</span><br><span class="line"><span class="comment"># 预测 这里是预测概率值 每个数据的预测包含两个值，对于二分类问题，也就是被判断为0的概率和被判断为1的概率</span></span><br><span class="line">y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values) <span class="comment"># 预测概率值而不是类别值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可能的阈值</span></span><br><span class="line">thresholds = [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>)) <span class="comment"># 画图域</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, i <span class="keyword">in</span> enumerate(thresholds):</span><br><span class="line">    <span class="comment"># 预测概率</span></span><br><span class="line">    y_test_predictions_high_recall = y_pred_undersample_proba[:, <span class="number">1</span>] &gt; i</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">3</span>, <span class="number">3</span>, index + <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    cnf_matrix = confusion_matrix(y_test_undersample, y_test_predictions_high_recall)</span><br><span class="line">    np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">print</span> (i, <span class="string">"Recall metric in the testing dataset: "</span>, cnf_matrix[<span class="number">1</span>, <span class="number">1</span>] / (cnf_matrix[<span class="number">1</span>, <span class="number">0</span>] + cnf_matrix[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line">    </span><br><span class="line">    class_names = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">    plot_confusion_matrix(cnf_matrix, classes=class_names, title=<span class="string">"Threshold &gt;= %s"</span> %i)</span><br><span class="line">    </span><br><span class="line"><span class="comment">## 随着阈值上升 召回率不断变化 其中本来是1的被误检测为0的越来越多 可见 要选取最合适的阈值以达到召回率最高</span></span><br></pre></td></tr></table></figure>
<img src="/2021/03/11/2018030701/20180307120937.png" title="如图">
<img src="/2021/03/11/2018030701/20180307121001.png" title="如图">
<img src="/2021/03/11/2018030701/20180307121022.png" title="如图">
<h2 id="过采样"><a href="#过采样" class="headerlink" title="过采样"></a>过采样</h2><blockquote>
<p>把数据相对少的增加,可增加为和数据多的数量相同的数量 (生成)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">credit_cards = pd.read_csv(<span class="string">"creditcard.csv"</span>)</span><br><span class="line">columns = credit_cards.columns</span><br><span class="line"></span><br><span class="line">features_columns = columns.delete(len(columns) - <span class="number">1</span>) <span class="comment">#删除最后一列数据</span></span><br><span class="line"><span class="keyword">print</span> (features_columns)</span><br><span class="line"></span><br><span class="line">features = credit_cards[features_columns]</span><br><span class="line">labels = credit_cards[<span class="string">'Class'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"原始的数据个数"</span>, (credit_cards[credit_cards[<span class="string">'Class'</span>] == <span class="number">0</span>]).shape, (credit_cards[credit_cards[<span class="string">'Class'</span>] == <span class="number">1</span>]).shape)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">print</span> (features_train.shape, features_test.shape, labels_train.shape, labels_test.shape)</span><br></pre></td></tr></table></figure>
<img src="/2021/03/11/2018030701/20180307121128.png" title="如图">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">oversampler = SMOTE(random_state = <span class="number">0</span>) <span class="comment"># SMOTE随机生成数据 生成只能是训练集生成数据, 而测试集不生成</span></span><br><span class="line"><span class="comment"># 只生成训练集数据 使得Class为1和为0的数量相同 返回训练集的特征和分类</span></span><br><span class="line">os_features, os_labels = oversampler.fit_sample(features_train, labels_train)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"可见 的确生成了新的数据,补充了异常的数据 "</span>, len(os_labels[os_labels[:] == <span class="number">1</span>]), len(os_labels[os_labels[:] == <span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> ((os_features).shape, len(os_features[os_features == <span class="number">1</span>]), len(os_features[os_features == <span class="number">0</span>]), </span><br><span class="line">       (os_labels).shape, len(os_labels[os_labels == <span class="number">1</span>]), len(os_labels[os_labels == <span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<img src="/2021/03/11/2018030701/20180307121154.png" title="如图">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">os_features = pd.DataFrame(os_features)</span><br><span class="line">os_labels = pd.DataFrame(os_labels)</span><br><span class="line"><span class="comment"># 获取最佳参数</span></span><br><span class="line">best_c = printing_Kfold_scores(os_features, os_labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot_confusion_matrix</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty=<span class="string">'l1'</span>)</span><br><span class="line"><span class="comment"># 训练 使用生成的数据</span></span><br><span class="line">lr.fit(os_features, os_labels.values.ravel())</span><br><span class="line"><span class="comment"># 使用真实数据测试</span></span><br><span class="line">y_pred = lr.predict(features_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印和绘制混淆矩阵</span></span><br><span class="line">cnf_matrix = confusion_matrix(labels_test, y_pred)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Recall metric in the testing dataset: "</span>, cnf_matrix[<span class="number">1</span>, <span class="number">1</span>] / (cnf_matrix[<span class="number">1</span>, <span class="number">0</span>] + cnf_matrix[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">class_names = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix, classes=class_names, title=<span class="string">'Confusion matrix'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>个人博客 欢迎来访： <a href="http://zj2626.github.io">http://zj2626.github.io</a></p>
</blockquote>
</div><script type="text/javascript" src="/js/share.js?v=0.0.1" async></script><a class="article-share-link" data-url="http://zj2626.github.io/2021/03/11/2018030701/" data-id="ckpdnagum006778utz6a49qvd" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACNElEQVR42u3aOXLDMAwFUN//0k6bIqI/ACUTkY+VJ4vE5wKD7fWKz/vbmfz86snrn9x2MDAwHst4L0/1Wvlbrp589durJ2BgYJzDWIfCPCxOwGvSh7djYGBgjD+v08d1OMbAwMDoBdzkuvnVJ+/FwMA4h5EHvnUhml+rGqxvq8UxMDAeyMjLy7///CvzDQwMjEcx3sWT/9dk5FC+FQYGxtaMPMDlQ81qkpckl9H4AQMDY1NGb8GiF2qTxYvmQBQDA2NrRjIeyB+Xh+Ckndcbi2JgYOzHWIfC+apWdYWiF44xMDD2ZuQBN2nfV1tp1eZdhMTAwDiGUV2zmCSXzR7hfNaKgYHxEMZkxaE3+Kwulq0BP2S4GBgYBzB6jbDesLMalKN2GwYGxgGMdYFaLV8nqxuF8hUDA+MARg7IQ+1dI88obcXAwDiGUV0R66WS1b8sLFtgYGBsyii0tOKlit6KWC9kF6YHGBgYD2fkAbE3hkyuVV22wMDAOJPRK3Grmw+9kNobM2BgYOzEyANrtRydjCeTr+bDlAMDA2NTRl6a5iVrNeFrjkgxMDCOYeQXerVONUwn7T8MDIy9Ge/iSWD5E6rtuQ9JIQYGxqaMeXe9l9LNS9abB5wYGBj/npGvhVWb+5MitjyWwMDAOIDRKzjz9PGuyerlGzEwMDBuGlJWQ3M+PMDAwMBYB8TeukY0tchTTAwMjAMYSRFbDZr3fgW3tdswMDAeyJhsakyuPl+2wMDAOIDxBeiYaphK0h/pAAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/python/">python</a><a href="/tags/机器学习/">机器学习</a><a href="/tags/逻辑回归/">逻辑回归</a></div><div class="post-nav"><a class="pre" href="/2021/03/11/2018031201/">scikit-learn数据预处理fit_transform()与transform()的区别(转)</a><a class="next" href="/2021/03/11/2018031202/">关于使用sklearn进行数据预处理-归一化/标准化/正则化(转)</a></div><div id="container"></div><link rel="stylesheet" href="/css/default.css?v=0.0.1"><script src="/js/gitment.browser.js?v=0.0.1"></script><script>var gitment = new Gitment({
  owner: 'zj2626',
  repo: 'zj2626.github.io',
  oauth: {
    client_id: '22769c7edffa5f05d10d',
    client_secret: '7bac8fc03397cb64c178fbdfe3a01d2abb459704',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/BUG解决/">BUG解决</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DOM操作/">DOM操作</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/DOM操作/XML/">XML</a><span class="category-list-count">6</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/JDBC/">JDBC</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java虚拟机/">java虚拟机</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java语言基础/">java语言基础</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/多线程/">多线程</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库连接池/">数据库连接池</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构和算法/">数据结构和算法</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架相关/">框架相关</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/框架相关/前端技术/">前端技术</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架相关/权限管理/">权限管理</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/正则/">正则</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/程序安装与配置/">程序安装与配置</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机网络/">计算机网络</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/深入了解java虚拟机/" style="font-size: 15px;">深入了解java虚拟机</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/注解/" style="font-size: 15px;">注解</a> <a href="/tags/元数据/" style="font-size: 15px;">元数据</a> <a href="/tags/Maven/" style="font-size: 15px;">Maven</a> <a href="/tags/Hexo优化/" style="font-size: 15px;">Hexo优化</a> <a href="/tags/jenkins/" style="font-size: 15px;">jenkins</a> <a href="/tags/Git/" style="font-size: 15px;">Git</a> <a href="/tags/maven/" style="font-size: 15px;">maven</a> <a href="/tags/HTML/" style="font-size: 15px;">HTML</a> <a href="/tags/iframe/" style="font-size: 15px;">iframe</a> <a href="/tags/C语言/" style="font-size: 15px;">C语言</a> <a href="/tags/junit/" style="font-size: 15px;">junit</a> <a href="/tags/Shiro/" style="font-size: 15px;">Shiro</a> <a href="/tags/Mybatis/" style="font-size: 15px;">Mybatis</a> <a href="/tags/定义/" style="font-size: 15px;">定义</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/转码/" style="font-size: 15px;">转码</a> <a href="/tags/DBCP/" style="font-size: 15px;">DBCP</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/Dom4j/" style="font-size: 15px;">Dom4j</a> <a href="/tags/Hibernate/" style="font-size: 15px;">Hibernate</a> <a href="/tags/常用命令/" style="font-size: 15px;">常用命令</a> <a href="/tags/shell/" style="font-size: 15px;">shell</a> <a href="/tags/Mongodb/" style="font-size: 15px;">Mongodb</a> <a href="/tags/CRUD/" style="font-size: 15px;">CRUD</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/存储过程/" style="font-size: 15px;">存储过程</a> <a href="/tags/XPath/" style="font-size: 15px;">XPath</a> <a href="/tags/ThreadLocal/" style="font-size: 15px;">ThreadLocal</a> <a href="/tags/C3P0/" style="font-size: 15px;">C3P0</a> <a href="/tags/DRUID/" style="font-size: 15px;">DRUID</a> <a href="/tags/工具类/" style="font-size: 15px;">工具类</a> <a href="/tags/Vue/" style="font-size: 15px;">Vue</a> <a href="/tags/jaxp/" style="font-size: 15px;">jaxp</a> <a href="/tags/Blob/" style="font-size: 15px;">Blob</a> <a href="/tags/JDBC/" style="font-size: 15px;">JDBC</a> <a href="/tags/事务/" style="font-size: 15px;">事务</a> <a href="/tags/sax/" style="font-size: 15px;">sax</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/逻辑回归/" style="font-size: 15px;">逻辑回归</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20210601001_OutOfMemoryError/">4.OutOfMemoryError</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20170924_VM-options配置/">VM options配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20170924_JVM运行原理/">JVM运行原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20170924_JVM的年轻代以及GC回收细节/">JVM的年轻代以及GC回收细节</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/20170924_GC之间的区别/">Minor GC、Major GC和Full GC之间的区别</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/201703101259_垃圾收集器与内存分配策略/">垃圾收集器与内存分配策略</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/01/201703092017_对象在HotSpot虚拟机中/">对象在HotSpot虚拟机中</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/11/2018031301/">使用多种算法对泰坦尼克号乘客获救原因进行分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/11/2018031201/">scikit-learn数据预处理fit_transform()与transform()的区别(转)</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/11/2018030701/">构建逻辑回归模型实例</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/zj2626/" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">ZJ_BLOG.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.1" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.1" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.1"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
    search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script>var _hmt = _hmt || [];
(function () {
    var hm = document.createElement("script");
    hm.src = '//hm.baidu.com/hm.js?' + 'c9a692191e9aca9e30daa3f6326cc789';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.1"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.1"></script></div></body></html>